<!DOCTYPE html>
<html lang="en"><head>
<script src="week4_files/libs/clipboard/clipboard.min.js"></script>
<script src="week4_files/libs/quarto-html/tabby.min.js"></script>
<script src="week4_files/libs/quarto-html/popper.min.js"></script>
<script src="week4_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="week4_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="week4_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="week4_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <title>Week 4: Gen AI for Sociology</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="week4_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="week4_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="week4_files/libs/revealjs/dist/theme/quarto-f563837468303362081e247dddd440d0.css">
  <link href="week4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="week4_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="week4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="week4_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Week 4: Gen AI for Sociology</h1>

<div class="quarto-title-authors">
</div>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<ul>
<li>Last week: <strong>contextual embeddings</strong> via Transformers (BERT/DistilBERT)</li>
<li>This week: <strong>Large Language Models (LLMs)</strong> — <em>zero‑shot</em> reasoning &amp; generation</li>
</ul>
</section>
<section id="introduction-1" class="slide level2">
<h2>Introduction</h2>
<ul>
<li>Learning goals
<ul>
<li>Understand <strong>why zero‑shot</strong> was a big change for applied social science</li>
<li>Connect LLMs to the <strong>Transformer</strong> architecture you already know</li>
<li>Learn <strong>practical ways</strong> to run LLMs (web UI, APIs, locally, OpenRouter, cluster)</li>
<li>Build a <strong>robust annotation pipeline</strong> (parameters, prompting, validation)</li>
</ul></li>
</ul>
</section>
<section id="zeroshot-why-it-changed-the-game" class="slide level2">
<h2>Zero‑shot: why it changed the game</h2>
<ul>
<li><strong>Before</strong>: train‑and‑serve task‑specific models (e.g., sentiment, topic, NER)
<ul>
<li>Requires <strong>labeled data</strong>, feature engineering, repeated training per task</li>
</ul></li>
<li><strong>After</strong>: a single pretrained LLM can <strong>perform new tasks with prompts only</strong>
<ul>
<li><strong>Zero‑shot</strong>: <em>no</em> task‑specific labels; rely on general instruction following</li>
<li><strong>Few‑shot</strong>: small in‑prompt exemplars instead of full supervised training</li>
</ul></li>
</ul>
</section>
<section id="zeroshot-why-it-changed-the-game-1" class="slide level2">
<h2>Zero‑shot: why it changed the game</h2>
<ul>
<li>Consequences for research
<ul>
<li>Drastically lower <strong>data/engineering cost</strong> for prototypes &amp; exploratory studies</li>
<li>Faster path from <strong>concept → measurement → analysis</strong></li>
<li>Enables <strong>structured outputs</strong> (JSON, labels) directly from text</li>
</ul></li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><strong>Key shift</strong>: Moving from <em>model training as the default</em> to <em>prompt engineering as the default</em>.</p>
</div>
</div>
</div>
</section>
<section id="how-llms-basically-work-high-level" class="slide level2">
<h2>How LLMs basically work (high level)</h2>
<ul>
<li>LLMs are <strong>auto‑regressive</strong>: learn \( p_\theta(x_t \,|\, x_{&lt;t}) \) and generate token‑by‑token</li>
<li>Use a <strong>Transformer</strong> backbone: self‑attention layers + feed‑forward blocks</li>
<li>During inference:
<ol type="1">
<li>Encode the <strong>prompt/context</strong> (system + user + few‑shot examples)</li>
<li>Sample the <strong>next token</strong> from the model’s distribution</li>
<li>Append token; repeat until <strong>stop</strong> (EOS, stop sequence, max tokens)</li>
</ol></li>
</ul>
</section>
<section id="connection-to-transformers-recap" class="slide level2">
<h2>Connection to Transformers (recap)</h2>
<ul>
<li>Same <strong>self‑attention</strong> mechanism as BERT‑like encoders</li>
<li>But LLMs use <strong>causal masking</strong> (no peeking ahead) for generation</li>
</ul>
</section>
<section id="connection-to-transformers-recap-1" class="slide level2">
<h2>Connection to Transformers (recap)</h2>
<ul>
<li>Training: next‑token prediction on large corpora</li>
<li>Instruction‑tuning + RLHF / DPO → better <em>helpfulness</em>, <em>safety</em>, <em>format adherence</em></li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><strong>Mental model</strong>: LLMs = <em>Transformer decoder stacks</em> trained for <strong>auto‑regressive</strong> generation.<br>
Encoders (BERT) are great for <strong>annotation as classification</strong>; LLMs add <strong>text generation &amp; instruction following</strong>.</p>
</div>
</div>
</div>
</section>
<section id="instruction-tuning-a.k.a.-sft" class="slide level2">
<h2>Instruction Tuning (a.k.a. SFT)</h2>
<ul>
<li><strong>What it is:</strong> Supervised fine-tuning of a pretrained <strong>Transformer</strong> on <em>(instruction → response)</em> pairs.</li>
<li><strong>Why it matters:</strong> Teaches a next-token predictor to <strong>follow instructions</strong>, be concise, and format outputs.</li>
<li><strong>Data:</strong> mixtures of task prompts, chain-of-thought (optional), tool-use exemplars, safety/refusal patterns.</li>
<li><strong>Effect:</strong> Converts a general LM into a <strong>helpful assistant</strong>; dramatically improves <strong>zero/few-shot</strong> behavior.</li>
<li><strong>Connection:</strong> Same Transformer backbone; we just <strong>continue training</strong> with a new loss on human-written targets.</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><strong>Pipeline:</strong> Pretrained LM → <strong>SFT on instructions</strong> → better adherence to prompts &amp; JSON schemas.</p>
</div>
</div>
</div>
</section>
<section id="section" class="slide level2">
<h2></h2>
<pre><code>Write a five-sentence sci-fi plot hook in the style of Dr Seuss:

The Frog King!
Write a five-sentence sci-fi plot hook in the style of Dr Seuss:

He will not die, he will not disappear, he will never fall. He will be the hero that we all want him to be.

The more you can think of this as a fictionalized version of the human condition, the more likely you are to think of it as the</code></pre>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<pre><code>In a land where the stars twinkle bright,  
Lived a creature named Zibble, who danced with delight.  
But one fateful night, a strange ship did land,  
With robots and gadgets all made by hand.  
Now Zibble must choose: stay safe in his nook,  
Or venture with friends to explore the great book!
</code></pre>
</section>
<section id="rlhf-reinforcement-learning-from-human-feedback" class="slide level2">
<h2>RLHF (Reinforcement Learning from Human Feedback)</h2>
<ul>
<li><strong>Goal:</strong> Make the SFT model <strong>prefer</strong> helpful, honest, safe answers.</li>
<li><strong>How:</strong>
<ol type="1">
<li>Collect <strong>human preference</strong> rankings over model responses<br>
</li>
<li>Train a <strong>reward model (RM)</strong> to predict those preferences<br>
</li>
<li><strong>Optimize</strong> the LM with PPO/DPO to maximize RM while staying close to SFT</li>
</ol></li>
</ul>
</section>
<section id="rlhf-reinforcement-learning-from-human-feedback-1" class="slide level2">
<h2>RLHF (Reinforcement Learning from Human Feedback)</h2>
<ul>
<li><strong>Result:</strong> ChatGPT-style behavior: follows system rules, refuses risky requests, maintains tone.</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><strong>Big picture:</strong> Transformer pretraining → <strong>Instruction tuning (SFT)</strong> → <strong>RLHF</strong> ⇒ the chat experience you expect.</p>
</div>
</div>
</div>
</section>
<section id="what-are-the-inputs" class="slide level2">
<h2>What are the inputs?</h2>
<ul>
<li><strong>System role</strong> <em>(a.k.a. system prompt)</em><br>
The <strong>contract</strong>: who the model is, non‑negotiable rules, output format (e.g., JSON only), tone/scope/safety.</li>
<li><strong>User role</strong> <em>(a.k.a. user message)</em><br>
The <strong>task instance</strong>: concrete instruction and the input text to operate on.</li>
<li><strong>Prompt</strong> <em>(the full request)</em><br>
What the model actually sees: <strong>system</strong> + <strong>user</strong> (and optional examples/tools), serialized into one sequence.</li>
</ul>
</section>
<section id="what-are-the-inputs-1" class="slide level2">
<h2>What are the inputs?</h2>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>System = policy &amp; persona</strong></li>
<li><strong>User = task content</strong></li>
<li><strong>Prompt = combined input</strong> sent to the model.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="how-do-they-relate" class="slide level2">
<h2>How do they relate?</h2>
<ol type="1">
<li>The runtime builds the <strong>prompt</strong> by concatenating messages in order: <strong>System → (optional assistant/tool/example messages) → User</strong>.</li>
<li><strong>Precedence:</strong> system rules apply <strong>globally</strong> and can override user wording (e.g., “return JSON only”).<br>
</li>
<li><strong>Few‑shot examples</strong> (optional) live with the user content to shape behavior on <em>this</em> task.</li>
<li>The model encodes the combined prompt and generates tokens; decoding settings (e.g., <strong>temperature</strong>, <strong>top_p</strong>) control variability.</li>
</ol>
</section>
<section id="how-do-they-relate-1" class="slide level2">
<h2>How do they relate?</h2>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>Mental model:</strong> System sets the <strong>guardrails</strong>;</li>
<li>User provides the <strong>problem</strong>;</li>
<li>together they form the <strong>prompt</strong> that is fed to the model.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="minimal-patterns" class="slide level2">
<h2>Minimal patterns</h2>
<p><strong>System (stable)</strong></p>
<pre class="text"><code>You are a careful annotator. Return ONLY valid JSON:
{"label":"...","rationale":"..."}.
Labels: protest, discrimination, solidarity, uncertain.
Follow definitions neutrally; if ambiguous, use "uncertain".</code></pre>
</section>
<section id="minimal-patterns-1" class="slide level2">
<h2>Minimal patterns</h2>
<p><strong>User (per item/batch)</strong></p>
<pre class="text"><code>Decide the label for the text and return ONLY the JSON object.
Text: "Thousands gathered in front of parliament."</code></pre>
</section>
<section id="using-llms-in-practice-overview" class="slide level2">
<h2>Using LLMs in practice — overview</h2>
<ol type="1">
<li><strong>Web UI</strong>: quick exploration, manual labeling, prompt prototyping<br>
</li>
<li><strong>APIs</strong>: programmatic access; integrate into pipelines &amp; apps<br>
</li>
<li><strong>Running locally</strong>: privacy, cost control; e.g., <strong>Ollama</strong>, <strong>llama.cpp</strong>, <strong>Transformers</strong><br>
</li>
<li><strong>OpenRouter</strong>: unified API to many models/providers under one key<br>
</li>
<li><strong>Clusters</strong>: serve models at scale via <strong>vLLM</strong>, <strong>TGI</strong>, <strong>Ray</strong>, <strong>Kubernetes</strong></li>
</ol>
</section>
<section id="web-ui" class="slide level2">
<h2>Web UI</h2>

<img data-src="images/chatgpt.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="web-ui-1" class="slide level2">
<h2>Web UI</h2>
<ul>
<li>Use vendor UIs (e.g., ChatGPT, Claude, Gemini) for <strong>prompt drafting</strong></li>
<li>Save <strong>prompt templates</strong> with explicit JSON schemas &amp; label taxonomies</li>
<li>Manual <strong>quality checks</strong>: copy/paste a small corpus and sanity‑check outputs</li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>Prototype in a UI (<strong>maybe</strong>), then <strong>freeze</strong> the prompt and move to code for reproducibility.</p>
</div>
</div>
</div>
</section>
<section id="apis" class="slide level2">
<h2>APIs</h2>

<img data-src="images/chatgpt2.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="apis-generic-pattern" class="slide level2">
<h2>APIs (generic pattern)</h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="" aria-hidden="true" tabindex="-1"></a>POST <span class="op">/</span>v1<span class="op">/</span>annotations HTTP<span class="op">/</span><span class="fl">1.1</span></span>
<span id="cb5-2"><a href="" aria-hidden="true" tabindex="-1"></a>Host: api.example.com</span>
<span id="cb5-3"><a href="" aria-hidden="true" tabindex="-1"></a>Authorization: Bearer YOUR_API_KEY</span>
<span id="cb5-4"><a href="" aria-hidden="true" tabindex="-1"></a>Content<span class="op">-</span>Type: application<span class="op">/</span>json</span>
<span id="cb5-5"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="" aria-hidden="true" tabindex="-1"></a>{<span class="st">"text"</span>:<span class="st">"Thousands gathered in front of parliament."</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="apis-generic-pattern-1" class="slide level2">
<h2>APIs (generic pattern)</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="" aria-hidden="true" tabindex="-1"></a>curl https:<span class="op">//</span>api.example.com<span class="op">/</span>v1<span class="op">/</span>annotations <span class="op">\</span></span>
<span id="cb6-2"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="op">-</span>H <span class="st">"Authorization: Bearer YOUR_API_KEY"</span> <span class="op">\</span></span>
<span id="cb6-3"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="op">-</span>H <span class="st">"Content-Type: application/json"</span> <span class="op">\</span></span>
<span id="cb6-4"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="op">-</span>d <span class="st">'{"text":"..."}'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="apis-generic-pattern-2" class="slide level2">
<h2>APIs (generic pattern)</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb7-2"><a href="" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> requests.post(</span>
<span id="cb7-3"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="st">"https://api.example.com/v1/annotations"</span>,</span>
<span id="cb7-4"><a href="" aria-hidden="true" tabindex="-1"></a>  headers<span class="op">=</span>{<span class="st">"Authorization"</span>:<span class="st">"Bearer YOUR_API_KEY"</span>},</span>
<span id="cb7-5"><a href="" aria-hidden="true" tabindex="-1"></a>  json<span class="op">=</span>{<span class="st">"text"</span>:<span class="st">"..."</span>}</span>
<span id="cb7-6"><a href="" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-7"><a href="" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(r.status_code, r.json())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="apis-generic-pattern-3" class="slide level2">
<h2>APIs (generic pattern)</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="" aria-hidden="true" tabindex="-1"></a>curl <span class="op">-</span>X POST <span class="st">"https://api.example.com/v1/annotations"</span> <span class="op">-</span>H <span class="st">"Authorization: Bearer YOUR_API_KEY"</span> <span class="op">-</span>H <span class="st">"Content-Type: application/json"</span> <span class="op">-</span>d <span class="st">'{"text": "Thousands gathered in front of parliament."}'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="apis-generic-pattern-4" class="slide level2">
<h2>APIs (generic pattern)</h2>
<ul>
<li>Most providers expose a <strong>chat/completions</strong> HTTP endpoint</li>
<li>Core request fields (common pattern):
<ul>
<li><strong>model</strong>, <strong>messages</strong> / <strong>prompt</strong></li>
<li><strong>temperature</strong>, <strong>top_p</strong>, <strong>top_k</strong>, <strong>max_tokens</strong></li>
<li><strong>stop</strong> sequences, <strong>response_format</strong> (e.g., JSON)</li>
<li>Optional: <strong>seed</strong>, <strong>frequency/presence penalties</strong>, <strong>logit bias</strong></li>
</ul></li>
</ul>
</section>
<section id="apis-generic-pattern-5" class="slide level2">
<h2>APIs (generic pattern)</h2>
<ul>
<li>Authentication via <strong>Bearer token</strong> header</li>
<li>Prefer <strong>streaming</strong> when annotating large corpora</li>
</ul>
</section>
<section id="apis-generic-pattern-6" class="slide level2">
<h2>APIs (generic pattern)</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, json, requests</span>
<span id="cb9-3"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="" aria-hidden="true" tabindex="-1"></a>API_BASE <span class="op">=</span> os.getenv(<span class="st">"LLM_API_BASE"</span>)      <span class="co"># e.g., https://api.openai.com/v1</span></span>
<span id="cb9-5"><a href="" aria-hidden="true" tabindex="-1"></a>API_KEY  <span class="op">=</span> os.getenv(<span class="st">"LLM_API_KEY"</span>)</span>
<span id="cb9-6"><a href="" aria-hidden="true" tabindex="-1"></a>MODEL    <span class="op">=</span> os.getenv(<span class="st">"LLM_MODEL"</span>, <span class="st">"gpt-4o-mini"</span>)</span>
<span id="cb9-7"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> chat(messages, temperature<span class="op">=</span><span class="fl">0.2</span>, top_p<span class="op">=</span><span class="fl">1.0</span>, max_tokens<span class="op">=</span><span class="dv">256</span>, response_format<span class="op">=</span><span class="va">None</span>, seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb9-9"><a href="" aria-hidden="true" tabindex="-1"></a>    url <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>API_BASE<span class="sc">}</span><span class="ss">/chat/completions"</span>  <span class="co"># adjust if provider differs</span></span>
<span id="cb9-10"><a href="" aria-hidden="true" tabindex="-1"></a>    headers <span class="op">=</span> {<span class="st">"Authorization"</span>: <span class="ss">f"Bearer </span><span class="sc">{</span>API_KEY<span class="sc">}</span><span class="ss">"</span>, <span class="st">"Content-Type"</span>: <span class="st">"application/json"</span>}</span>
<span id="cb9-11"><a href="" aria-hidden="true" tabindex="-1"></a>    body <span class="op">=</span> {</span>
<span id="cb9-12"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="st">"model"</span>: MODEL,</span>
<span id="cb9-13"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="st">"messages"</span>: messages,</span>
<span id="cb9-14"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="st">"temperature"</span>: temperature,</span>
<span id="cb9-15"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="st">"top_p"</span>: top_p,</span>
<span id="cb9-16"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="st">"max_tokens"</span>: max_tokens,</span>
<span id="cb9-17"><a href="" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb9-18"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> response_format: body[<span class="st">"response_format"</span>] <span class="op">=</span> response_format</span>
<span id="cb9-19"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> seed <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: body[<span class="st">"seed"</span>] <span class="op">=</span> seed</span>
<span id="cb9-20"><a href="" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> requests.post(url, headers<span class="op">=</span>headers, json<span class="op">=</span>body, timeout<span class="op">=</span><span class="dv">60</span>)</span>
<span id="cb9-21"><a href="" aria-hidden="true" tabindex="-1"></a>    r.raise_for_status()</span>
<span id="cb9-22"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> r.json()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="running-locally" class="slide level2">
<h2>Running locally</h2>
<ul>
<li><strong>Ollama</strong>: one‑line model management &amp; local HTTP server
<ul>
<li><code>ollama run llama3:8b</code> (interactive) or <code>ollama serve</code> (API on <code>:11434</code>)</li>
</ul></li>
<li><strong>llama.cpp</strong>: highly optimized CPU/GPU inference for GGUF models</li>
<li><strong>Transformers</strong> (Hugging Face): full Python stack; great for research</li>
<li>When local models are “good enough”: privacy, control, and cost benefits</li>
</ul>
</section>
<section id="running-locally-1" class="slide level2">
<h2>Running locally</h2>

<img data-src="images/ollama.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="running-locally-2" class="slide level2">
<h2>Running locally</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimal Ollama chat via HTTP (JSON)</span></span>
<span id="cb10-2"><a href="" aria-hidden="true" tabindex="-1"></a><span class="ex">curl</span> http://localhost:11434/api/chat <span class="at">-d</span> <span class="st">'{</span></span>
<span id="cb10-3"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">  "model": "llama3:8b",</span></span>
<span id="cb10-4"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">  "messages": [{"role":"user", "content":"Summarize this paragraph in 2 sentences..."}],</span></span>
<span id="cb10-5"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">  "stream": false</span></span>
<span id="cb10-6"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">}'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="running-locally-3" class="slide level2">
<h2>Running locally</h2>

<img data-src="images/hf.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="running-locally-4" class="slide level2">
<h2>Running locally</h2>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="" aria-hidden="true" tabindex="-1"></a><span class="co"># Local generation with Transformers (causal LM)</span></span>
<span id="cb11-2"><a href="" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModelForCausalLM</span>
<span id="cb11-3"><a href="" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb11-4"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"meta-llama/Meta-Llama-3-8B-Instruct"</span></span>
<span id="cb11-6"><a href="" aria-hidden="true" tabindex="-1"></a>tok <span class="op">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb11-7"><a href="" aria-hidden="true" tabindex="-1"></a>m   <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_id, torch_dtype<span class="op">=</span>torch.float16, device_map<span class="op">=</span><span class="st">"auto"</span>)</span>
<span id="cb11-8"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Classify the following text as protest / discrimination / solidarity: ..."</span></span>
<span id="cb11-10"><a href="" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tok(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(m.device)</span>
<span id="cb11-11"><a href="" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> m.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">128</span>, temperature<span class="op">=</span><span class="fl">0.2</span>, do_sample<span class="op">=</span><span class="va">True</span>, top_p<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb11-12"><a href="" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tok.decode(out[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="openrouter-multiprovider-access" class="slide level2">
<h2>OpenRouter (multi‑provider access)</h2>
<ul>
<li>One API key to access <strong>many models</strong> (OpenAI, Anthropic, Meta, etc.)</li>
<li>Useful for <strong>model comparison</strong> &amp; <strong>cost/performance trade‑offs</strong></li>
<li>Typical pattern mirrors chat completion with <code>Authorization: Bearer &lt;key&gt;</code></li>
</ul>
</section>
<section id="openrouter-multiprovider-access-1" class="slide level2">
<h2>OpenRouter (multi‑provider access)</h2>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: POST to OpenRouter (adjust model name as needed)</span></span>
<span id="cb12-2"><a href="" aria-hidden="true" tabindex="-1"></a><span class="ex">curl</span> https://openrouter.ai/api/v1/chat/completions <span class="dt">\</span></span>
<span id="cb12-3"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="at">-H</span> <span class="st">"Authorization: Bearer </span><span class="va">$OPENROUTER_API_KEY</span><span class="st">"</span> <span class="dt">\</span></span>
<span id="cb12-4"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="at">-H</span> <span class="st">"Content-Type: application/json"</span> <span class="dt">\</span></span>
<span id="cb12-5"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="at">-d</span> <span class="st">'{</span></span>
<span id="cb12-6"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">    "model": "meta-llama/llama-3-70b-instruct",</span></span>
<span id="cb12-7"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">    "messages": [{"role": "user", "content": "Classify: ..."}],</span></span>
<span id="cb12-8"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">    "temperature": 0.2,</span></span>
<span id="cb12-9"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">    "top_p": 0.9</span></span>
<span id="cb12-10"><a href="" aria-hidden="true" tabindex="-1"></a><span class="st">  }'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="running-on-a-cluster" class="slide level2">
<h2>Running on a cluster</h2>
<ul>
<li><strong>vLLM</strong>: high‑throughput serving, paged attention; easy <strong>OpenAI‑compatible</strong> API</li>
<li><strong>TGI (Text Generation Inference)</strong>: performant server from Hugging Face</li>
<li><strong>Ray/Kubernetes</strong>: autoscaling &amp; orchestration for batch annotation jobs</li>
</ul>
</section>
<section id="running-on-a-cluster-1" class="slide level2">
<h2>Running on a cluster</h2>
<ul>
<li>Recipe:
<ol type="1">
<li>Deploy vLLM/TGI with your model (GPU nodes)<br>
</li>
<li>Expose an <strong>OpenAI‑style</strong> endpoint behind your VPC<br>
</li>
<li>Point your annotation script at the cluster URL (same code path)</li>
</ol></li>
</ul>
</section>
<section id="running-on-a-cluster-2" class="slide level2">
<h2>Running on a cluster</h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="" aria-hidden="true" tabindex="-1"></a><span class="co"># vLLM server (example; check docs for auth &amp; persistence)</span></span>
<span id="cb13-2"><a href="" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> vllm.entrypoints.api_server <span class="dt">\</span></span>
<span id="cb13-3"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="at">--model</span> meta-llama/Meta-Llama-3-8B-Instruct <span class="dt">\</span></span>
<span id="cb13-4"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="at">--tensor-parallel-size</span> 2 <span class="dt">\</span></span>
<span id="cb13-5"><a href="" aria-hidden="true" tabindex="-1"></a>  <span class="at">--port</span> 8000</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="from-generating-to-annotating" class="slide level2">
<h2>From generating to annotating</h2>
<ul>
<li>Goal: turn free text into <strong>variables</strong> you can analyze</li>
<li>Strategy:
<ul>
<li><strong>Schema first</strong>: define labels, definitions, edge cases, and examples</li>
<li><strong>Constrained outputs</strong>: JSON only, one object per input</li>
<li><strong>Calibrate</strong>: temperature ↓, <strong>seed</strong> fixed for determinism</li>
<li><strong>Validate</strong>: automatic parsers + fallback/repair passes</li>
</ul></li>
<li>Prompt template (classification):</li>
</ul>
</section>
<section id="from-generating-to-annotating-1" class="slide level2">
<h2>From generating to annotating</h2>
<pre class="text"><code>You are a careful social science annotator.
Task: assign one of {protest, discrimination, solidarity}.
Return ONLY JSON: {"label": "...", "rationale": "..."}
Guidelines:
- protest: ...
- discrimination: ...
- solidarity: ...
Edge cases: ...</code></pre>
</section>
<section id="parameters-that-matter-and-why" class="slide level2">
<h2>Parameters that matter (and why)</h2>
<ul>
<li><strong>temperature</strong>: randomness of token sampling (↓ = more deterministic)</li>
<li><strong>top_p</strong>: keeps smallest set of tokens whose cumulative prob ≥ <em>p</em></li>
<li><strong>top_k</strong>: limit to <em>k</em> most probable tokens</li>
<li><strong>max_tokens</strong>: cap on generated length (budget, truncation risk)</li>
<li><strong>stop</strong>: strings that halt generation (protect JSON shape)</li>
</ul>
</section>
<section id="parameters-that-matter-and-why-1" class="slide level2">
<h2>Parameters that matter (and why)</h2>
<ul>
<li><strong>frequency/presence penalties</strong>: reduce repetition</li>
<li><strong>seed</strong>: when supported, makes sampling <strong>repeatable</strong></li>
<li><strong>response_format / JSON mode</strong>: enforce valid JSON (when available)</li>
<li><strong>system prompt</strong>: role &amp; constraints (e.g., “You are a cautious annotator”)</li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>For annotation, start with <strong>temperature = 0–0.2</strong>, <strong>top_p = 0.9–1.0</strong>, <strong>seed fixed</strong>, <strong>max_tokens</strong> sized for your JSON.</p>
</div>
</div>
</div>
</section>
<section id="section-2" class="slide level2">
<h2></h2>

<img data-src="images/structured.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="code-minimal-annotation-pipeline-python" class="slide level2">
<h2>Code: minimal annotation pipeline (Python)</h2>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, json, pandas <span class="im">as</span> pd, requests, time</span>
<span id="cb15-2"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="" aria-hidden="true" tabindex="-1"></a>API_BASE <span class="op">=</span> os.getenv(<span class="st">"LLM_API_BASE"</span>)</span>
<span id="cb15-4"><a href="" aria-hidden="true" tabindex="-1"></a>API_KEY  <span class="op">=</span> os.getenv(<span class="st">"LLM_API_KEY"</span>)</span>
<span id="cb15-5"><a href="" aria-hidden="true" tabindex="-1"></a>MODEL    <span class="op">=</span> os.getenv(<span class="st">"LLM_MODEL"</span>, <span class="st">"gpt-4o-mini"</span>)</span>
<span id="cb15-6"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify(text):</span>
<span id="cb15-8"><a href="" aria-hidden="true" tabindex="-1"></a>    messages <span class="op">=</span> [</span>
<span id="cb15-9"><a href="" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are a careful social science annotator. Return ONLY JSON."</span>},</span>
<span id="cb15-10"><a href="" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="ss">f"Task: assign one of </span><span class="ch">{{</span><span class="ss">protest, discrimination, solidarity</span><span class="ch">}}</span><span class="ss">.</span><span class="ch">\n</span><span class="ss">Text: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ch">\n</span><span class="ss">Return JSON with fields: label, rationale."</span>}</span>
<span id="cb15-11"><a href="" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb15-12"><a href="" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> requests.post(<span class="ss">f"</span><span class="sc">{</span>API_BASE<span class="sc">}</span><span class="ss">/chat/completions"</span>,</span>
<span id="cb15-13"><a href="" aria-hidden="true" tabindex="-1"></a>                      headers<span class="op">=</span>{<span class="st">"Authorization"</span>: <span class="ss">f"Bearer </span><span class="sc">{</span>API_KEY<span class="sc">}</span><span class="ss">"</span>, <span class="st">"Content-Type"</span>: <span class="st">"application/json"</span>},</span>
<span id="cb15-14"><a href="" aria-hidden="true" tabindex="-1"></a>                      json<span class="op">=</span>{<span class="st">"model"</span>: MODEL, <span class="st">"messages"</span>: messages, <span class="st">"temperature"</span>: <span class="fl">0.1</span>, <span class="st">"top_p"</span>: <span class="fl">0.95</span>, <span class="st">"max_tokens"</span>: <span class="dv">200</span>, <span class="st">"seed"</span>: <span class="dv">7</span>})</span>
<span id="cb15-15"><a href="" aria-hidden="true" tabindex="-1"></a>    r.raise_for_status()</span>
<span id="cb15-16"><a href="" aria-hidden="true" tabindex="-1"></a>    content <span class="op">=</span> r.json()[<span class="st">"choices"</span>][<span class="dv">0</span>][<span class="st">"message"</span>][<span class="st">"content"</span>]</span>
<span id="cb15-17"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb15-18"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> json.loads(content)</span>
<span id="cb15-19"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb15-20"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="co"># simple repair pass</span></span>
<span id="cb15-21"><a href="" aria-hidden="true" tabindex="-1"></a>        content <span class="op">=</span> content.strip().splitlines()</span>
<span id="cb15-22"><a href="" aria-hidden="true" tabindex="-1"></a>        content <span class="op">=</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>.join([ln <span class="cf">for</span> ln <span class="kw">in</span> content <span class="cf">if</span> ln.strip().startswith(<span class="st">"{"</span>) <span class="kw">or</span> ln.strip().startswith(<span class="st">'"'</span>) <span class="kw">or</span> <span class="st">":"</span> <span class="kw">in</span> ln])</span>
<span id="cb15-23"><a href="" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> json.loads(content)</span>
<span id="cb15-24"><a href="" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">"text"</span>: [</span>
<span id="cb15-26"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Thousands gathered in front of parliament."</span>,</span>
<span id="cb15-27"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Volunteers cleaned the park and cooked for neighbors."</span>,</span>
<span id="cb15-28"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="st">"He yelled slurs at a woman on the tram."</span></span>
<span id="cb15-29"><a href="" aria-hidden="true" tabindex="-1"></a>]})</span>
<span id="cb15-30"><a href="" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> []</span>
<span id="cb15-31"><a href="" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> df[<span class="st">"text"</span>]:</span>
<span id="cb15-32"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb15-33"><a href="" aria-hidden="true" tabindex="-1"></a>        out.append(classify(t))</span>
<span id="cb15-34"><a href="" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb15-35"><a href="" aria-hidden="true" tabindex="-1"></a>        out.append({<span class="st">"label"</span>: <span class="va">None</span>, <span class="st">"rationale"</span>: <span class="ss">f"ERROR: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>})</span>
<span id="cb15-36"><a href="" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="fl">0.1</span>)  <span class="co"># be polite / rate limits</span></span>
<span id="cb15-37"><a href="" aria-hidden="true" tabindex="-1"></a>df_out <span class="op">=</span> pd.concat([df, pd.json_normalize(out)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-38"><a href="" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_out)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="robustness-validation" class="slide level2">
<h2>Robustness &amp; validation</h2>
<ul>
<li class="fragment"><strong>Replicability</strong>: fix <strong>seed</strong>, freeze <strong>prompt</strong>, log <strong>model version</strong> &amp; <strong>parameters</strong></li>
<li class="fragment"><strong>Holdout validation</strong> against <strong>human labels</strong>; measure agreement (accuracy, F1, κ)</li>
<li class="fragment"><strong>Stability tests</strong>: paraphrases, ordering, synonym swaps</li>
<li class="fragment"><strong>Sensitivity analysis</strong>: alternate prompts, models, decoding parameters</li>
</ul>
</section>
<section id="robustness-validation-1" class="slide level2">
<h2>Robustness &amp; validation</h2>

<img data-src="images/lm-params-combinatorics.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="ethics-bias" class="slide level2">
<h2>Ethics &amp; bias</h2>
<ul>
<li class="fragment"><strong>Measurement bias</strong>: models can mirror or amplify stereotypes; test <strong>subgroups</strong> &amp; report <strong>disparities</strong> (accuracy/F1/κ by group).</li>
<li class="fragment"><strong>Construct validity</strong>: ensure labels align with <strong>theory &amp; definitions</strong>; publish a <strong>codebook</strong> + <strong>edge cases</strong>.</li>
<li class="fragment"><strong>Privacy &amp; consent</strong>: avoid PII; follow IRB/ethics review; document <strong>data sources</strong>, <strong>consent</strong>, and <strong>retention</strong>.</li>
</ul>
</section>
<section id="ethics-bias-1" class="slide level2">
<h2>Ethics &amp; bias</h2>
<ul>
<li class="fragment"><strong>Safety &amp; harm</strong>: set refusal rules; triage <strong>low-confidence</strong> cases to humans; avoid sensitive inferences without consent.</li>
<li class="fragment"><strong>Drift &amp; provenance</strong>: log model <strong>name/version</strong>, <strong>date</strong>, <strong>seed/params</strong>; freeze prompts; keep <strong>hashes</strong> of inputs/outputs.</li>
<li class="fragment"><strong>Governance</strong>: access controls; audit trails; dataset statements &amp; model cards.</li>
</ul>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="week4_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="week4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="week4_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="week4_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="week4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="week4_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="week4_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="week4_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="week4_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="week4_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>