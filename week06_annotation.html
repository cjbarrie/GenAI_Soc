
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Structured Text Annotation with LLMs &#8212; GenAI for Sociology</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'week06_annotation';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="LLMs for Synthetic Data I: Simulating Survey Respondents" href="week07_silicon_sampling.html" />
    <link rel="prev" title="Qualitative Coding with LLMs" href="week05_qualitative.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">GenAI for Sociology</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    GenAI for Sociology
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="week04_llms.html">LLMs for Annotation I</a></li>
<li class="toctree-l1"><a class="reference internal" href="week05_qualitative.html">LLMs for Annotation II</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">LLMs for Annotation III</a></li>
<li class="toctree-l1"><a class="reference internal" href="week07_silicon_sampling.html">LLMs for Synthetic Data I: Simulating Survey Respondents</a></li>
<li class="toctree-l1"><a class="reference internal" href="week08_interactive_experiments.html">LLMs for Synthetic Data II: Interactive Experiments and Persuasion</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/cjbarrie/GenAI_Soc/blob/main/genai_book/week06_annotation.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/cjbarrie/GenAI_Soc" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cjbarrie/GenAI_Soc/issues/new?title=Issue%20on%20page%20%2Fweek06_annotation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/week06_annotation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Structured Text Annotation with LLMs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-in-google-colab">Running in Google Colab</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-locally">Running Locally</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-prompt-formatting-strategies">Part 1: Prompt Formatting Strategies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-f-string-prompting">1A. Simple f-string Prompting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-reusable-template-with-format">1B. Reusable Template with .format()</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-few-shot-prompting">1C. Few-Shot Prompting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-chain-of-thought-prompting">1D. Chain-of-Thought Prompting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-three-approaches-to-getting-structured-outputs-json">Part 2: Three Approaches to Getting Structured Outputs (JSON)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-prompt-for-json-simplest-least-reliable">Approach 1: Prompt for JSON (Simplest, Least Reliable)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-json-mode-api-parameter-recommended-for-most-tasks">Approach 2: JSON Mode API Parameter (Recommended for Most Tasks)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-3-provider-json-mode-more-reliable">Approach 3: Provider JSON Mode (More Reliable)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-summary">Comparison Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-robust-json-extraction">Part 3: Robust JSON Extraction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-4-batch-annotation">Part 4: Batch Annotation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-source-alternatives">Open-Source Alternatives</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama">Using Ollama</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-hugging-face">Using Hugging Face</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-formatting">1. Prompt Formatting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#structured-outputs-three-approaches">2. Structured Outputs (Three Approaches)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-extraction">3. Robust Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-annotation">4. Batch Annotation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-practices-checklist">Best Practices Checklist</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="structured-text-annotation-with-llms">
<h1>Structured Text Annotation with LLMs<a class="headerlink" href="#structured-text-annotation-with-llms" title="Link to this heading">#</a></h1>
<p>This notebook demonstrates how to reliably extract structured outputs from LLMs for text annotation tasks in social science research.</p>
<section id="learning-objectives">
<h2>Learning Objectives<a class="headerlink" href="#learning-objectives" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Master <strong>prompt formatting</strong> strategies (f-strings, templates, few-shot, chain-of-thought)</p></li>
<li><p>Understand <strong>three approaches</strong> to structured outputs (JSON)</p>
<ol class="arabic simple">
<li><p><strong>Prompt for JSON</strong> (simplest, least reliable)</p></li>
<li><p><strong>JSON Mode API</strong> (recommended default)</p></li>
<li><p><strong>Function Calling</strong> (most structured, type-safe)</p></li>
</ol>
</li>
<li><p>Implement <strong>robust JSON extraction</strong> with error handling and retries</p></li>
<li><p>Perform <strong>batch annotation</strong> with quality checks and logging</p></li>
<li><p>Follow <strong>replication best practices</strong> (validation, logging, fingerprinting)</p></li>
</ul>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<section id="running-in-google-colab">
<h3>Running in Google Colab<a class="headerlink" href="#running-in-google-colab" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Upload this notebook to Google Colab</p></li>
<li><p>Run the installation cell below</p></li>
<li><p>You’ll be prompted to enter your OpenAI API key</p></li>
</ol>
</section>
<section id="running-locally">
<h3>Running Locally<a class="headerlink" href="#running-locally" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Install requirements: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">openai</span> <span class="pre">pandas</span> <span class="pre">scikit-learn</span> <span class="pre">numpy</span></code></p></li>
<li><p>Set environment variable: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">OPENAI_API_KEY=&quot;your-key-here&quot;</span></code></p></li>
<li><p>Run notebook with Jupyter: <code class="docutils literal notranslate"><span class="pre">jupyter</span> <span class="pre">notebook</span> <span class="pre">week6_structured_annotation_colab.ipynb</span></code></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install required packages (uncomment if needed)</span>
<span class="c1"># !pip install -q &quot;openai&gt;=1.40.0&quot; pandas scikit-learn numpy</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hashlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">cohen_kappa_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">getpass</span>

<span class="c1"># Set your OpenAI API key</span>
<span class="c1"># For Colab: you&#39;ll be prompted to enter it</span>
<span class="c1"># For local: set OPENAI_API_KEY environment variable</span>
<span class="k">if</span> <span class="s2">&quot;OPENAI_API_KEY&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">getpass</span><span class="o">.</span><span class="n">getpass</span><span class="p">(</span><span class="s2">&quot;OpenAI API key: &quot;</span><span class="p">)</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">()</span>  <span class="c1"># reads OPENAI_API_KEY from environment</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✓ Setup complete!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>What this code does:</strong></p>
<p>Sets up the complete environment for production-grade LLM annotation:</p>
<p><strong>Key libraries:</strong></p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">openai</span></code></strong>: API access to GPT models</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">pandas</span></code></strong>: Tabular data manipulation (annotation results)</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></strong>: Validation metrics (Cohen’s kappa, confusion matrix)</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">hashlib</span></code></strong>: Model fingerprinting to detect API drift</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">datetime</span></code></strong>: Timestamping for reproducibility</p></li>
</ul>
<p><strong>Why this setup is more comprehensive than previous notebooks:</strong></p>
<ul class="simple">
<li><p>Includes validation metrics (Cohen’s kappa)</p></li>
<li><p>Supports model fingerprinting (detect when API changes)</p></li>
<li><p>Designed for research-grade reproducibility</p></li>
</ul>
<p><strong>When to use each metric:</strong></p>
<ul class="simple">
<li><p><strong>Cohen’s kappa</strong>: Inter-rater reliability (target: κ &gt; 0.80)</p></li>
<li><p><strong>Confusion matrix</strong>: Where disagreements occur</p></li>
<li><p><strong>Fingerprinting</strong>: Detect if model behavior changes over time</p></li>
</ul>
<p><strong>Security reminder:</strong> Use <code class="docutils literal notranslate"><span class="pre">getpass</span></code> for API keys, never hardcode them.</p>
<p><strong>Expected output:</strong> “✓ Setup complete!” - you’re ready for structured annotation workflows.</p>
</section>
</section>
<hr class="docutils" />
<section id="part-1-prompt-formatting-strategies">
<h2>Part 1: Prompt Formatting Strategies<a class="headerlink" href="#part-1-prompt-formatting-strategies" title="Link to this heading">#</a></h2>
<p>Before we get structured outputs, let’s review simple ways to format prompts for text annotation tasks.</p>
<section id="a-simple-f-string-prompting">
<h3>1A. Simple f-string Prompting<a class="headerlink" href="#a-simple-f-string-prompting" title="Link to this heading">#</a></h3>
<p>The most basic approach: use Python f-strings to insert text into a prompt template.</p>
<p><strong>What this code does:</strong></p>
<p>Demonstrates the <strong>simplest</strong> prompting approach using Python f-strings:</p>
<p><strong>How f-strings work:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f&quot;string</span> <span class="pre">with</span> <span class="pre">{variable}&quot;</span></code> inserts variable values directly</p></li>
<li><p>Simple, readable, familiar to Python developers</p></li>
</ul>
<p><strong>Key parameter: temperature=0</strong></p>
<ul class="simple">
<li><p>For annotation tasks, use temperature 0 (deterministic)</p></li>
<li><p>Same input = same output (critical for reproducibility)</p></li>
<li><p>Higher temperature (0.7+) is for creative tasks only</p></li>
</ul>
<p><strong>Limitations of this approach:</strong></p>
<ul class="simple">
<li><p>No structured output (returns free text)</p></li>
<li><p>Hard to parse programmatically</p></li>
<li><p>Model might add extra explanation</p></li>
<li><p>Not suitable for batch processing</p></li>
</ul>
<p><strong>When to use:</strong></p>
<ul class="simple">
<li><p>Quick prototyping</p></li>
<li><p>Interactive exploration</p></li>
<li><p>Single-shot annotations where you’ll read the output</p></li>
</ul>
<p><strong>For production:</strong> Use structured outputs (Approach 2 or 3 later in this notebook)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample political texts for annotation</span>
<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;We must invest in renewable energy now!&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Cut taxes and reduce business regulations&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Healthcare is a human right for all citizens&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Maintain current spending levels and balanced budget&quot;</span>
<span class="p">]</span>

<span class="c1"># Simple f-string approach</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Classify the political stance of this text as:</span>
<span class="s2">- Progressive</span>
<span class="s2">- Conservative</span>
<span class="s2">- Centrist</span>

<span class="s2">Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span>
<span class="s2">Stance:&quot;&quot;&quot;</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>  <span class="c1"># Deterministic for annotation</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stance: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>What this code does:</strong></p>
<p>Improves on f-strings by using <strong>reusable templates</strong> with <code class="docutils literal notranslate"><span class="pre">.format()</span></code>:</p>
<p><strong>Why templates are better:</strong></p>
<ul class="simple">
<li><p>Define prompt once, reuse for all texts</p></li>
<li><p>Ensures consistency across annotations</p></li>
<li><p>Easy to modify prompt for entire batch</p></li>
<li><p>Supports batch processing naturally</p></li>
</ul>
<p><strong>How <code class="docutils literal notranslate"><span class="pre">.format()</span></code> works:</strong></p>
<ul class="simple">
<li><p>Template contains <code class="docutils literal notranslate"><span class="pre">{variable_name}</span></code> placeholders</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.format(variable_name=value)</span></code> fills them in</p></li>
<li><p>More explicit than f-strings (clearer what’s being inserted)</p></li>
</ul>
<p><strong>Best practices for template prompts:</strong></p>
<ol class="arabic simple">
<li><p>Keep instructions consistent across all texts</p></li>
<li><p>Clearly define categories (Progressive/Conservative/Centrist)</p></li>
<li><p>Place variable at the end (reduces interference)</p></li>
<li><p>Use imperative tone (“Classify the…”) not questions</p></li>
</ol>
<p><strong>Still limited:</strong></p>
<ul class="simple">
<li><p>Output is free text, not structured</p></li>
<li><p>Need parsing logic to extract stance</p></li>
<li><p>Model might be verbose or inconsistent</p></li>
</ul>
<p><strong>Next steps:</strong> Add few-shot examples (next cell) or use JSON mode (Approach 3)</p>
</section>
<section id="b-reusable-template-with-format">
<h3>1B. Reusable Template with .format()<a class="headerlink" href="#b-reusable-template-with-format" title="Link to this heading">#</a></h3>
<p>For batch processing, create a template you can reuse across multiple texts.</p>
<p><strong>What this code does:</strong></p>
<p>Improves on f-strings by using <strong>reusable templates</strong> with <code class="docutils literal notranslate"><span class="pre">.format()</span></code>:</p>
<p><strong>Why templates are better:</strong></p>
<ul class="simple">
<li><p>Define prompt once, reuse for all texts</p></li>
<li><p>Ensures consistency across annotations</p></li>
<li><p>Easy to modify prompt for entire batch</p></li>
<li><p>Supports batch processing naturally</p></li>
</ul>
<p><strong>How <code class="docutils literal notranslate"><span class="pre">.format()</span></code> works:</strong></p>
<ul class="simple">
<li><p>Template contains <code class="docutils literal notranslate"><span class="pre">{variable_name}</span></code> placeholders</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.format(variable_name=value)</span></code> fills them in</p></li>
<li><p>More explicit than f-strings (clearer what’s being inserted)</p></li>
</ul>
<p><strong>Best practices for template prompts:</strong></p>
<ol class="arabic simple">
<li><p>Keep instructions consistent across all texts</p></li>
<li><p>Clearly define categories (Progressive/Conservative/Centrist)</p></li>
<li><p>Place variable at the end (reduces interference)</p></li>
<li><p>Use imperative tone (“Classify the…”) not questions</p></li>
</ol>
<p><strong>Still limited:</strong></p>
<ul class="simple">
<li><p>Output is free text, not structured</p></li>
<li><p>Need parsing logic to extract stance</p></li>
<li><p>Model might be verbose or inconsistent</p></li>
</ul>
<p><strong>Next steps:</strong> Add few-shot examples or use JSON mode (Part 2)</p>
<p><strong>What this code does:</strong></p>
<p>Demonstrates <strong>few-shot prompting</strong> - providing examples to guide the model:</p>
<p><strong>What is few-shot learning:</strong></p>
<ul class="simple">
<li><p>Show model 2-5 examples of input → output pairs</p></li>
<li><p>Model learns the pattern and applies it to new inputs</p></li>
<li><p>No fine-tuning required (examples in prompt only)</p></li>
</ul>
<p><strong>Why few-shot helps:</strong></p>
<ul class="simple">
<li><p><strong>Clarifies format:</strong> Shows exact output style you want</p></li>
<li><p><strong>Reduces ambiguity:</strong> Examples demonstrate edge cases</p></li>
<li><p><strong>Improves consistency:</strong> Model mimics example structure</p></li>
<li><p><strong>Domain adaptation:</strong> Examples can include domain jargon</p></li>
</ul>
<p><strong>Structure of few-shot prompts:</strong></p>
<ol class="arabic simple">
<li><p>Task description (brief)</p></li>
<li><p>Examples (2-5 is usually enough)</p>
<ul class="simple">
<li><p>Show diverse cases (not all similar)</p></li>
<li><p>Include format you want (here: “Text → Label”)</p></li>
</ul>
</li>
<li><p>New input to classify</p></li>
</ol>
<p><strong>How many examples to use:</strong></p>
<ul class="simple">
<li><p><strong>0-shot (zero-shot):</strong> No examples (what we did before)</p></li>
<li><p><strong>Few-shot (2-5):</strong> Most common, good balance</p></li>
<li><p><strong>Many-shot (10-100):</strong> For complex tasks or narrow domains</p></li>
</ul>
<p><strong>When few-shot is essential:</strong></p>
<ul class="simple">
<li><p>Narrow domain (not in training data)</p></li>
<li><p>Specific format required</p></li>
<li><p>Ambiguous category boundaries</p></li>
<li><p>Model is undershooting or overshooting</p></li>
</ul>
<p><strong>Cost consideration:</strong> Examples add tokens → higher cost. But often worth it for quality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Template approach for consistency</span>
<span class="n">STANCE_TEMPLATE</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Classify the political stance of this text as:</span>
<span class="s2">- Progressive</span>
<span class="s2">- Conservative</span>
<span class="s2">- Centrist</span>

<span class="s2">Text: </span><span class="si">{text}</span>
<span class="s2">Stance:&quot;&quot;&quot;</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">STANCE_TEMPLATE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>
    
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    
    <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span> <span class="s2">&quot;stance&quot;</span><span class="p">:</span> <span class="n">result</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;• </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ Annotated </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="si">}</span><span class="s2"> texts&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="c-few-shot-prompting">
<h3>1C. Few-Shot Prompting<a class="headerlink" href="#c-few-shot-prompting" title="Link to this heading">#</a></h3>
<p>Provide <strong>examples</strong> in the prompt to guide the model’s behavior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Few-shot template with examples</span>
<span class="n">FEW_SHOT_TEMPLATE</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Classify political stance as Progressive, Conservative, or Centrist.</span>

<span class="s2">Examples:</span>
<span class="s2">Text: &quot;Cut taxes and reduce regulations&quot; → Conservative</span>
<span class="s2">Text: &quot;Expand healthcare access for all&quot; → Progressive</span>
<span class="s2">Text: &quot;Maintain current spending levels&quot; → Centrist</span>

<span class="s2">Text: </span><span class="si">{text}</span><span class="s2"> →&quot;&quot;&quot;</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Protect traditional family values and limit government overreach&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">FEW_SHOT_TEMPLATE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Key advantages over Approach 1 (prompt-only):</strong></p>
<ul class="simple">
<li><p><strong>Guaranteed valid JSON:</strong> No “Here’s the JSON:” or markdown fences</p></li>
<li><p><strong>No retry logic needed:</strong> Works first time</p></li>
<li><p><strong>Same cost:</strong> No extra charge</p></li>
<li><p><strong>Simpler code:</strong> No complex parsing</p></li>
</ul>
<p><strong>Requirements:</strong></p>
<ul class="simple">
<li><p>Model must support JSON mode (GPT-4, GPT-3.5-turbo, GPT-4o do)</p></li>
<li><p>Must mention “JSON” in prompt (system or user message)</p></li>
</ul>
<p><strong>When to use:</strong></p>
<ul class="simple">
<li><p><strong>This is the recommended default approach</strong></p></li>
<li><p>Most annotation tasks (sentiment, topics, stance, etc.)</p></li>
<li><p>When you want flexible schema (any JSON structure)</p></li>
</ul>
<p><strong>Limitation:</strong></p>
<ul class="simple">
<li><p>No type validation (can’t enforce “confidence must be 0-1”)</p></li>
<li><p>For strict typing, use Approach 3</p></li>
</ul>
</section>
<section id="d-chain-of-thought-prompting">
<h3>1D. Chain-of-Thought Prompting<a class="headerlink" href="#d-chain-of-thought-prompting" title="Link to this heading">#</a></h3>
<p>Ask the model to <strong>explain its reasoning</strong> step-by-step before giving an answer.</p>
<p><strong>What this code does:</strong></p>
<p><strong>Approach 3 (JSON Mode)</strong> - The <strong>recommended approach</strong> for most annotation tasks:</p>
<p><strong>How it works:</strong></p>
<ul class="simple">
<li><p>Set <code class="docutils literal notranslate"><span class="pre">response_format={&quot;type&quot;:</span> <span class="pre">&quot;json_object&quot;}</span></code> in API call</p></li>
<li><p>API <strong>guarantees</strong> valid JSON output</p></li>
<li><p>Model cannot return prose or malformed JSON</p></li>
</ul>
<p><strong>Key advantages:</strong></p>
<ul class="simple">
<li><p><strong>99.9%+ reliability:</strong> Valid JSON guaranteed</p></li>
<li><p><strong>No examples needed:</strong> Saves tokens/cost</p></li>
<li><p><strong>Simple to use:</strong> Just one parameter</p></li>
<li><p><strong>Fast:</strong> No retry logic needed</p></li>
</ul>
<p><strong>Requirements:</strong></p>
<ol class="arabic simple">
<li><p>Must mention “JSON” in prompt (system or user message)</p></li>
<li><p>Model must support it (GPT-4, GPT-3.5-turbo, GPT-4o, etc.)</p></li>
<li><p>Temperature can be anything (0 for consistency)</p></li>
</ol>
<p><strong>How to structure the request:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">messages</span><span class="o">=</span><span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are X. Return valid JSON only.&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Task: ... Return JSON with keys: ...&quot;</span><span class="p">}</span>
<span class="p">]</span>
<span class="n">response_format</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_object&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p><strong>Compared to other approaches:</strong></p>
<ul class="simple">
<li><p><strong>vs Prompt-only:</strong> Much more reliable (99% vs 70%)</p></li>
<li><p><strong>vs Few-shot:</strong> Simpler and cheaper (no examples needed)</p></li>
<li><p><strong>vs Function calling:</strong> More flexible schema (next cell)</p></li>
</ul>
<p><strong>When to use JSON mode:</strong></p>
<ul class="simple">
<li><p>Most annotation tasks (sentiment, topics, stance, etc.)</p></li>
<li><p>When you want flexibility in schema</p></li>
<li><p>When you don’t need enum validation</p></li>
</ul>
<p><strong>When to use Function calling instead:</strong></p>
<ul class="simple">
<li><p>Need strict type checking (enums, number ranges)</p></li>
<li><p>Complex nested schemas</p></li>
<li><p>Want IDE autocomplete on schema</p></li>
</ul>
<p><strong>Cost:</strong> Same as normal API calls - no extra charge for JSON mode.</p>
<p><strong>What this code does:</strong></p>
<p>Implements <strong>chain-of-thought (CoT) prompting</strong> - asking the model to reason step-by-step:</p>
<p><strong>What is chain-of-thought:</strong></p>
<ul class="simple">
<li><p>Ask model to show its reasoning before giving final answer</p></li>
<li><p>Originated in Wei et al. (2022) “Chain-of-Thought Prompting Elicits Reasoning”</p></li>
<li><p>Dramatically improves performance on reasoning tasks</p></li>
</ul>
<p><strong>Why CoT helps:</strong></p>
<ul class="simple">
<li><p><strong>Better accuracy:</strong> Especially on multi-step problems</p></li>
<li><p><strong>Transparency:</strong> Can see model’s logic</p></li>
<li><p><strong>Debugging:</strong> Identify where reasoning goes wrong</p></li>
<li><p><strong>Trust:</strong> Justifications build confidence in annotations</p></li>
</ul>
<p><strong>Temperature: 0.3 (slightly higher)</strong></p>
<ul class="simple">
<li><p>CoT needs some creativity for explanations</p></li>
<li><p>But still low enough for consistency</p></li>
<li><p>Trade-off between rigid and random</p></li>
</ul>
<p><strong>When to use CoT:</strong></p>
<ul class="simple">
<li><p>Complex classification (multiple factors to consider)</p></li>
<li><p>Need justifications for auditing</p></li>
<li><p>Debugging misclassifications</p></li>
<li><p>Training human annotators (shows reasoning process)</p></li>
</ul>
<p><strong>When NOT to use CoT:</strong></p>
<ul class="simple">
<li><p>Simple tasks (adds unnecessary tokens/cost)</p></li>
<li><p>Speed critical (CoT is slower)</p></li>
<li><p>Don’t need explanations</p></li>
</ul>
<p><strong>Cost consideration:</strong> CoT generates more tokens (reasoning + answer), so ~2-3x more expensive than direct classification.</p>
<p><strong>Alternative:</strong> Use JSON mode (Part 2) to get structured reasoning + classification</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">COT_TEMPLATE</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Classify the stance and explain your reasoning.</span>

<span class="s2">Text: </span><span class="si">{text}</span>

<span class="s2">Think step-by-step:</span>
<span class="s2">1. What policy domain is this?</span>
<span class="s2">2. What values does it express?</span>
<span class="s2">3. What stance does this suggest?</span>

<span class="s2">Reasoning:</span>
<span class="s2">Stance:&quot;&quot;&quot;</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Invest heavily in public education and teacher salaries&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">COT_TEMPLATE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.3</span>  <span class="c1"># Slightly higher for reasoning</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Chain-of-Thought Response:</span><span class="se">\n</span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ CoT provides reasoning steps before final classification&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Key advantages over Approach 2 (JSON mode):</strong></p>
<ul class="simple">
<li><p><strong>Type validation:</strong> <code class="docutils literal notranslate"><span class="pre">&quot;type&quot;:</span> <span class="pre">&quot;number&quot;</span></code> ensures numeric values</p></li>
<li><p><strong>Enum constraints:</strong> <code class="docutils literal notranslate"><span class="pre">&quot;enum&quot;:</span> <span class="pre">[&quot;A&quot;,</span> <span class="pre">&quot;B&quot;,</span> <span class="pre">&quot;C&quot;]</span></code> restricts to specific values</p></li>
<li><p><strong>Required fields:</strong> <code class="docutils literal notranslate"><span class="pre">&quot;required&quot;:</span> <span class="pre">[...]</span></code> ensures all fields present</p></li>
<li><p><strong>Nested structures:</strong> Complex object hierarchies with validation</p></li>
</ul>
<p><strong>The schema format:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;analyze_stance&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;stance&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="s2">&quot;enum&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Progressive&quot;</span><span class="p">,</span> <span class="s2">&quot;Conservative&quot;</span><span class="p">,</span> <span class="s2">&quot;Centrist&quot;</span><span class="p">]},</span>
                <span class="s2">&quot;confidence&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;number&quot;</span><span class="p">},</span>  <span class="c1"># Must be a number</span>
                <span class="s2">&quot;reasoning&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;stance&quot;</span><span class="p">,</span> <span class="s2">&quot;confidence&quot;</span><span class="p">,</span> <span class="s2">&quot;reasoning&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>When to use:</strong></p>
<ul class="simple">
<li><p>Production systems needing validation guarantees</p></li>
<li><p>Strict category sets (must be one of 3 options, not free text)</p></li>
<li><p>Type safety important (confidence must be number, not string)</p></li>
<li><p>Complex nested schemas</p></li>
</ul>
<p><strong>vs JSON mode:</strong></p>
<ul class="simple">
<li><p><strong>JSON mode:</strong> Flexible, simpler, good default</p></li>
<li><p><strong>Function calling:</strong> Stricter, more setup, better for production</p></li>
</ul>
<p><strong>Cost:</strong> Same as JSON mode - no extra charge</p>
</section>
</section>
<hr class="docutils" />
<section id="part-2-three-approaches-to-getting-structured-outputs-json">
<h2>Part 2: Three Approaches to Getting Structured Outputs (JSON)<a class="headerlink" href="#part-2-three-approaches-to-getting-structured-outputs-json" title="Link to this heading">#</a></h2>
<p>When you want the LLM to return structured data (like JSON with specific keys), you have <strong>three main approaches</strong>. Each has different reliability and complexity.</p>
<p><strong>Why structured outputs matter:</strong></p>
<ul class="simple">
<li><p>Easy to parse programmatically (no regex needed)</p></li>
<li><p>Can extract multiple fields (label, confidence, reasoning)</p></li>
<li><p>Essential for batch annotation pipelines</p></li>
<li><p>Enables downstream analysis</p></li>
</ul>
<p>Let’s compare the three approaches from simplest to most reliable.</p>
<section id="approach-1-prompt-for-json-simplest-least-reliable">
<h3>Approach 1: Prompt for JSON (Simplest, Least Reliable)<a class="headerlink" href="#approach-1-prompt-for-json-simplest-least-reliable" title="Link to this heading">#</a></h3>
<p><strong>How it works:</strong> Just ask the LLM to return JSON in your prompt. No special API parameters.</p>
<p><strong>What you do:</strong></p>
<ul class="simple">
<li><p>Include “Return JSON” in your prompt</p></li>
<li><p>Hope the model follows instructions</p></li>
<li><p>Try to parse the response with <code class="docutils literal notranslate"><span class="pre">json.loads()</span></code></p></li>
</ul>
<p><strong>Success rate:</strong> ~60-80% (varies by model and complexity)</p>
</section>
<section id="approach-2-json-mode-api-parameter-recommended-for-most-tasks">
<h3>Approach 2: JSON Mode API Parameter (Recommended for Most Tasks)<a class="headerlink" href="#approach-2-json-mode-api-parameter-recommended-for-most-tasks" title="Link to this heading">#</a></h3>
<p><strong>How it works:</strong> Use <code class="docutils literal notranslate"><span class="pre">response_format={&quot;type&quot;:</span> <span class="pre">&quot;json_object&quot;}</span></code> in your API call. The API <strong>guarantees</strong> valid JSON.</p>
<p><strong>What you do:</strong></p>
<ol class="arabic simple">
<li><p>Add <code class="docutils literal notranslate"><span class="pre">response_format={&quot;type&quot;:</span> <span class="pre">&quot;json_object&quot;}</span></code> parameter</p></li>
<li><p>Mention “JSON” somewhere in your prompt</p></li>
<li><p>Parse the response - it will always be valid JSON</p></li>
</ol>
<p><strong>Success rate:</strong> ~99.9% (valid JSON guaranteed by API)</p>
<p><strong>What this code does:</strong></p>
<p>Implements <strong>robust JSON extraction with retry logic</strong> for when parsing fails:</p>
<p><strong>The three-phase approach:</strong></p>
<p><strong>Phase 1: Initial request</strong></p>
<ul class="simple">
<li><p>Clear instructions: “Return only a JSON object”</p></li>
<li><p>Low temperature (0.1) for consistency</p></li>
<li><p>Specify exact schema in prompt</p></li>
</ul>
<p><strong>Phase 2: Parse attempt</strong></p>
<ul class="simple">
<li><p>Try <code class="docutils literal notranslate"><span class="pre">json.loads()</span></code> on response</p></li>
<li><p>If successful → return result</p></li>
<li><p>If fails → proceed to Phase 3</p></li>
</ul>
<p><strong>Phase 3: Retry with correction</strong></p>
<ul class="simple">
<li><p>Send original prompt + failed response + correction instruction</p></li>
<li><p>Use temperature 0.0 (most deterministic)</p></li>
<li><p>Try parsing again</p></li>
<li><p>If still fails → raise exception for manual review</p></li>
</ul>
<p><strong>Key features:</strong></p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">max_retries</span></code> parameter:</strong> Control how many attempts (1 is usually enough)</p></li>
<li><p><strong>Error logging:</strong> Print failed output for debugging</p></li>
<li><p><strong>Gradual temperature reduction:</strong> 0.1 → 0.0 increases determinism</p></li>
</ul>
<p><strong>When to use retry logic:</strong></p>
<ul class="simple">
<li><p>Using Approach 1 or 2 (not JSON mode)</p></li>
<li><p>Critical annotations (can’t skip failures)</p></li>
<li><p>Debugging schema issues</p></li>
</ul>
<p><strong>When NOT needed:</strong></p>
<ul class="simple">
<li><p>Using JSON mode or function calling (already reliable)</p></li>
<li><p>Batch processing (skip failures, review later)</p></li>
</ul>
<p><strong>Success rates:</strong></p>
<ul class="simple">
<li><p>Without retry: ~85% (prompt-only) to ~95% (few-shot)</p></li>
<li><p>With retry: ~98%</p></li>
<li><p>Remaining 2%: Usually schema issues or model limitations</p></li>
</ul>
<p><strong>Best practice:</strong> Use JSON mode (Approach 3) to avoid needing this complexity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Cut taxes and reduce regulations&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You output ONLY valid JSON with keys: stance, confidence, reasoning.</span>

<span class="s2">Example:</span>
<span class="s2">Input: Expand healthcare access for all</span>
<span class="s2">Output: {{&quot;stance&quot;:&quot;Progressive&quot;,&quot;confidence&quot;:0.9,&quot;reasoning&quot;:&quot;Universal healthcare is progressive policy&quot;}}</span>

<span class="s2">Example:</span>
<span class="s2">Input: Maintain current spending levels</span>
<span class="s2">Output: {{&quot;stance&quot;:&quot;Centrist&quot;,&quot;confidence&quot;:0.8,&quot;reasoning&quot;:&quot;Status quo signals moderate position&quot;}}</span>

<span class="s2">Now do the same:</span>
<span class="s2">Input: </span><span class="si">{input}</span>
<span class="s2">Output:</span>
<span class="s2">&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">llm_call</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Raw output:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Parsing JSON...&quot;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✓ Successfully parsed!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="approach-3-provider-json-mode-more-reliable">
<h3>Approach 3: Provider JSON Mode (More Reliable)<a class="headerlink" href="#approach-3-provider-json-mode-more-reliable" title="Link to this heading">#</a></h3>
<p>Use the API’s <strong>JSON mode</strong> to <strong>force</strong> valid JSON output. This is the recommended approach for most annotation tasks.</p>
<p><strong>Why this approach often fails:</strong></p>
<p>Common problems:</p>
<ol class="arabic simple">
<li><p><strong>Extra text:</strong> “Here’s the JSON: {…}”</p></li>
<li><p><strong>Markdown fences:</strong> ```json {…} ```</p></li>
<li><p><strong>Prose instead:</strong> “The stance is Progressive because…”</p></li>
<li><p><strong>Malformed JSON:</strong> Trailing commas, unquoted keys</p></li>
</ol>
<p><strong>When to use:</strong></p>
<ul class="simple">
<li><p>Quick prototyping only</p></li>
<li><p>Not recommended for production</p></li>
</ul>
<p><strong>Better alternatives:</strong> Approach 2 (JSON mode API parameter) or Approach 3 (function calling)</p>
<p><strong>What this code does:</strong></p>
<p>Implements <strong>production-grade batch annotation</strong> with comprehensive logging and error handling:</p>
<p><strong>The <code class="docutils literal notranslate"><span class="pre">annotate_text</span></code> function:</strong></p>
<ul class="simple">
<li><p>Single-text annotation with JSON mode</p></li>
<li><p>Returns parsed dictionary</p></li>
<li><p>Extended schema: stance, confidence, reasoning, <strong>policy_domain</strong></p></li>
</ul>
<p><strong>The <code class="docutils literal notranslate"><span class="pre">batch_annotate</span></code> function workflow:</strong></p>
<ol class="arabic simple">
<li><p>Loop through all texts with progress indicator</p></li>
<li><p>Try to annotate each text</p></li>
<li><p>On success: Add metadata (model, timestamp, success=True)</p></li>
<li><p>On failure: Log error, mark success=False, set fields to None</p></li>
<li><p>Return pandas DataFrame for analysis</p></li>
</ol>
<p><strong>Key metadata fields:</strong></p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">model</span></code>:</strong> Track which model annotated (for comparison)</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">timestamp</span></code>:</strong> When annotation happened (ISO format)</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">success</span></code>:</strong> Boolean flag for filtering</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">error</span></code>:</strong> Error message if failed</p></li>
</ul>
<p><strong>Why comprehensive logging matters:</strong></p>
<ul class="simple">
<li><p><strong>Reproducibility:</strong> Can trace back to exact API call</p></li>
<li><p><strong>Debugging:</strong> Identify systematic failures</p></li>
<li><p><strong>Cost tracking:</strong> Know how many API calls made</p></li>
<li><p><strong>Validation:</strong> Compare annotations across time</p></li>
</ul>
<p><strong>Quality summary:</strong></p>
<ul class="simple">
<li><p>Print success rate at end</p></li>
<li><p>Identify low-confidence annotations</p></li>
<li><p>Flag failures for manual review</p></li>
</ul>
<p><strong>How to use:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">batch_annotate</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">)</span>
<span class="c1"># Filter successful</span>
<span class="n">successful</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;success&#39;</span><span class="p">]]</span>
<span class="c1"># Check low confidence</span>
<span class="n">review</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;confidence&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.7</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>Best practices:</strong></p>
<ul class="simple">
<li><p>Always wrap API calls in try/except</p></li>
<li><p>Log everything (model, time, prompt, response)</p></li>
<li><p>Return structured DataFrames (easier analysis)</p></li>
<li><p>Calculate success rate and quality metrics</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Protect traditional family values&quot;</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
         <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a political analyst. Return valid JSON only.&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
         <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Analyze political stance: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Return JSON with stance, confidence, reasoning.&quot;</span><span class="p">}</span>
    <span class="p">],</span>
    <span class="n">response_format</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_object&quot;</span><span class="p">},</span>  <span class="c1"># Force JSON mode</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✓ JSON mode guarantees valid JSON&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define function schema with typed arguments</span>
<span class="n">tools</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;analyze_stance&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Return structured political stance analysis&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;stance&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;enum&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Progressive&quot;</span><span class="p">,</span> <span class="s2">&quot;Conservative&quot;</span><span class="p">,</span> <span class="s2">&quot;Centrist&quot;</span><span class="p">]</span>
                <span class="p">},</span>
                <span class="s2">&quot;confidence&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;number&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Confidence score from 0 to 1&quot;</span>
                <span class="p">},</span>
                <span class="s2">&quot;reasoning&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Brief explanation of the classification&quot;</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;stance&quot;</span><span class="p">,</span> <span class="s2">&quot;confidence&quot;</span><span class="p">,</span> <span class="s2">&quot;reasoning&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}]</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Expand social safety nets&quot;</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Analyze: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}],</span>
    <span class="n">tools</span><span class="o">=</span><span class="n">tools</span><span class="p">,</span>
    <span class="n">tool_choice</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="c1"># Extract structured arguments</span>
<span class="n">call</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✓ Function calling provides strongest guarantees&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Function called: </span><span class="si">{</span><span class="n">call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><strong>What this code does:</strong></p>
<p>Implements <strong>mixture of experts (MoE)</strong> - using multiple models and aggregating predictions:</p>
<p><strong>Theoretical foundation:</strong></p>
<ul class="simple">
<li><p>Kraft et al. (2024): “Mixture-of-Experts Approach to LLM-Based Political Ideology Scaling”</p></li>
<li><p>Ensemble methods reduce variance and bias</p></li>
<li><p>Multiple perspectives increase reliability</p></li>
</ul>
<p><strong>The approach:</strong></p>
<ol class="arabic simple">
<li><p>Get ideological score from each model (-1 to +1)</p></li>
<li><p>Aggregate using mean, median, std</p></li>
<li><p>Use std as uncertainty measure</p></li>
</ol>
<p><strong>The <code class="docutils literal notranslate"><span class="pre">get_stance_score</span></code> function:</strong></p>
<ul class="simple">
<li><p>Asks for numeric score (not categorical)</p></li>
<li><p>-1 = most progressive</p></li>
<li><p>+1 = most conservative</p></li>
<li><p>0 = centrist</p></li>
<li><p>Returns float for aggregation</p></li>
</ul>
<p><strong>The <code class="docutils literal notranslate"><span class="pre">ensemble_stance</span></code> function:</strong></p>
<ul class="simple">
<li><p>Calls multiple models</p></li>
<li><p>Handles failures gracefully (skip failed models)</p></li>
<li><p>Computes aggregate statistics</p></li>
<li><p>Returns uncertainty metrics</p></li>
</ul>
<p><strong>Key metrics:</strong></p>
<ul class="simple">
<li><p><strong>Mean:</strong> Central tendency</p></li>
<li><p><strong>Median:</strong> Robust to outliers</p></li>
<li><p><strong>Std:</strong> Agreement/uncertainty</p>
<ul>
<li><p>Low std (&lt;0.3) = high agreement</p></li>
<li><p>High std (&gt;0.6) = low agreement = review needed</p></li>
</ul>
</li>
</ul>
<p><strong>When to use MoE:</strong></p>
<ul class="simple">
<li><p>High-stakes decisions (publication-critical)</p></li>
<li><p>Ambiguous/contested texts</p></li>
<li><p>Want confidence intervals</p></li>
<li><p>Have budget for multiple API calls</p></li>
</ul>
<p><strong>Cost consideration:</strong></p>
<ul class="simple">
<li><p>N models × cost per call</p></li>
<li><p>3 models = 3× cost (but usually worth it for quality)</p></li>
</ul>
<p><strong>Alternative aggregation:</strong></p>
<ul class="simple">
<li><p>Majority vote (for categorical)</p></li>
<li><p>Weighted average (weight by model quality)</p></li>
<li><p>Bayesian model combination</p></li>
</ul>
</section>
<section id="comparison-summary">
<h3>Comparison Summary<a class="headerlink" href="#comparison-summary" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">comparison_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;Approach&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;1. Prompt for JSON&quot;</span><span class="p">,</span>
        <span class="s2">&quot;2. JSON Mode (API)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;3. Function Calling&quot;</span>
    <span class="p">],</span>
    <span class="s2">&quot;Reliability&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;60-80%&quot;</span><span class="p">,</span>
        <span class="s2">&quot;99.9%&quot;</span><span class="p">,</span>
        <span class="s2">&quot;99.9%&quot;</span>
    <span class="p">],</span>
    <span class="s2">&quot;Type Safety&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;None&quot;</span><span class="p">,</span>
        <span class="s2">&quot;None&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Full&quot;</span>
    <span class="p">],</span>
    <span class="s2">&quot;Complexity&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Lowest&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Low&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Medium&quot;</span>
    <span class="p">],</span>
    <span class="s2">&quot;When to Use&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">&quot;Prototyping only&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Most tasks (default)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Production systems&quot;</span>
    <span class="p">]</span>
<span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="n">comparison_df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">💡 **Recommendation for novices:**&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Start with Approach 2 (JSON Mode) - reliable and simple&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">💡 **For production systems:**&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Use Approach 3 (Function Calling) if you need type validation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="part-3-robust-json-extraction">
<h2>Part 3: Robust JSON Extraction<a class="headerlink" href="#part-3-robust-json-extraction" title="Link to this heading">#</a></h2>
<p>Sometimes JSON parsing fails. Here’s how to handle errors gracefully with <strong>retry logic</strong>.</p>
<p><strong>What this code does:</strong></p>
<p>Implements <strong>comprehensive logging</strong> for full reproducibility of LLM annotations:</p>
<p><strong>Why complete logging is essential:</strong></p>
<ul class="simple">
<li><p><strong>Reproducibility:</strong> Others can replicate your exact setup</p></li>
<li><p><strong>Debugging:</strong> Trace errors back to source</p></li>
<li><p><strong>Auditing:</strong> See exactly what model was asked</p></li>
<li><p><strong>Cost tracking:</strong> Monitor token usage</p></li>
<li><p><strong>Drift detection:</strong> Compare results over time</p></li>
</ul>
<p><strong>What to log:</strong></p>
<ol class="arabic simple">
<li><p><strong>Timestamp:</strong> When annotation happened (ISO 8601 format)</p></li>
<li><p><strong>Input:</strong> Original text</p></li>
<li><p><strong>Model:</strong> Exact version (e.g., “gpt-4-0613”, not just “gpt-4”)</p></li>
<li><p><strong>Parameters:</strong> Temperature, seed, top_p, etc.</p></li>
<li><p><strong>Prompt:</strong> Exact prompt sent (system + user)</p></li>
<li><p><strong>Response:</strong> Complete model output</p></li>
<li><p><strong>Usage:</strong> Token counts (prompt, completion, total)</p></li>
<li><p><strong>Metadata:</strong> Finish reason, API version</p></li>
</ol>
<p><strong>The <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter:</strong></p>
<ul class="simple">
<li><p>Available in some OpenAI models (GPT-4, GPT-4o)</p></li>
<li><p>Makes sampling deterministic</p></li>
<li><p>Same (model + prompt + seed + temp) = same output</p></li>
<li><p>Critical for reproducibility</p></li>
</ul>
<p><strong>Best practices:</strong></p>
<ul class="simple">
<li><p>Pin model version: Use “gpt-4-0613” not “gpt-4”</p></li>
<li><p>Always log seed and temperature</p></li>
<li><p>Store logs as JSONL (one JSON object per line)</p></li>
<li><p>Include git commit hash if code changes</p></li>
<li><p>Log API response headers (rate limits, etc.)</p></li>
</ul>
<p><strong>How to use logs:</strong></p>
<ul class="simple">
<li><p>Debug failures by inspecting prompt</p></li>
<li><p>Calculate cost from token counts</p></li>
<li><p>Verify reproducibility by re-running with same params</p></li>
<li><p>Track model drift by comparing same prompts over time</p></li>
</ul>
<p><strong>Storage recommendation:</strong> Save to file, not just print</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clear instructions for JSON-only output</span>
<span class="n">INSTRUCTIONS</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s1">&#39;Return only a JSON object like this:</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="s1">&#39;{&quot;stance&quot;:&quot;Progressive|Conservative|Centrist|null&quot;,&#39;</span>
    <span class="s1">&#39;&quot;confidence&quot;:0-1,&quot;reasoning&quot;:&quot;brief&quot;}</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="s1">&#39;Do not add any extra text.&#39;</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_labels_robust</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span> <span class="n">max_retries</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Robust JSON extraction with error handling and retry logic.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        text: Text to annotate</span>
<span class="sd">        model: Model name</span>
<span class="sd">        max_retries: Number of retry attempts on parse failure</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        dict: Parsed JSON result</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1) Initial request with low temperature</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">INSTRUCTIONS</span><span class="si">}</span><span class="se">\n\n</span><span class="s1">Text: &quot;</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s1">&quot;&#39;</span>
    
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span>  <span class="c1"># Low temp for consistency</span>
    <span class="p">)</span>
    
    <span class="n">output</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    
    <span class="c1"># 2) Try to parse as JSON</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;⚠ Parse failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Raw output: </span><span class="si">{</span><span class="n">output</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">max_retries</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># 3) Retry with correction prompt</span>
            <span class="n">fix_prompt</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;That was not valid JSON. Please send ONLY the JSON object, &quot;</span>
                <span class="s2">&quot;nothing else. No explanations, no markdown fences.&quot;</span>
            <span class="p">)</span>
            
            <span class="n">retry_response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">output</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">fix_prompt</span><span class="p">}</span>
                <span class="p">],</span>
                <span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span>  <span class="c1"># Zero temp for retry</span>
            <span class="p">)</span>
            
            <span class="n">retry_output</span> <span class="o">=</span> <span class="n">retry_response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Retry output: </span><span class="si">{</span><span class="n">retry_output</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s2">...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">retry_output</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✗ Parse failed after retry&quot;</span><span class="p">)</span>
                <span class="k">raise</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span>

<span class="c1"># Test cases</span>
<span class="n">test_texts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;We must expand Medicare to cover everyone&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Cut taxes and reduce government spending&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Maintain balanced approach to fiscal policy&quot;</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing robust extraction with retry logic:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_texts</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">get_labels_robust</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✓ Success: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;stance&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> (confidence: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;confidence&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">)</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✗ Failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>What this code does:</strong></p>
<p>Implements <strong>model fingerprinting</strong> to detect when API behavior changes (API drift):</p>
<p><strong>What is API drift:</strong></p>
<ul class="simple">
<li><p>Model providers update models without warning</p></li>
<li><p>“gpt-4” might point to different weights next month</p></li>
<li><p>Causes non-reproducibility issues</p></li>
<li><p>Your results today ≠ results tomorrow</p></li>
</ul>
<p><strong>How fingerprinting works:</strong></p>
<ol class="arabic simple">
<li><p>Create a small test set (5-10 prompts)</p></li>
<li><p>Run them through model with fixed seed and temperature</p></li>
<li><p>Hash the concatenated responses (SHA256)</p></li>
<li><p>Save this fingerprint</p></li>
<li><p>Periodically re-run and compare hashes</p></li>
</ol>
<p><strong>The <code class="docutils literal notranslate"><span class="pre">model_fingerprint</span></code> function:</strong></p>
<ul class="simple">
<li><p>Takes model name and test prompts</p></li>
<li><p>Uses temperature=0 and seed for determinism</p></li>
<li><p>Concatenates all responses</p></li>
<li><p>Computes SHA256 hash (deterministic)</p></li>
<li><p>Returns 64-character hex string</p></li>
</ul>
<p><strong>When fingerprint changes:</strong></p>
<ul class="simple">
<li><p>Model has been updated (weights changed)</p></li>
<li><p>API behavior changed</p></li>
<li><p>Your previous results may not be replicable</p></li>
<li><p>Need to re-run annotations or document drift</p></li>
</ul>
<p><strong>Best practices:</strong></p>
<ol class="arabic simple">
<li><p><strong>Create fingerprint at start:</strong> Before annotating corpus</p></li>
<li><p><strong>Check periodically:</strong> Weekly or monthly</p></li>
<li><p><strong>Store with results:</strong> Save fingerprint with annotations</p></li>
<li><p><strong>Document changes:</strong> Note when drift detected</p></li>
<li><p><strong>Use versioned models:</strong> “gpt-4-0613” vs “gpt-4”</p></li>
</ol>
<p><strong>How often does drift happen:</strong></p>
<ul class="simple">
<li><p>Unversioned models (“gpt-4”): Monthly</p></li>
<li><p>Versioned models (“gpt-4-0613”): Rarely (usually stable)</p></li>
<li><p>Open-source models: Never (fixed weights)</p></li>
</ul>
<p><strong>Recommendation:</strong> Always use versioned models for research</p>
</section>
<hr class="docutils" />
<section id="part-4-batch-annotation">
<h2>Part 4: Batch Annotation<a class="headerlink" href="#part-4-batch-annotation" title="Link to this heading">#</a></h2>
<p>Annotating multiple texts efficiently with <strong>logging</strong> and <strong>quality checks</strong>.</p>
<p><strong>What this code does:</strong></p>
<p>Measures <strong>agreement between human and LLM annotations</strong> using standard metrics:</p>
<p><strong>Why validation is critical:</strong></p>
<ul class="simple">
<li><p>LLMs can be systematically biased</p></li>
<li><p>Need to know if LLM matches human judgment</p></li>
<li><p>Required for publication in most venues</p></li>
<li><p>Establishes annotation quality</p></li>
</ul>
<p><strong>Cohen’s Kappa (κ):</strong></p>
<ul class="simple">
<li><p>Measures inter-rater reliability (agreement corrected for chance)</p></li>
<li><p>Range: -1 to +1 (usually 0 to 1)</p></li>
<li><p><strong>Interpretation:</strong></p>
<ul>
<li><p>κ &gt; 0.80: Substantial agreement (excellent)</p></li>
<li><p>κ &gt; 0.60: Moderate agreement (acceptable)</p></li>
<li><p>κ &lt; 0.60: Questionable (needs work)</p></li>
</ul>
</li>
<li><p>Formula accounts for chance agreement</p></li>
</ul>
<p><strong>Accuracy:</strong></p>
<ul class="simple">
<li><p>Simple: % of matching labels</p></li>
<li><p>Doesn’t account for chance</p></li>
<li><p>Can be misleading with imbalanced classes</p></li>
</ul>
<p><strong>Confusion Matrix:</strong></p>
<ul class="simple">
<li><p>Shows where disagreements occur</p></li>
<li><p>Rows = human labels</p></li>
<li><p>Cols = LLM labels</p></li>
<li><p>Diagonal = agreements</p></li>
<li><p>Off-diagonal = disagreements</p></li>
</ul>
<p><strong>How to use in practice:</strong></p>
<ol class="arabic simple">
<li><p><strong>Validation set:</strong> Human-annotate 100-200 texts</p></li>
<li><p><strong>LLM annotation:</strong> Annotate same texts with LLM</p></li>
<li><p><strong>Calculate κ:</strong> Use <code class="docutils literal notranslate"><span class="pre">cohen_kappa_score()</span></code></p></li>
<li><p><strong>Analyze errors:</strong> Check confusion matrix</p></li>
<li><p><strong>Iterate:</strong> If κ &lt; 0.80, refine prompt and repeat</p></li>
</ol>
<p><strong>Target thresholds for publication:</strong></p>
<ul class="simple">
<li><p>Minimum: κ &gt; 0.70</p></li>
<li><p>Good: κ &gt; 0.80</p></li>
<li><p>Excellent: κ &gt; 0.90</p></li>
</ul>
<p><strong>Cost saving:</strong> Once validated, can annotate full corpus with LLM</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample corpus for batch annotation</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;We need stronger borders and immigration control&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Healthcare is a human right for all&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Balance the budget through moderate tax reform&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Invest in renewable energy infrastructure&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Cut regulations on small businesses&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Expand access to affordable childcare&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Maintain current defense spending levels&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Protect voting rights and access&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Reduce corporate tax rates&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Fund public education and teacher salaries&quot;</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Corpus: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span><span class="si">}</span><span class="s2"> political statements&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>What this code does:</strong></p>
<p>Creates a <strong>promptbook</strong> - a comprehensive documentation artifact for reproducible LLM research:</p>
<p><strong>What is a promptbook:</strong></p>
<ul class="simple">
<li><p>Single JSON file documenting entire annotation pipeline</p></li>
<li><p>Analogous to lab notebook in experimental research</p></li>
<li><p>Enables exact replication by other researchers</p></li>
<li><p>Required by some journals (e.g., Nature family)</p></li>
</ul>
<p><strong>What to include:</strong></p>
<ol class="arabic simple">
<li><p><strong>Task description:</strong> What you’re annotating</p></li>
<li><p><strong>Model details:</strong> Exact version, provider, parameters</p></li>
<li><p><strong>Prompts:</strong> Full system and user messages</p></li>
<li><p><strong>Output schema:</strong> Structure of responses</p></li>
<li><p><strong>Validation:</strong> Human agreement metrics (Cohen’s κ)</p></li>
<li><p><strong>Fingerprint:</strong> Hash for detecting drift</p></li>
<li><p><strong>Metadata:</strong> Date, version, notes</p></li>
</ol>
<p><strong>Why this matters for reproducibility:</strong></p>
<ul class="simple">
<li><p>Someone with your promptbook can replicate exactly</p></li>
<li><p>Shows transparency about model and prompts</p></li>
<li><p>Documents validation against human labels</p></li>
<li><p>Tracks when model behavior changes (fingerprint)</p></li>
</ul>
<p><strong>Best practices:</strong></p>
<ol class="arabic simple">
<li><p><strong>Version control:</strong> Increment version when prompts change</p></li>
<li><p><strong>Git integration:</strong> Include git commit hash</p></li>
<li><p><strong>Store with data:</strong> Save alongside annotations</p></li>
<li><p><strong>Share openly:</strong> Publish with paper (supplementary materials)</p></li>
<li><p><strong>Update regularly:</strong> New fingerprint each month</p></li>
</ol>
<p><strong>What to do with promptbook:</strong></p>
<ul class="simple">
<li><p>Include in paper’s methods section</p></li>
<li><p>Upload to OSF/Dataverse with data</p></li>
<li><p>Reference in computational appendix</p></li>
<li><p>Use for internal documentation</p></li>
</ul>
<p><strong>Publication requirements:</strong></p>
<ul class="simple">
<li><p>Many journals now require computational reproducibility</p></li>
<li><p>Promptbook satisfies most requirements</p></li>
<li><p>Some journals have templates (adapt this structure)</p></li>
</ul>
<p><strong>This establishes research-grade annotation practices</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">annotate_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Annotate a single text with structured output&quot;&quot;&quot;</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
             <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a political analyst. Return valid JSON only.&quot;</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
             <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Analyze this political text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span>

<span class="s2">Return JSON with keys:</span>
<span class="s2">- stance (Progressive/Conservative/Centrist)</span>
<span class="s2">- confidence (0-1)</span>
<span class="s2">- reasoning (brief explanation)</span>
<span class="s2">- policy_domain (e.g., healthcare, economy, education)&quot;&quot;&quot;</span><span class="p">}</span>
        <span class="p">],</span>
        <span class="n">response_format</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_object&quot;</span><span class="p">},</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">batch_annotate</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Annotate multiple texts with error handling and logging&quot;&quot;&quot;</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Annotating </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span><span class="si">}</span><span class="s2"> texts with </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2">...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span><span class="si">}</span><span class="s2">] </span><span class="si">{</span><span class="n">text</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="n">annotation</span> <span class="o">=</span> <span class="n">annotate_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">)</span>
            <span class="n">annotation</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
            <span class="n">annotation</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span>
            <span class="n">annotation</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">isoformat</span><span class="p">()</span>
            <span class="n">annotation</span><span class="p">[</span><span class="s1">&#39;success&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">annotation</span><span class="p">[</span><span class="s1">&#39;error&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
            
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ✗ Error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">annotation</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
                <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
                <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">isoformat</span><span class="p">(),</span>
                <span class="s1">&#39;success&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s1">&#39;error&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span>
                <span class="s1">&#39;stance&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;confidence&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;reasoning&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;policy_domain&#39;</span><span class="p">:</span> <span class="kc">None</span>
            <span class="p">}</span>
        
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">annotation</span><span class="p">)</span>
    
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ Completed: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;success&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2"> successful&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">df</span>

<span class="c1"># Run batch annotation</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">batch_annotate</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== ANNOTATION RESULTS ===</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Summary by stance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;stance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Average confidence by stance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;stance&#39;</span><span class="p">)[</span><span class="s1">&#39;confidence&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sample annotations:&quot;</span><span class="p">)</span>
<span class="n">display_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;stance&#39;</span><span class="p">,</span> <span class="s1">&#39;confidence&#39;</span><span class="p">,</span> <span class="s1">&#39;policy_domain&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">display_df</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Quality checks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== QUALITY CHECKS ===</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Check for low confidence predictions</span>
<span class="n">low_confidence</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;confidence&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.7</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Low confidence annotations (&lt; 0.7): </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">low_confidence</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">low_confidence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">low_confidence</span><span class="p">[[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;stance&#39;</span><span class="p">,</span> <span class="s1">&#39;confidence&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># Check for failures</span>
<span class="n">failures</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;success&#39;</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Failed annotations: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">failures</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">failures</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">failures</span><span class="p">[[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;error&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ Quality checks complete&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_stance_score</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get ideological position score from a model.</span>
<span class="sd">    Returns: float from -1 (most progressive) to +1 (most conservative)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Rate this text on ideology from -1 (most progressive)</span>
<span class="s2">to +1 (most conservative). Return only the number.</span>

<span class="s2">Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span>
    
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>

<span class="k">def</span><span class="w"> </span><span class="nf">ensemble_stance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">models</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Aggregate stance estimates across multiple models&quot;&quot;&quot;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">individual</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">get_stance_score</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
            <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="n">individual</span><span class="p">[</span><span class="n">model</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">model</span><span class="si">:</span><span class="s2">20</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">model</span><span class="si">:</span><span class="s2">20</span><span class="si">}</span><span class="s2">: Error - </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">continue</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">scores</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span>
        <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span>
        <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span>
        <span class="s2">&quot;min&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span>
        <span class="s2">&quot;max&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span>
        <span class="s2">&quot;individual&quot;</span><span class="p">:</span> <span class="n">individual</span><span class="p">,</span>
        <span class="s2">&quot;n_models&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Single text with multiple models</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">]</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;We must protect traditional family values and limit government overreach&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Individual model scores:&quot;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">ensemble_stance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">models</span><span class="p">)</span>

<span class="k">if</span> <span class="n">result</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Ensemble results:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean:      </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Median:    </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;median&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Std dev:   </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Range:     [</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">+.3f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    
    <span class="n">agreement</span> <span class="o">=</span> <span class="s2">&quot;High&quot;</span> <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.3</span> <span class="k">else</span> <span class="s2">&quot;Medium&quot;</span> <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.6</span> <span class="k">else</span> <span class="s2">&quot;Low&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Agreement: </span><span class="si">{</span><span class="n">agreement</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="open-source-alternatives">
<h2>Open-Source Alternatives<a class="headerlink" href="#open-source-alternatives" title="Link to this heading">#</a></h2>
<p>The examples above use OpenAI’s API. Here’s how to use open-source alternatives with Ollama or Hugging Face.</p>
<section id="using-ollama">
<h3>Using Ollama<a class="headerlink" href="#using-ollama" title="Link to this heading">#</a></h3>
<p>Using the Ollama setup from Week 04:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ollama</span><span class="w"> </span><span class="kn">import</span> <span class="n">Client</span> <span class="k">as</span> <span class="n">OllamaClient</span>

<span class="n">ollama_client</span> <span class="o">=</span> <span class="n">OllamaClient</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;http://localhost:11434&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✓ Ollama client initialized&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Annotation with structured outputs using Ollama</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>

<span class="k">class</span><span class="w"> </span><span class="nc">StanceAnnotation</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">stance</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># Progressive, Conservative, or Centrist</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">reasoning</span><span class="p">:</span> <span class="nb">str</span>

<span class="k">def</span><span class="w"> </span><span class="nf">annotate_with_ollama</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a careful social science annotator.&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;&#39;&#39;Classify the political stance of this statement as Progressive, Conservative, or Centrist.</span>

<span class="s1">Statement: &quot;</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s1">&quot;&#39;&#39;&#39;</span><span class="p">}</span>
    <span class="p">]</span>
    
    <span class="n">response</span> <span class="o">=</span> <span class="n">ollama_client</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="nb">format</span><span class="o">=</span><span class="n">StanceAnnotation</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">StanceAnnotation</span><span class="o">.</span><span class="n">model_validate_json</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>

<span class="c1"># Example</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;We need stronger social safety nets and universal healthcare.&quot;</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">annotate_with_ollama</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stance: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">stance</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Confidence: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">confidence</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reasoning: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">reasoning</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-hugging-face">
<h3>Using Hugging Face<a class="headerlink" href="#using-hugging-face" title="Link to this heading">#</a></h3>
<p>Works on Google Colab with GPU runtime:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Load model</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">hf_model_name</span> <span class="o">=</span> <span class="s2">&quot;microsoft/Phi-3-mini-4k-instruct&quot;</span>
<span class="n">hf_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">hf_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">hf_model_name</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">annotate_with_hf</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a careful social science annotator. Return valid JSON only.&quot;</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;&#39;&#39;Classify the political stance as Progressive, Conservative, or Centrist.</span>

<span class="s1">Statement: &quot;</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s1">&quot;</span>

<span class="s1">Return JSON with keys: stance, confidence, reasoning.&#39;&#39;&#39;</span><span class="p">}</span>
    <span class="p">]</span>
    
    <span class="n">formatted_prompt</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="p">(</span><span class="n">formatted_prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">hf_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">generated_ids</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:]</span>
    <span class="n">response_text</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Parse JSON</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
    <span class="n">json_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\{.*\}&#39;</span><span class="p">,</span> <span class="n">response_text</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">DOTALL</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json_match</span><span class="o">.</span><span class="n">group</span><span class="p">())</span> <span class="k">if</span> <span class="n">json_match</span> <span class="k">else</span> <span class="p">{}</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">annotate_with_hf</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Stance: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;stance&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<p>This notebook demonstrated key techniques for reliable, reproducible LLM annotation:</p>
<section id="prompt-formatting">
<h3>1. Prompt Formatting<a class="headerlink" href="#prompt-formatting" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>f-strings</strong>: Simple variable insertion</p></li>
<li><p><strong>Templates</strong>: Reusable format strings with <code class="docutils literal notranslate"><span class="pre">.format()</span></code></p></li>
<li><p><strong>Few-shot</strong>: Provide examples to guide behavior</p></li>
<li><p><strong>Chain-of-thought</strong>: Ask for step-by-step reasoning</p></li>
</ul>
</section>
<section id="structured-outputs-three-approaches">
<h3>2. Structured Outputs (Three Approaches)<a class="headerlink" href="#structured-outputs-three-approaches" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Prompt-only</strong>: Ask for JSON (least reliable)</p></li>
<li><p><strong>JSON mode</strong>: Force valid JSON with API parameter (recommended)</p></li>
<li><p><strong>Function calling</strong>: Typed schemas (most structured)</p></li>
</ul>
</section>
<section id="robust-extraction">
<h3>3. Robust Extraction<a class="headerlink" href="#robust-extraction" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Error handling with try/except</p></li>
<li><p>Retry logic for parse failures</p></li>
<li><p>Low temperature for consistency</p></li>
</ul>
</section>
<section id="batch-annotation">
<h3>4. Batch Annotation<a class="headerlink" href="#batch-annotation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Efficient processing of multiple texts</p></li>
<li><p>Logging timestamps and metadata</p></li>
<li><p>Quality checks (low confidence, failures)</p></li>
</ul>
</section>
</section>
<section id="best-practices-checklist">
<h2>Best Practices Checklist<a class="headerlink" href="#best-practices-checklist" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>☐ Pin model versions (use specific snapshots like <code class="docutils literal notranslate"><span class="pre">gpt-4-0613</span></code>)</p></li>
<li><p>☐ Set temperature to 0 for deterministic outputs</p></li>
<li><p>☐ Use seed parameter when supported</p></li>
<li><p>☐ Log everything (prompts, responses, settings, timestamps)</p></li>
<li><p>☐ Create promptbook for documentation</p></li>
<li><p>☐ Validate against human labels (Cohen’s κ &gt; 0.80)</p></li>
<li><p>☐ Test-retest reliability (check consistency over time)</p></li>
<li><p>☐ Model fingerprinting (detect API drift)</p></li>
<li><p>☐ Share code and configs for replication</p></li>
<li><p>☐ Consider open models for perfect reproducibility</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="week05_qualitative.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Qualitative Coding with LLMs</p>
      </div>
    </a>
    <a class="right-next"
       href="week07_silicon_sampling.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">LLMs for Synthetic Data I: Simulating Survey Respondents</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-objectives">Learning Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-in-google-colab">Running in Google Colab</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-locally">Running Locally</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-1-prompt-formatting-strategies">Part 1: Prompt Formatting Strategies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-simple-f-string-prompting">1A. Simple f-string Prompting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-reusable-template-with-format">1B. Reusable Template with .format()</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-few-shot-prompting">1C. Few-Shot Prompting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-chain-of-thought-prompting">1D. Chain-of-Thought Prompting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-2-three-approaches-to-getting-structured-outputs-json">Part 2: Three Approaches to Getting Structured Outputs (JSON)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-prompt-for-json-simplest-least-reliable">Approach 1: Prompt for JSON (Simplest, Least Reliable)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-json-mode-api-parameter-recommended-for-most-tasks">Approach 2: JSON Mode API Parameter (Recommended for Most Tasks)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-3-provider-json-mode-more-reliable">Approach 3: Provider JSON Mode (More Reliable)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-summary">Comparison Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-3-robust-json-extraction">Part 3: Robust JSON Extraction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-4-batch-annotation">Part 4: Batch Annotation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-source-alternatives">Open-Source Alternatives</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama">Using Ollama</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-hugging-face">Using Hugging Face</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-formatting">1. Prompt Formatting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#structured-outputs-three-approaches">2. Structured Outputs (Three Approaches)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robust-extraction">3. Robust Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batch-annotation">4. Batch Annotation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-practices-checklist">Best Practices Checklist</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christopher Barrie
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>