{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLMs for Synthetic Data I: Simulating Survey Respondents\n\n**Learning objectives:**\n- Understand silicon sampling and its application to survey research\n- Implement demographic persona construction following Argyle et al. (2023)\n- Generate synthetic survey responses and compare to real data\n- Measure accuracy, invariance, and stereotyping\n- Validate synthetic data against ground truth surveys\n- Understand boundary conditions for when silicon sampling works (Bisbee et al. 2024)\n\n**How to run this notebook:**\n- **Google Colab** (recommended): Works for all parts\n- **OpenAI API key needed**: For generating synthetic responses\n\n---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Silicon Sampling?\n",
        "\n",
        "**Silicon sampling** is the use of large language models (LLMs) to simulate survey respondents by conditioning the model on demographic characteristics.\n",
        "\n",
        "**The basic idea:**\n",
        "1. Create a demographic \"persona\" (age, gender, education, etc.)\n",
        "2. Prompt an LLM to respond as that persona would\n",
        "3. Ask survey questions and collect responses\n",
        "4. Aggregate across many personas to estimate population distributions\n",
        "\n",
        "**Potential applications:**\n",
        "- Rapid prototyping of survey instruments\n",
        "- Exploring counterfactual scenarios\n",
        "- Augmenting small samples\n",
        "- Pre-testing research designs\n",
        "\n",
        "**Key challenges:**\n",
        "- **Algorithmic fidelity**: Do synthetic distributions match real ones?\n",
        "- **Invariance**: Do all personas with same demographics give identical answers?\n",
        "- **Stereotyping**: Are between-group differences exaggerated?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install packages\n",
        "!pip install -q openai pandas numpy scipy scikit-learn matplotlib seaborn requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import os\nimport json\nimport re\nimport getpass\nimport time\nfrom datetime import datetime\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.spatial.distance import cosine\nfrom scipy.stats import entropy, spearmanr\nfrom sklearn.metrics import cohen_kappa_score, confusion_matrix\nfrom openai import OpenAI\n\n# Set API key\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n\nclient = OpenAI()\n\n# Set plotting style\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"\u2713 Setup complete!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this code does:**\n",
        "\n",
        "Sets up the environment for silicon sampling experiments:\n",
        "\n",
        "**Key libraries:**\n",
        "- **`openai`**: API access to GPT models\n",
        "- **`pandas`**: Data manipulation and analysis\n",
        "- **`scipy`**: Statistical measures (cosine similarity, KL divergence, Spearman correlation)\n",
        "- **`sklearn`**: Validation metrics (Cohen's kappa, confusion matrix)\n",
        "- **`matplotlib/seaborn`**: Visualization\n",
        "\n",
        "**Why these specific tools:**\n",
        "- **Cosine similarity**: Measure algorithmic fidelity (how similar are distributions?)\n",
        "- **KL divergence**: Another distance metric for distributions\n",
        "- **Cohen's kappa**: Inter-rater reliability between synthetic and real\n",
        "- **Spearman correlation**: Ordinal association between rankings\n",
        "\n",
        "**Security reminder:** Uses `getpass` for API keys - never hardcode them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 1: Creating Demographic Personas (Argyle et al. 2023)\n",
        "\n",
        "The foundation of silicon sampling is constructing realistic demographic personas. Based on Argyle et al. (2023), personas should include:\n",
        "\n",
        "- Age\n",
        "- Gender\n",
        "- Race/ethnicity\n",
        "- Education level\n",
        "- Income bracket\n",
        "- Geographic region\n",
        "- Political party (for political questions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": "**What this code does:**\n\nImplements the **persona construction** approach from Argyle et al. (2023):\n\n**The `create_persona` function:**\n- Takes a dictionary of demographic attributes\n- Formats them into a natural language persona description\n- Uses second person (\"You are...\") to prime the model\n\n**Key demographic variables:**\n- **Age**: Specific number (not range) for precision\n- **Race/ethnicity**: Following U.S. Census categories\n- **Gender**: Binary in original study (limitations noted)\n- **Education**: Categorical levels (high school, some college, college degree, graduate)\n- **Income**: Specific dollar amount or range\n- **Region**: Geographic area (affects policy preferences)\n- **Party**: Political affiliation (optional, task-dependent)\n\n**Why this format:**\n- Clear, unambiguous demographic information\n- Mimics how humans think about identity\n- Tested extensively in Argyle et al. (2023)\n\n**Limitations:**\n- Simplified categories (e.g., binary gender)\n- May activate stereotypes in the model\n- Assumes demographics determine opinions (not always true)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this code does:**\n",
        "\n",
        "Implements the **persona construction** approach from Argyle et al. (2023):\n",
        "\n",
        "**The `create_persona` function:**\n",
        "- Takes a dictionary of demographic attributes\n",
        "- Formats them into a natural language persona description\n",
        "- Uses second person (\"You are...\") to prime the model\n",
        "\n",
        "**Key demographic variables:**\n",
        "- **Age**: Specific number (not range) for precision\n",
        "- **Race/ethnicity**: Following U.S. Census categories\n",
        "- **Gender**: Binary in original study (limitations noted)\n",
        "- **Education**: Categorical levels (high school, some college, college degree, graduate)\n",
        "- **Income**: Specific dollar amount or range\n",
        "- **Region**: Geographic area (affects policy preferences)\n",
        "- **Party**: Political affiliation (optional, task-dependent)\n",
        "\n",
        "**Why this format:**\n",
        "- Clear, unambiguous demographic information\n",
        "- Mimics how humans think about identity\n",
        "- Tested extensively in Argyle et al. (2023)\n",
        "\n",
        "**Limitations:**\n",
        "- Simplified categories (e.g., binary gender)\n",
        "- May activate stereotypes in the model\n",
        "- Assumes demographics determine opinions (not always true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 2: Generating Synthetic Survey Responses\n",
        "\n",
        "Now we'll implement the core silicon sampling function to generate survey responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def silicon_sample_likert(demographics, question, scale=(1, 5), model=\"gpt-3.5-turbo\", temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate synthetic survey response for Likert scale question\n",
        "    \n",
        "    Args:\n",
        "        demographics: dict of demographic attributes\n",
        "        question: survey question text\n",
        "        scale: tuple of (min, max) for Likert scale\n",
        "        model: which OpenAI model to use\n",
        "        temperature: sampling temperature (1.0 matches Argyle et al.)\n",
        "    \n",
        "    Returns:\n",
        "        int or None: numeric response on scale, or None if parsing fails\n",
        "    \"\"\"\n",
        "    persona = create_persona(demographics)\n",
        "    \n",
        "    prompt = f\"\"\"{question}\n",
        "\n",
        "Please respond with only a number from {scale[0]} to {scale[1]}, where:\n",
        "{scale[0]} = Strongly Disagree\n",
        "{scale[1]} = Strongly Agree\n",
        "\n",
        "Your response (number only):\"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": persona},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=temperature\n",
        "        )\n",
        "        \n",
        "        # Extract numeric response\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        # Try to extract first number\n",
        "        import re\n",
        "        numbers = re.findall(r'\\d+', content)\n",
        "        if numbers:\n",
        "            value = int(numbers[0])\n",
        "            # Validate in range\n",
        "            if scale[0] <= value <= scale[1]:\n",
        "                return value\n",
        "        \n",
        "        return None\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test with example question\n",
        "question = \"The government should provide universal healthcare for all citizens.\"\n",
        "\n",
        "print(f\"Question: {question}\\n\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nSynthetic responses:\\n\")\n",
        "\n",
        "for i, demo in enumerate(example_personas, 1):\n",
        "    response = silicon_sample_likert(demo, question)\n",
        "    print(f\"Persona {i} ({demo['party']}): {response}\")\n",
        "    time.sleep(0.3)  # Rate limiting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this code does:**\n\nImplements the core **silicon sampling function** for Likert-scale questions:\n\n**The `silicon_sample_likert` function workflow:**\n1. Create persona from demographics\n2. Format question with clear scale instructions\n3. Send to LLM with persona as system message\n4. Extract numeric response with error handling\n5. Validate response is in valid range\n\n**Key parameters:**\n- **`temperature=1.0`**: Matches Argyle et al. (2023) default\n  - Higher than annotation tasks (0.1-0.3)\n  - Allows for within-group diversity\n  - Still not as diverse as real humans\n  - **Why 1.0 instead of lower values**: We want to simulate human variability, not find a single \"correct\" answer. Lower temperatures would reduce response diversity, making personas with similar demographics give more similar responses. Temperature=1.0 introduces sampling variability to better approximate real human diversity.\n- **`model=\"gpt-3.5-turbo\"`**: Original study used GPT-3 (similar)\n\n**Robust parsing:**\n- Uses regex to extract first number from response\n- Handles cases where model adds explanation\n- Validates number is in valid range\n- Returns `None` if parsing fails\n\n**Why system vs user message:**\n- **System message**: Sets persistent context (persona)\n- **User message**: Contains the specific question\n- This separation helps model stay \"in character\"\n\n**Cost consideration:** Each call costs ~$0.0005-0.001 with GPT-3.5-turbo, so 1000 responses \u2248 $0.50-1.00"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating responses for multiple questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define survey questions (simplified ANES-style)\n",
        "questions = [\n",
        "    \"The government should provide universal healthcare for all citizens.\",\n",
        "    \"We should increase spending on defense and military.\",\n",
        "    \"Climate change is one of the most serious problems facing the country.\",\n",
        "    \"Immigration levels should be decreased.\",\n",
        "    \"The government should do more to regulate big corporations.\"\n",
        "]\n",
        "\n",
        "def collect_responses(demographics, questions, model=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Collect responses for multiple questions from a single persona\n",
        "    \"\"\"\n",
        "    responses = {}\n",
        "    \n",
        "    for i, question in enumerate(questions, 1):\n",
        "        response = silicon_sample_likert(demographics, question, model=model)\n",
        "        responses[f\"Q{i}\"] = response\n",
        "        time.sleep(0.2)  # Rate limiting\n",
        "    \n",
        "    return responses\n",
        "\n",
        "# Collect responses from example personas\n",
        "results = []\n",
        "\n",
        "for demo in example_personas:\n",
        "    print(f\"Collecting responses for: {demo['party']}, {demo['age']}, {demo['race']}...\")\n",
        "    responses = collect_responses(demo, questions)\n",
        "    \n",
        "    result = {**demo, **responses}\n",
        "    results.append(result)\n",
        "\n",
        "df_synthetic = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n\u2713 Synthetic responses collected\\n\")\n",
        "print(df_synthetic[['party', 'age', 'race', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**What this code does:**\n\nImplements **multi-question survey collection** from synthetic personas:\n\n**The `collect_responses` function:**\n- Takes single demographic profile and list of questions\n- Collects response for each question sequentially\n- Returns dictionary of question IDs \u2192 responses\n- Includes rate limiting to avoid API throttling\n\n**Question design:**\n- Based on typical ANES (American National Election Studies) format\n- Cover different policy domains (healthcare, defense, environment, immigration, economy)\n- Clear, unambiguous phrasing\n- Scaled as agreement (1-5)\n\n**Why collect multiple questions:**\n- Test consistency within persona\n- Enable correlation analysis (do issues cluster as expected?)\n- Compare to real survey patterns\n- Detect stereotyping across domains\n\n**Output format:**\n- Pandas DataFrame with demographics + responses\n- Easy to analyze, visualize, export\n- Can merge with real survey data for comparison\n\n**Note on None values:**\n- If the LLM fails to return a valid numeric response, `silicon_sample_likert` returns `None`\n- This can happen if the model provides explanation instead of just a number, or if parsing fails\n- These None values will appear in the DataFrame and should be handled in analysis (e.g., filtered out or imputed)\n- Always check for and report the rate of failed parses in your validation\n\n**Next steps:** Scale up to many personas and compare to real distributions"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## Part 3: Validating Synthetic Data Against Real Surveys\n\n**Validation** measures how well synthetic responses match real survey data.\n\nKey metrics:\n- **Proportion matching**: What percentage of synthetic responses match the modal real response?\n- **Response variance**: Do synthetic responses show similar spread to real responses?\n- **Distribution plots**: Visual comparison of response distributions\n\n**\u26a0\ufe0f IMPORTANT: The \"real\" survey data used in this section is simulated for demonstration purposes only. In actual research, you MUST use authentic survey data from sources like ANES, GSS, Pew, or your own validated surveys.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate real survey data for comparison\n",
        "# (In practice, you'd use actual survey data like ANES or GSS)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create \"real\" data with realistic distributions\n",
        "# Democrats favor Q1 (healthcare), Republicans favor Q2 (defense)\n",
        "real_data = []\n",
        "\n",
        "for party in ['Democrat', 'Republican', 'Independent']:\n",
        "    n = 100\n",
        "    \n",
        "    if party == 'Democrat':\n",
        "        q1 = np.random.choice([3, 4, 5], n, p=[0.2, 0.4, 0.4])  # Pro healthcare\n",
        "        q2 = np.random.choice([1, 2, 3], n, p=[0.4, 0.4, 0.2])  # Anti defense spending\n",
        "    elif party == 'Republican':\n",
        "        q1 = np.random.choice([1, 2, 3], n, p=[0.4, 0.4, 0.2])  # Anti healthcare\n",
        "        q2 = np.random.choice([3, 4, 5], n, p=[0.2, 0.4, 0.4])  # Pro defense\n",
        "    else:  # Independent\n",
        "        q1 = np.random.choice([2, 3, 4], n, p=[0.3, 0.4, 0.3])  # Moderate\n",
        "        q2 = np.random.choice([2, 3, 4], n, p=[0.3, 0.4, 0.3])  # Moderate\n",
        "    \n",
        "    for i in range(n):\n",
        "        real_data.append({\n",
        "            'party': party,\n",
        "            'Q1': q1[i],\n",
        "            'Q2': q2[i]\n",
        "        })\n",
        "\n",
        "df_real = pd.DataFrame(real_data)\n",
        "\n",
        "print(\"'Real' survey data (simulated):\")\n",
        "print(df_real.groupby('party')[['Q1', 'Q2']].mean().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate proportion matching and variance comparison\n\nprint(\"Validation Metrics\\n\")\nprint(\"=\" * 70)\n\n# For each party and question, compare synthetic to real\nfor party in ['Democrat', 'Republican']:\n    print(f\"\\n{party} - Q1 (Healthcare):\")\n    print(\"-\" * 70)\n    \n    # Get real responses\n    real_responses = df_real[df_real['party'] == party]['Q1']\n    real_mean = real_responses.mean()\n    real_std = real_responses.std()\n    real_mode = real_responses.mode()[0]\n    \n    print(f\"  Real data:\")\n    print(f\"    Mean: {real_mean:.2f}\")\n    print(f\"    Std:  {real_std:.2f}\")\n    print(f\"    Modal response: {real_mode}\")\n    \n    # For synthetic (in practice, you'd have many synthetic responses per party)\n    # Here we just show the structure\n    print(f\"\\n  Synthetic data (need larger sample for comparison):\")\n    print(f\"    [Generate 30+ responses per party]\")\n    print(f\"    Then calculate:\")\n    print(f\"      - Proportion matching modal response\")\n    print(f\"      - Mean and std of synthetic responses\")\n    print(f\"      - Compare std to real std\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"\\n**Interpretation:**\")\nprint(\"- **Proportion matching**: Higher is better (> 50% good)\")\nprint(\"- **Variance comparison**: Synthetic std should be close to real std\")\nprint(\"  - If synthetic std << real std: Underestimating diversity (invariance)\")\nprint(\"  - If synthetic std >> real std: Overestimating diversity\")\nprint(\"- **Visual inspection**: Plot distributions side-by-side\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this code does:**\n\n**Proportion matching:**\n- Find the most common (modal) response in real data\n- Calculate what % of synthetic responses match that mode\n- **Example**: If real Democrats most commonly say \"5\" (strongly agree) to healthcare, what % of synthetic Democrats also say \"5\"?\n- Higher matching indicates better alignment with real data\n\n**Variance comparison:**\n- Real humans have variance in responses even with same demographics\n- Compare std deviation of synthetic vs real\n- **Example**: \n  - Real Democrats on healthcare: mean=4.2, std=1.1\n  - Synthetic Democrats: mean=4.3, std=0.4\n  - **Problem**: Synthetic std too low \u2192 invariance issue\n- Ideally, synthetic variance should be similar to real variance\n\n**Why these metrics:**\n- **More intuitive**: Easier to explain to non-technical audiences\n- **Direct**: Measures actual agreement, not abstract distance\n- **Actionable**: Clear when synthetic data fails validation\n\n**Visual comparison (next cell):**\n- Plot distributions side-by-side\n- See where synthetic over/under-represents responses\n- Identify systematic biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize variance comparison\n",
        "# This would use actual synthetic data once generated\n\n",
        "# Example visualization code:\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n",
        "# Plot 1: Distribution comparison\n",
        "ax = axes[0]\n",
        "parties = ['Democrat', 'Republican']\n",
        "x = np.arange(len(parties))\n",
        "width = 0.35\n\n",
        "# Real data means (from df_real)\n",
        "real_means = [df_real[df_real['party'] == p]['Q1'].mean() for p in parties]\n",
        "real_stds = [df_real[df_real['party'] == p]['Q1'].std() for p in parties]\n\n",
        "# Synthetic would go here (placeholder)\n",
        "synthetic_means = [4.1, 2.3]  # Placeholder - replace with actual synthetic data\n",
        "synthetic_stds = [0.6, 0.5]   # Placeholder\n\n",
        "ax.bar(x - width/2, real_means, width, label='Real', yerr=real_stds, capsize=5, alpha=0.7)\n",
        "ax.bar(x + width/2, synthetic_means, width, label='Synthetic (placeholder)', yerr=synthetic_stds, capsize=5, alpha=0.7)\n",
        "ax.set_ylabel('Mean Response (1-5)')\n",
        "ax.set_title('Q1: Healthcare - Mean \u00b1 Std')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(parties)\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 6)\n",
        "ax.axhline(y=3, color='gray', linestyle='--', alpha=0.3, label='Neutral')\n\n",
        "# Plot 2: Variance comparison\n",
        "ax = axes[1]\n",
        "variance_data = {\n",
        "    'Democrat': {'Real': real_stds[0], 'Synthetic': synthetic_stds[0]},\n",
        "    'Republican': {'Real': real_stds[1], 'Synthetic': synthetic_stds[1]}\n",
        "}\n\n",
        "x = np.arange(len(parties))\n",
        "real_vars = [variance_data[p]['Real'] for p in parties]\n",
        "synth_vars = [variance_data[p]['Synthetic'] for p in parties]\n\n",
        "ax.bar(x - width/2, real_vars, width, label='Real', alpha=0.7)\n",
        "ax.bar(x + width/2, synth_vars, width, label='Synthetic (placeholder)', alpha=0.7)\n",
        "ax.set_ylabel('Standard Deviation')\n",
        "ax.set_title('Response Variance Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(parties)\n",
        "ax.legend()\n",
        "ax.axhline(y=1.0, color='red', linestyle='--', alpha=0.3, label='Target (human-level)')\n\n",
        "plt.tight_layout()\n",
        "plt.show()\n\n",
        "print(\"\\n\u2713 Visualization shows:\")\n",
        "print(\"  Left: Mean responses with error bars (std)\")\n",
        "print(\"  Right: Direct variance comparison\")\n",
        "print(\"  \u26a0 Replace placeholder synthetic data with actual generated responses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating larger synthetic sample for proper validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Generate larger synthetic sample (this will take a few minutes and cost ~$0.09-$0.50)\n# Uncomment to run - skipping by default to save API costs\n\n\"\"\"\n# Create diverse demographic profiles\nfrom itertools import product\n\n# Define demographic space\nages = [25, 35, 45, 55, 65]\nraces = ['white', 'Black', 'Hispanic']\ngenders = ['male', 'female']\neducations = ['high school', 'college degree']\nincomes = ['35,000', '65,000', '95,000']\nregions = ['Northeast', 'South', 'Midwest', 'West']\nparties = ['Democrat', 'Republican', 'Independent']\n\n# Generate personas (this creates hundreds of combinations)\n# For demo purposes, sample a subset\nnp.random.seed(42)\n\npersonas = []\nfor party in parties:\n    for i in range(30):  # 30 per party = 90 total\n        persona = {\n            'age': np.random.choice(ages),\n            'race': np.random.choice(races),\n            'gender': np.random.choice(genders),\n            'education': np.random.choice(educations),\n            'income': np.random.choice(incomes),\n            'region': np.random.choice(regions),\n            'party': party\n        }\n        personas.append(persona)\n\n# Collect responses\nsynthetic_results = []\n\nfor i, persona in enumerate(personas, 1):\n    if i % 10 == 0:\n        print(f\"Progress: {i}/{len(personas)}\")\n    \n    responses = collect_responses(persona, questions[:2])  # Just Q1, Q2 for speed\n    result = {**persona, **responses}\n    synthetic_results.append(result)\n\ndf_synthetic_large = pd.DataFrame(synthetic_results)\ndf_synthetic_large.to_csv('synthetic_survey_data.csv', index=False)\n\nprint(\"\\n\u2713 Large synthetic sample collected and saved\")\n\"\"\"\n\nprint(\"[Skipped to save API costs - uncomment to run]\")\nprint(\"This would generate 90 synthetic respondents\")\nprint(\"Cost estimate: ~$0.09 for completions, up to $0.50 with prompt tokens depending on length\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this code does:**\n",
        "\n",
        "Demonstrates how to generate a **large-scale synthetic sample** for validation:\n",
        "\n",
        "**The demographic space:**\n",
        "- **Full factorial**: All combinations of demographics\n",
        "- **Sampling strategy**: Random sample from space (more efficient than full grid)\n",
        "- **Stratification**: Equal samples per party (can weight later)\n",
        "\n",
        "**Sample size considerations:**\n",
        "- **Minimum**: 30-50 per group for distribution comparison\n",
        "- **Good**: 100+ per group\n",
        "- **Excellent**: 200+ per group (like Argyle et al.)\n",
        "\n",
        "**Cost calculation:**\n",
        "- 90 personas \u00d7 2 questions = 180 API calls\n",
        "- ~$0.0005 per call with GPT-3.5-turbo\n",
        "- Total: ~$0.10-0.50 depending on prompt length\n",
        "\n",
        "**Why commented out:**\n",
        "- Saves API costs for students running the notebook\n",
        "- Takes 5-10 minutes to run\n",
        "- You can uncomment when ready to do real validation\n",
        "\n",
        "**Best practices:**\n",
        "- Save results to CSV after generation\n",
        "- Don't regenerate unnecessarily\n",
        "- Include random seed for reproducibility\n",
        "- Log all parameters (model, temperature, timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test invariance: multiple responses from same persona\ntest_persona = example_personas[0]  # Democrat, 45, white male\ntest_question = questions[0]  # Healthcare\n\nprint(f\"Testing invariance for persona: {test_persona['party']}, {test_persona['age']}, {test_persona['race']}\")\nprint(f\"Question: {test_question}\\n\")\nprint(\"=\" * 70)\n\n# Collect 10 responses from same persona\nresponses = []\nfor i in range(10):\n    response = silicon_sample_likert(test_persona, test_question)\n    responses.append(response)\n    print(f\"Response {i+1}: {response}\")\n    time.sleep(0.3)\n\n# Calculate variance\nresponses = [r for r in responses if r is not None]\nmean_response = np.mean(responses)\nvariance = np.var(responses)\nstd = np.std(responses)\n\nprint(f\"\\nWithin-persona statistics:\")\nprint(f\"  Mean: {mean_response:.2f}\")\nprint(f\"  Std: {std:.2f}\")\nprint(f\"  Variance: {variance:.2f}\")\n\n# Compare to expected human variance\nprint(f\"\\nComparison:\")\nprint(f\"  LLM within-persona std: {std:.2f}\")\nprint(f\"  Typical human within-group std: ~1.0-1.5\")\nprint(f\"\\nInterpretation: Lower std indicates less diversity than humans\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "**What this code does:**\n\nTests for **invariance** by repeatedly querying the same persona:\n\n**The invariance problem:**\n- Real humans: Same demographics \u2260 identical opinions  \n- LLMs: May produce very similar responses for identical personas\n- This **underestimates real heterogeneity**\n\n**Why invariance happens:**\n- Even with temperature > 0, models show less diversity than humans\n- Models average over training data\n- Stereotypical \"typical\" response for each demographic\n- Missing individual-level factors (personality, experiences, etc.)\n\n**What we measure:**\n- **Mean**: Average response for persona\n- **Std (standard deviation)**: Spread of responses\n- **Variance**: Squared std\n\n**Interpretation:**\n- Compare LLM std to typical human std (~1.0-1.5 on 5-point scales)\n- Lower LLM std indicates less diversity (invariance problem)\n- Higher LLM std approaching human levels suggests better diversity\n\n**Typical observations:**\n- LLMs: Std varies by question, model, and temperature\n- Humans: Generally show more within-group diversity\n- **Implication**: LLMs often underestimate within-group diversity\n\n**Bisbee et al. (2024) finding:**\n- Invariance worse for identity-salient questions\n- Better for non-political factual questions\n- Larger models (GPT-4) show slightly better diversity than GPT-3.5\n\n**Solutions:**\n- Higher temperature helps but doesn't fully solve the problem\n- Add personality traits to personas\n- Fine-tune on diverse real responses\n- Acknowledge limitation in reporting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**What this code does:**\n\nTests for **invariance** by repeatedly querying the same persona:\n\n**The invariance problem:**\n- Real humans: Same demographics \u2260 identical opinions\n- LLMs: May produce very similar responses for identical personas\n- This **underestimates real heterogeneity**\n\n**Why invariance happens:**\n- Temperature > 0 adds randomness, but not enough\n- Models average over training data\n- Stereotypical \"typical\" response for each demographic\n- Missing individual-level factors (personality, experiences, etc.)\n\n**What we measure:**\n- **Mean**: Average response for persona\n- **Std (standard deviation)**: Spread of responses\n- **Variance**: Squared std\n\n**Interpretation:**\n- **Std < 0.5**: High invariance (responses very similar)\n- **Std 0.5-1.0**: Moderate diversity (less than humans)\n- **Std > 1.0**: Good diversity (approaching human levels)\n\n**Note on thresholds with temperature=1.0:**\n- With temperature=1.0, LLM variance is typically higher than with temperature=0\n- However, the thresholds above (< 0.5, 0.5-1.0, > 1.0) still apply because they're calibrated against human within-group variance\n- Even with temperature=1.0, LLMs often show variance around 0.3-0.8, which is still less than typical human variance of 1.0-1.5\n- The higher temperature helps but doesn't fully solve the invariance problem\n\n**Typical observations:**\n- LLMs: Std ~ 0.3-0.8 (varies by question and model)\n- Humans: Std ~ 1.0-1.5 on same demographic\n- **Implication**: LLMs underestimate within-group diversity\n\n**Bisbee et al. (2024) finding:**\n- Invariance worse for identity-salient questions\n- Better for non-political factual questions\n- Larger models (GPT-4) show slightly better diversity than GPT-3.5\n\n**Solutions:**\n- Higher temperature (but may reduce accuracy)\n- Add personality traits to personas\n- Fine-tune on diverse real responses\n- Acknowledge limitation in reporting"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 5: Diagnosing Stereotyping\n",
        "\n",
        "**Stereotyping** occurs when LLMs exaggerate between-group differences compared to real data.\n",
        "\n",
        "**The problem:**\n",
        "- LLMs trained on text that often contains stereotypes\n",
        "- May amplify partisan/demographic differences\n",
        "- Creates artificial polarization\n",
        "\n",
        "**How to test:**\n",
        "- Compare effect sizes for demographics in synthetic vs real data\n",
        "- Look for exaggerated differences between groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate means and differences\n",
        "dem_mean = df_stereotyping[df_stereotyping['party'] == 'Democrat']['response'].mean()\n",
        "rep_mean = df_stereotyping[df_stereotyping['party'] == 'Republican']['response'].mean()\n",
        "\n",
        "print(\"\\nBetween-group analysis (Healthcare question):\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nDemocrat mean: {dem_mean:.2f}\")\n",
        "print(f\"Republican mean: {rep_mean:.2f}\")\n",
        "print(f\"Difference: {abs(dem_mean - rep_mean):.2f}\")\n",
        "\n",
        "print(f\"\\nNote: Compare this difference to real survey data\")\n",
        "print(f\"If synthetic difference >> real difference, this suggests stereotyping\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this code does:**\n",
        "\n",
        "Tests for **stereotyping** by measuring between-group differences:\n",
        "\n",
        "**What is stereotyping in silicon sampling:**\n",
        "- LLMs may exaggerate differences between demographic groups\n",
        "- E.g., making Democrats MORE pro-healthcare than real Democrats\n",
        "- Or Republicans MORE anti-healthcare than real Republicans\n",
        "- Creates artificial polarization\n",
        "\n",
        "**Measuring group differences:**\n",
        "- Calculate mean response for each group\n",
        "- Calculate absolute difference\n",
        "- Compare to real data differences\n",
        "\n",
        "**How to detect stereotyping:**\n",
        "1. Calculate group difference for synthetic data\n",
        "2. Calculate group difference for real data\n",
        "3. Compare: If synthetic difference >> real difference, stereotyping present\n",
        "\n",
        "**Example:**\n",
        "- Real data: Democrat vs Republican on healthcare, difference = 1.2\n",
        "- Synthetic: difference = 2.4\n",
        "- **Interpretation**: LLM is doubling the partisan divide\n",
        "\n",
        "**Why stereotyping happens:**\n",
        "- Training data contains exaggerated partisan rhetoric\n",
        "- News articles emphasize differences\n",
        "- Social media polarization in training data\n",
        "- Models learn \"prototypical\" Democrat/Republican\n",
        "\n",
        "**Bisbee et al. (2024) findings:**\n",
        "- Stereotyping worse for:\n",
        "  - Morally charged issues (abortion, guns)\n",
        "  - Identity-salient topics (race, gender)\n",
        "  - Minority subgroups (underrepresented in training)\n",
        "- Better for:\n",
        "  - Non-political topics\n",
        "  - Aggregate estimates (averaging reduces bias)\n",
        "\n",
        "**Solutions:**\n",
        "- Compare differences to real data (essential validation step)\n",
        "- Avoid using for identity-salient questions\n",
        "- Consider weighting/calibrating to match real distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 6: When Does Silicon Sampling Work? (Bisbee et al. 2024)\n",
        "\n",
        "Based on Bisbee et al. (2024), silicon sampling has clear **boundary conditions**.\n",
        "\n",
        "### When it works:\n",
        "- \u2713 High-consensus topics (e.g., basic civic knowledge)\n",
        "- \u2713 Non-identity-salient issues\n",
        "- \u2713 Aggregate-level estimates\n",
        "- \u2713 Larger models (GPT-4 > GPT-3.5)\n",
        "\n",
        "### When it fails:\n",
        "- \u2717 Morally charged issues (abortion, immigration)\n",
        "- \u2717 Identity-salient topics (racial attitudes, gender policies)\n",
        "- \u2717 Minority subgroups (underrepresented in training)\n",
        "- \u2717 Individual-level predictions\n",
        "\n",
        "### Appropriate use cases:\n",
        "1. **Question development**: Test survey instruments before fielding\n",
        "2. **Exploratory research**: Generate hypotheses to test with real data\n",
        "3. **Education**: Teach survey methodology\n",
        "4. **Augmentation**: Supplement small real samples (with caution)\n",
        "\n",
        "### Inappropriate use cases:\n",
        "1. \u2717 Replacing representative surveys\n",
        "2. \u2717 Studying marginalized populations\n",
        "3. \u2717 Making substantive claims about \"public opinion\"\n",
        "4. \u2717 High-stakes decisions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**What we learned:**\n",
        "1. \u2713 How to construct **demographic personas** following Argyle et al. (2023)\n",
        "2. \u2713 How to generate **synthetic survey responses** with LLMs\n",
        "3. \u2713 How to validate using **proportion matching** and **variance comparison**\n",
        "4. \u2713 How to diagnose **invariance** (within-group diversity)\n",
        "5. \u2713 How to diagnose **stereotyping** (exaggerated between-group differences)\n",
        "6. \u2713 **Boundary conditions** for when silicon sampling works (Bisbee et al. 2024)\n",
        "\n",
        "**Key insights:**\n",
        "- Silicon sampling can **approximate** population distributions for some questions\n",
        "- But faces serious challenges: **invariance** and **stereotyping**\n",
        "- Works best for **non-controversial, aggregate-level** estimates\n",
        "- Fails for **identity-salient, morally charged** topics\n",
        "- **Validation** against real data is essential\n",
        "\n",
        "**Historical context:**\n",
        "- Before LLMs: ABMs, synthetic populations, MRP, multiple imputation\n",
        "- LLMs add: Flexible generation, natural language, few-shot learning\n",
        "- But: Less principled uncertainty quantification than traditional methods\n",
        "\n",
        "**Validation metrics:**\n",
        "\n",
        "| Metric | What it measures | Target |\n",
        "|--------|------------------|--------|\n",
        "| Proportion matching | Agreement with modal response | > 50% |\n",
        "| Variance ratio | Synthetic std / Real std | 0.7-1.3 |\n",
        "| Within-group std | Invariance | > 1.0 |\n",
        "| Mean difference ratio | Stereotyping | \u2248 1.0 |\n",
        "\n",
        "**Best practices:**\n",
        "1. Always validate against real survey data\n",
        "2. Report all three challenges (accuracy, invariance, stereotyping)\n",
        "3. Use for exploration, not substitution\n",
        "4. Be transparent about limitations\n",
        "5. Consider ethical implications\n",
        "\n",
        "**Ethical considerations:**\n",
        "- Risk of reproducing harmful stereotypes\n",
        "- Collapsing diversity within demographic groups\n",
        "- Claiming to represent voices not consulted\n",
        "- Must disclose use of synthetic data\n",
        "\n",
        "**Next steps:**\n",
        "- **Week 8**: Interactive simulations and behavioral experiments with LLMs\n",
        "- **Week 9**: Generative agents and multi-agent systems\n",
        "- **Week 10**: Using LLMs to predict experimental outcomes\n",
        "\n",
        "---\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}