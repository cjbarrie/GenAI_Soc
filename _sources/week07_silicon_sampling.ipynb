{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# LLMs for Synthetic Data I: Simulating Survey Respondents\n\n**Learning objectives:**\n- Understand silicon sampling and its application to survey research\n- Implement demographic persona construction following Argyle et al. (2023)\n- Generate synthetic survey responses and compare to real data\n- Measure algorithmic fidelity, invariance, and stereotyping\n- Validate synthetic data against ground truth surveys\n- Understand boundary conditions for when silicon sampling works (Bisbee et al. 2024)\n\n**How to run this notebook:**\n- **Google Colab** (recommended): Works for all parts\n- **OpenAI API key needed**: For generating synthetic responses\n- **SubPOP dataset**: Available at github.com/JosephJeesungSuh/subpop\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Silicon Sampling?\n",
    "\n",
    "**Silicon sampling** is the use of large language models (LLMs) to simulate survey respondents by conditioning the model on demographic characteristics.\n",
    "\n",
    "**The basic idea:**\n",
    "1. Create a demographic \"persona\" (age, gender, education, etc.)\n",
    "2. Prompt an LLM to respond as that persona would\n",
    "3. Ask survey questions and collect responses\n",
    "4. Aggregate across many personas to estimate population distributions\n",
    "\n",
    "**Potential applications:**\n",
    "- Rapid prototyping of survey instruments\n",
    "- Exploring counterfactual scenarios\n",
    "- Augmenting small samples\n",
    "- Pre-testing research designs\n",
    "\n",
    "**Key challenges:**\n",
    "- **Algorithmic fidelity**: Do synthetic distributions match real ones?\n",
    "- **Invariance**: Do all personas with same demographics give identical answers?\n",
    "- **Stereotyping**: Are between-group differences exaggerated?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q openai pandas numpy scipy scikit-learn matplotlib seaborn requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport re\nimport getpass\nimport time\nfrom datetime import datetime\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.spatial.distance import cosine\nfrom scipy.stats import entropy, spearmanr\nfrom sklearn.metrics import cohen_kappa_score, confusion_matrix\nfrom openai import OpenAI\n\n# Set API key\nif \"OPENAI_API_KEY\" not in os.environ:\n    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n\nclient = OpenAI()\n\n# Set plotting style\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"✓ Setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Sets up the environment for silicon sampling experiments:\n",
    "\n",
    "**Key libraries:**\n",
    "- **`openai`**: API access to GPT models\n",
    "- **`pandas`**: Data manipulation and analysis\n",
    "- **`scipy`**: Statistical measures (cosine similarity, KL divergence, Spearman correlation)\n",
    "- **`sklearn`**: Validation metrics (Cohen's kappa, confusion matrix)\n",
    "- **`matplotlib/seaborn`**: Visualization\n",
    "\n",
    "**Why these specific tools:**\n",
    "- **Cosine similarity**: Measure algorithmic fidelity (how similar are distributions?)\n",
    "- **KL divergence**: Another distance metric for distributions\n",
    "- **Cohen's kappa**: Inter-rater reliability between synthetic and real\n",
    "- **Spearman correlation**: Ordinal association between rankings\n",
    "\n",
    "**Security reminder:** Uses `getpass` for API keys - never hardcode them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Creating Demographic Personas (Argyle et al. 2023)\n",
    "\n",
    "The foundation of silicon sampling is constructing realistic demographic personas. Based on Argyle et al. (2023), personas should include:\n",
    "\n",
    "- Age\n",
    "- Gender\n",
    "- Race/ethnicity\n",
    "- Education level\n",
    "- Income bracket\n",
    "- Geographic region\n",
    "- Political party (for political questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "**What this code does:**\n\nImplements the **persona construction** approach from Argyle et al. (2023):\n\n**The `create_persona` function:**\n- Takes a dictionary of demographic attributes\n- Formats them into a natural language persona description\n- Uses second person (\"You are...\") to prime the model\n\n**Key demographic variables:**\n- **Age**: Specific number (not range) for precision\n- **Race/ethnicity**: Following U.S. Census categories\n- **Gender**: Binary in original study (limitations noted)\n- **Education**: Categorical levels (high school, some college, college degree, graduate)\n- **Income**: Specific dollar amount or range\n- **Region**: Geographic area (affects policy preferences)\n- **Party**: Political affiliation (optional, task-dependent)\n\n**Why this format:**\n- Clear, unambiguous demographic information\n- Mimics how humans think about identity\n- Tested extensively in Argyle et al. (2023)\n\n**Limitations:**\n- Simplified categories (e.g., binary gender)\n- May activate stereotypes in the model\n- Assumes demographics determine opinions (not always true)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements the **persona construction** approach from Argyle et al. (2023):\n",
    "\n",
    "**The `create_persona` function:**\n",
    "- Takes a dictionary of demographic attributes\n",
    "- Formats them into a natural language persona description\n",
    "- Uses second person (\"You are...\") to prime the model\n",
    "\n",
    "**Key demographic variables:**\n",
    "- **Age**: Specific number (not range) for precision\n",
    "- **Race/ethnicity**: Following U.S. Census categories\n",
    "- **Gender**: Binary in original study (limitations noted)\n",
    "- **Education**: Categorical levels (high school, some college, college degree, graduate)\n",
    "- **Income**: Specific dollar amount or range\n",
    "- **Region**: Geographic area (affects policy preferences)\n",
    "- **Party**: Political affiliation (optional, task-dependent)\n",
    "\n",
    "**Why this format:**\n",
    "- Clear, unambiguous demographic information\n",
    "- Mimics how humans think about identity\n",
    "- Tested extensively in Argyle et al. (2023)\n",
    "\n",
    "**Limitations:**\n",
    "- Simplified categories (e.g., binary gender)\n",
    "- May activate stereotypes in the model\n",
    "- Assumes demographics determine opinions (not always true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Generating Synthetic Survey Responses\n",
    "\n",
    "Now we'll implement the core silicon sampling function to generate survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silicon_sample_likert(demographics, question, scale=(1, 5), model=\"gpt-3.5-turbo\", temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate synthetic survey response for Likert scale question\n",
    "    \n",
    "    Args:\n",
    "        demographics: dict of demographic attributes\n",
    "        question: survey question text\n",
    "        scale: tuple of (min, max) for Likert scale\n",
    "        model: which OpenAI model to use\n",
    "        temperature: sampling temperature (1.0 matches Argyle et al.)\n",
    "    \n",
    "    Returns:\n",
    "        int or None: numeric response on scale, or None if parsing fails\n",
    "    \"\"\"\n",
    "    persona = create_persona(demographics)\n",
    "    \n",
    "    prompt = f\"\"\"{question}\n",
    "\n",
    "Please respond with only a number from {scale[0]} to {scale[1]}, where:\n",
    "{scale[0]} = Strongly Disagree\n",
    "{scale[1]} = Strongly Agree\n",
    "\n",
    "Your response (number only):\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": persona},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # Extract numeric response\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        # Try to extract first number\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', content)\n",
    "        if numbers:\n",
    "            value = int(numbers[0])\n",
    "            # Validate in range\n",
    "            if scale[0] <= value <= scale[1]:\n",
    "                return value\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with example question\n",
    "question = \"The government should provide universal healthcare for all citizens.\"\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSynthetic responses:\\n\")\n",
    "\n",
    "for i, demo in enumerate(example_personas, 1):\n",
    "    response = silicon_sample_likert(demo, question)\n",
    "    print(f\"Persona {i} ({demo['party']}): {response}\")\n",
    "    time.sleep(0.3)  # Rate limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**What this code does:**\n\nImplements the core **silicon sampling function** for Likert-scale questions:\n\n**The `silicon_sample_likert` function workflow:**\n1. Create persona from demographics\n2. Format question with clear scale instructions\n3. Send to LLM with persona as system message\n4. Extract numeric response with error handling\n5. Validate response is in valid range\n\n**Key parameters:**\n- **`temperature=1.0`**: Matches Argyle et al. (2023) default\n  - Higher than annotation tasks (0.1-0.3)\n  - Allows for within-group diversity\n  - Still not as diverse as real humans\n  - **Why 1.0 instead of 0**: We want to simulate human variability, not find a single \"correct\" answer. Temperature=0 would make all personas with identical demographics give identical responses, which is unrealistic. Temperature=1.0 introduces sampling stochasticity to approximate real human diversity.\n- **`model=\"gpt-3.5-turbo\"`**: Original study used GPT-3 (similar)\n\n**Robust parsing:**\n- Uses regex to extract first number from response\n- Handles cases where model adds explanation\n- Validates number is in valid range\n- Returns `None` if parsing fails\n\n**Why system vs user message:**\n- **System message**: Sets persistent context (persona)\n- **User message**: Contains the specific question\n- This separation helps model stay \"in character\"\n\n**Cost consideration:** Each call costs ~$0.0005-0.001 with GPT-3.5-turbo, so 1000 responses ≈ $0.50-1.00"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating responses for multiple questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define survey questions (simplified ANES-style)\n",
    "questions = [\n",
    "    \"The government should provide universal healthcare for all citizens.\",\n",
    "    \"We should increase spending on defense and military.\",\n",
    "    \"Climate change is one of the most serious problems facing the country.\",\n",
    "    \"Immigration levels should be decreased.\",\n",
    "    \"The government should do more to regulate big corporations.\"\n",
    "]\n",
    "\n",
    "def collect_responses(demographics, questions, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Collect responses for multiple questions from a single persona\n",
    "    \"\"\"\n",
    "    responses = {}\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        response = silicon_sample_likert(demographics, question, model=model)\n",
    "        responses[f\"Q{i}\"] = response\n",
    "        time.sleep(0.2)  # Rate limiting\n",
    "    \n",
    "    return responses\n",
    "\n",
    "# Collect responses from example personas\n",
    "results = []\n",
    "\n",
    "for demo in example_personas:\n",
    "    print(f\"Collecting responses for: {demo['party']}, {demo['age']}, {demo['race']}...\")\n",
    "    responses = collect_responses(demo, questions)\n",
    "    \n",
    "    result = {**demo, **responses}\n",
    "    results.append(result)\n",
    "\n",
    "df_synthetic = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n✓ Synthetic responses collected\\n\")\n",
    "print(df_synthetic[['party', 'age', 'race', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**What this code does:**\n\nImplements **multi-question survey collection** from synthetic personas:\n\n**The `collect_responses` function:**\n- Takes single demographic profile and list of questions\n- Collects response for each question sequentially\n- Returns dictionary of question IDs → responses\n- Includes rate limiting to avoid API throttling\n\n**Question design:**\n- Based on typical ANES (American National Election Studies) format\n- Cover different policy domains (healthcare, defense, environment, immigration, economy)\n- Clear, unambiguous phrasing\n- Scaled as agreement (1-5)\n\n**Why collect multiple questions:**\n- Test consistency within persona\n- Enable correlation analysis (do issues cluster as expected?)\n- Compare to real survey patterns\n- Detect stereotyping across domains\n\n**Output format:**\n- Pandas DataFrame with demographics + responses\n- Easy to analyze, visualize, export\n- Can merge with real survey data for comparison\n\n**Note on None values:**\n- If the LLM fails to return a valid numeric response, `silicon_sample_likert` returns `None`\n- This can happen if the model provides explanation instead of just a number, or if parsing fails\n- These None values will appear in the DataFrame and should be handled in analysis (e.g., filtered out or imputed)\n- Always check for and report the rate of failed parses in your validation\n\n**Next steps:** Scale up to many personas and compare to real distributions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Part 3: Measuring Algorithmic Fidelity\n\n**Algorithmic fidelity** measures how well synthetic distributions match real survey distributions.\n\nCommon metrics:\n- **Cosine similarity**: 1 = identical, 0 = orthogonal, -1 = opposite\n- **KL divergence**: 0 = identical, higher = more different\n- **Spearman correlation**: Ordinal association (-1 to +1)\n\n**⚠️ IMPORTANT: The \"real\" survey data used in this section is simulated for demonstration purposes only. In actual research, you MUST use authentic survey data from sources like ANES, GSS, Pew, or your own validated surveys.**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate real survey data for comparison\n",
    "# (In practice, you'd use actual survey data like ANES or GSS)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create \"real\" data with realistic distributions\n",
    "# Democrats favor Q1 (healthcare), Republicans favor Q2 (defense)\n",
    "real_data = []\n",
    "\n",
    "for party in ['Democrat', 'Republican', 'Independent']:\n",
    "    n = 100\n",
    "    \n",
    "    if party == 'Democrat':\n",
    "        q1 = np.random.choice([3, 4, 5], n, p=[0.2, 0.4, 0.4])  # Pro healthcare\n",
    "        q2 = np.random.choice([1, 2, 3], n, p=[0.4, 0.4, 0.2])  # Anti defense spending\n",
    "    elif party == 'Republican':\n",
    "        q1 = np.random.choice([1, 2, 3], n, p=[0.4, 0.4, 0.2])  # Anti healthcare\n",
    "        q2 = np.random.choice([3, 4, 5], n, p=[0.2, 0.4, 0.4])  # Pro defense\n",
    "    else:  # Independent\n",
    "        q1 = np.random.choice([2, 3, 4], n, p=[0.3, 0.4, 0.3])  # Moderate\n",
    "        q2 = np.random.choice([2, 3, 4], n, p=[0.3, 0.4, 0.3])  # Moderate\n",
    "    \n",
    "    for i in range(n):\n",
    "        real_data.append({\n",
    "            'party': party,\n",
    "            'Q1': q1[i],\n",
    "            'Q2': q2[i]\n",
    "        })\n",
    "\n",
    "df_real = pd.DataFrame(real_data)\n",
    "\n",
    "print(\"'Real' survey data (simulated):\")\n",
    "print(df_real.groupby('party')[['Q1', 'Q2']].mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_cosine_similarity(dist1, dist2):\n    \"\"\"\n    Calculate cosine similarity between two distributions\n    \n    Returns:\n        float: 1 = identical, 0 = orthogonal, -1 = opposite\n    \"\"\"\n    # Ensure same length and normalize\n    dist1 = np.array(dist1) / np.sum(dist1)\n    dist2 = np.array(dist2) / np.sum(dist2)\n    \n    return 1 - cosine(dist1, dist2)\n\ndef calculate_kl_divergence(p, q):\n    \"\"\"\n    Calculate KL divergence from distribution q to p\n    Lower is better (0 = identical)\n    \"\"\"\n    p = np.array(p) / np.sum(p)\n    q = np.array(q) / np.sum(q)\n    \n    # Add small epsilon to avoid division by zero\n    epsilon = 1e-10\n    p = p + epsilon\n    q = q + epsilon\n    \n    return entropy(p, q)\n\n# Compare distributions for Q1 by party\nprint(\"Algorithmic Fidelity Analysis (Q1: Healthcare)\\n\")\nprint(\"=\" * 70)\n\nfor party in ['Democrat', 'Republican']:\n    # Get real distribution\n    real_dist = df_real[df_real['party'] == party]['Q1'].value_counts().sort_index()\n    real_dist = real_dist.reindex([1, 2, 3, 4, 5], fill_value=0).values\n    \n    # For synthetic, we only have 1 sample per party in example\n    # In practice, you'd generate many samples\n    print(f\"\\n{party}:\")\n    print(f\"  Real distribution: {real_dist}\")\n    print(f\"  (Note: Need larger synthetic sample for proper comparison)\")\n\n# Example computation with dummy synthetic data for demonstration\nprint(\"\\n\\nExample fidelity calculations (with hypothetical synthetic data):\")\nprint(\"=\" * 70)\n\n# Create example synthetic distribution for Democrats (hypothetical)\nreal_dem_dist = np.array([40, 40, 20, 0, 0])  # From real_data above\nsynthetic_dem_dist = np.array([35, 45, 15, 5, 0])  # Hypothetical synthetic\n\ncosine_sim = calculate_cosine_similarity(real_dem_dist, synthetic_dem_dist)\nkl_div = calculate_kl_divergence(real_dem_dist, synthetic_dem_dist)\n\nprint(f\"\\nDemocrat Q1 (Healthcare) - Hypothetical comparison:\")\nprint(f\"  Real distribution:      {real_dem_dist}\")\nprint(f\"  Synthetic distribution: {synthetic_dem_dist}\")\nprint(f\"  Cosine similarity: {cosine_sim:.3f}\")\nprint(f\"  KL divergence:     {kl_div:.3f}\")\nprint(f\"\\nInterpretation:\")\nif cosine_sim > 0.9:\n    print(f\"  Excellent match (cosine > 0.9)\")\nelif cosine_sim > 0.7:\n    print(f\"  Good match (cosine 0.7-0.9)\")\nelse:\n    print(f\"  Poor match (cosine < 0.7)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements **algorithmic fidelity metrics** to compare synthetic and real distributions:\n",
    "\n",
    "**Why we need simulated data:**\n",
    "- Real survey data (ANES, GSS) requires download/access\n",
    "- Simulated data lets us demonstrate the metrics\n",
    "- In practice, you'd replace this with actual survey data\n",
    "\n",
    "**Cosine similarity:**\n",
    "- Measures angle between two vectors\n",
    "- **Range**: -1 (opposite) to +1 (identical)\n",
    "- **Interpretation**:\n",
    "  - > 0.9: Excellent match\n",
    "  - 0.7-0.9: Good match (typical in Argyle et al.)\n",
    "  - < 0.7: Poor match\n",
    "- **Advantage**: Scale-invariant (doesn't matter if one dist is larger)\n",
    "\n",
    "**KL divergence (Kullback-Leibler):**\n",
    "- Measures how one distribution differs from another\n",
    "- **Range**: 0 (identical) to ∞ (completely different)\n",
    "- **Interpretation**:\n",
    "  - < 0.1: Excellent match\n",
    "  - 0.1-0.5: Moderate difference\n",
    "  - > 0.5: Large difference\n",
    "- **Asymmetric**: KL(P||Q) ≠ KL(Q||P)\n",
    "- **Sensitive to zeros**: Need epsilon for numerical stability\n",
    "\n",
    "**When to use each:**\n",
    "- **Cosine**: Easier to interpret, symmetric, good for correlation\n",
    "- **KL divergence**: More sensitive to differences, standard in ML\n",
    "- **Report both**: Different perspectives on same comparison\n",
    "\n",
    "**Practical note:** Need large samples (100+ per group) for reliable distribution comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating larger synthetic sample for proper validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate larger synthetic sample (this will take a few minutes and cost ~$0.09-$0.50)\n# Uncomment to run - skipping by default to save API costs\n\n\"\"\"\n# Create diverse demographic profiles\nfrom itertools import product\n\n# Define demographic space\nages = [25, 35, 45, 55, 65]\nraces = ['white', 'Black', 'Hispanic']\ngenders = ['male', 'female']\neducations = ['high school', 'college degree']\nincomes = ['35,000', '65,000', '95,000']\nregions = ['Northeast', 'South', 'Midwest', 'West']\nparties = ['Democrat', 'Republican', 'Independent']\n\n# Generate personas (this creates hundreds of combinations)\n# For demo purposes, sample a subset\nnp.random.seed(42)\n\npersonas = []\nfor party in parties:\n    for i in range(30):  # 30 per party = 90 total\n        persona = {\n            'age': np.random.choice(ages),\n            'race': np.random.choice(races),\n            'gender': np.random.choice(genders),\n            'education': np.random.choice(educations),\n            'income': np.random.choice(incomes),\n            'region': np.random.choice(regions),\n            'party': party\n        }\n        personas.append(persona)\n\n# Collect responses\nsynthetic_results = []\n\nfor i, persona in enumerate(personas, 1):\n    if i % 10 == 0:\n        print(f\"Progress: {i}/{len(personas)}\")\n    \n    responses = collect_responses(persona, questions[:2])  # Just Q1, Q2 for speed\n    result = {**persona, **responses}\n    synthetic_results.append(result)\n\ndf_synthetic_large = pd.DataFrame(synthetic_results)\ndf_synthetic_large.to_csv('synthetic_survey_data.csv', index=False)\n\nprint(\"\\n✓ Large synthetic sample collected and saved\")\n\"\"\"\n\nprint(\"[Skipped to save API costs - uncomment to run]\")\nprint(\"This would generate 90 synthetic respondents\")\nprint(\"Cost estimate: ~$0.09 for completions, up to $0.50 with prompt tokens depending on length\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Demonstrates how to generate a **large-scale synthetic sample** for validation:\n",
    "\n",
    "**The demographic space:**\n",
    "- **Full factorial**: All combinations of demographics\n",
    "- **Sampling strategy**: Random sample from space (more efficient than full grid)\n",
    "- **Stratification**: Equal samples per party (can weight later)\n",
    "\n",
    "**Sample size considerations:**\n",
    "- **Minimum**: 30-50 per group for distribution comparison\n",
    "- **Good**: 100+ per group\n",
    "- **Excellent**: 200+ per group (like Argyle et al.)\n",
    "\n",
    "**Cost calculation:**\n",
    "- 90 personas × 2 questions = 180 API calls\n",
    "- ~$0.0005 per call with GPT-3.5-turbo\n",
    "- Total: ~$0.10-0.50 depending on prompt length\n",
    "\n",
    "**Why commented out:**\n",
    "- Saves API costs for students running the notebook\n",
    "- Takes 5-10 minutes to run\n",
    "- You can uncomment when ready to do real validation\n",
    "\n",
    "**Best practices:**\n",
    "- Save results to CSV after generation\n",
    "- Don't regenerate unnecessarily\n",
    "- Include random seed for reproducibility\n",
    "- Log all parameters (model, temperature, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Diagnosing Invariance\n",
    "\n",
    "**Invariance** refers to the lack of within-group diversity - do all personas with the same demographics give identical answers?\n",
    "\n",
    "**The problem:**\n",
    "- Real humans with same demographics have diverse opinions\n",
    "- LLMs may give identical answers for identical demographics\n",
    "- This underestimates real heterogeneity\n",
    "\n",
    "**How to test:**\n",
    "- Generate multiple responses for same persona\n",
    "- Measure within-persona variance\n",
    "- Compare to human within-group variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test invariance: multiple responses from same persona\n",
    "test_persona = example_personas[0]  # Democrat, 45, white male\n",
    "test_question = questions[0]  # Healthcare\n",
    "\n",
    "print(f\"Testing invariance for persona: {test_persona['party']}, {test_persona['age']}, {test_persona['race']}\")\n",
    "print(f\"Question: {test_question}\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Collect 10 responses from same persona\n",
    "responses = []\n",
    "for i in range(10):\n",
    "    response = silicon_sample_likert(test_persona, test_question)\n",
    "    responses.append(response)\n",
    "    print(f\"Response {i+1}: {response}\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "# Calculate variance\n",
    "responses = [r for r in responses if r is not None]\n",
    "mean_response = np.mean(responses)\n",
    "variance = np.var(responses)\n",
    "std = np.std(responses)\n",
    "\n",
    "print(f\"\\nWithin-persona statistics:\")\n",
    "print(f\"  Mean: {mean_response:.2f}\")\n",
    "print(f\"  Std: {std:.2f}\")\n",
    "print(f\"  Variance: {variance:.2f}\")\n",
    "\n",
    "# Compare to expected human variance\n",
    "# For real data, same-demographic humans typically have std ~ 1.0-1.5 on 5-point scale\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  LLM within-persona std: {std:.2f}\")\n",
    "print(f\"  Expected human within-group std: ~1.0-1.5\")\n",
    "\n",
    "if std < 0.5:\n",
    "    print(f\"  ⚠ High invariance detected (low diversity)\")\n",
    "elif std < 1.0:\n",
    "    print(f\"  ⚠ Moderate invariance (less diverse than humans)\")\n",
    "else:\n",
    "    print(f\"  ✓ Variance comparable to humans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**What this code does:**\n\nTests for **invariance** by repeatedly querying the same persona:\n\n**The invariance problem:**\n- Real humans: Same demographics ≠ identical opinions\n- LLMs: May produce very similar responses for identical personas\n- This **underestimates real heterogeneity**\n\n**Why invariance happens:**\n- Temperature > 0 adds randomness, but not enough\n- Models average over training data\n- Stereotypical \"typical\" response for each demographic\n- Missing individual-level factors (personality, experiences, etc.)\n\n**What we measure:**\n- **Mean**: Average response for persona\n- **Std (standard deviation)**: Spread of responses\n- **Variance**: Squared std\n\n**Interpretation:**\n- **Std < 0.5**: High invariance (responses very similar)\n- **Std 0.5-1.0**: Moderate diversity (less than humans)\n- **Std > 1.0**: Good diversity (approaching human levels)\n\n**Note on thresholds with temperature=1.0:**\n- With temperature=1.0, LLM variance is typically higher than with temperature=0\n- However, the thresholds above (< 0.5, 0.5-1.0, > 1.0) still apply because they're calibrated against human within-group variance\n- Even with temperature=1.0, LLMs often show variance around 0.3-0.8, which is still less than typical human variance of 1.0-1.5\n- The higher temperature helps but doesn't fully solve the invariance problem\n\n**Typical observations:**\n- LLMs: Std ~ 0.3-0.8 (varies by question and model)\n- Humans: Std ~ 1.0-1.5 on same demographic\n- **Implication**: LLMs underestimate within-group diversity\n\n**Bisbee et al. (2024) finding:**\n- Invariance worse for identity-salient questions\n- Better for non-political factual questions\n- Larger models (GPT-4) show slightly better diversity than GPT-3.5\n\n**Solutions:**\n- Higher temperature (but may reduce accuracy)\n- Add personality traits to personas\n- Fine-tune on diverse real responses\n- Acknowledge limitation in reporting"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Diagnosing Stereotyping\n",
    "\n",
    "**Stereotyping** occurs when LLMs exaggerate between-group differences compared to real data.\n",
    "\n",
    "**The problem:**\n",
    "- LLMs trained on text that often contains stereotypes\n",
    "- May amplify partisan/demographic differences\n",
    "- Creates artificial polarization\n",
    "\n",
    "**How to test:**\n",
    "- Compare effect sizes for demographics in synthetic vs real data\n",
    "- Look for exaggerated differences between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze stereotyping: between-group differences\n",
    "\n",
    "# For demonstration, generate synthetic data for Democrats vs Republicans\n",
    "print(\"Generating responses from 5 Democrats and 5 Republicans...\\n\")\n",
    "\n",
    "stereotyping_data = []\n",
    "\n",
    "for party in ['Democrat', 'Republican']:\n",
    "    for i in range(5):\n",
    "        persona = {\n",
    "            'age': 45 + i * 5,\n",
    "            'race': 'white',\n",
    "            'gender': 'male' if i % 2 == 0 else 'female',\n",
    "            'education': 'college degree',\n",
    "            'income': '75,000',\n",
    "            'region': 'Midwest',\n",
    "            'party': party\n",
    "        }\n",
    "        \n",
    "        response = silicon_sample_likert(persona, questions[0])  # Healthcare question\n",
    "        stereotyping_data.append({\n",
    "            'party': party,\n",
    "            'response': response\n",
    "        })\n",
    "        time.sleep(0.3)\n",
    "\n",
    "df_stereotyping = pd.DataFrame(stereotyping_data)\n",
    "\n",
    "# Calculate means and effect size\n",
    "dem_mean = df_stereotyping[df_stereotyping['party'] == 'Democrat']['response'].mean()\n",
    "rep_mean = df_stereotyping[df_stereotyping['party'] == 'Republican']['response'].mean()\n",
    "\n",
    "# Cohen's d (effect size)\n",
    "pooled_std = df_stereotyping.groupby('party')['response'].std().mean()\n",
    "cohens_d = (dem_mean - rep_mean) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "print(\"\\nBetween-group analysis (Healthcare question):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDemocrat mean: {dem_mean:.2f}\")\n",
    "print(f\"Republican mean: {rep_mean:.2f}\")\n",
    "print(f\"Difference: {abs(dem_mean - rep_mean):.2f}\")\n",
    "print(f\"Cohen's d: {abs(cohens_d):.2f}\")\n",
    "\n",
    "print(f\"\\nEffect size interpretation:\")\n",
    "if abs(cohens_d) < 0.5:\n",
    "    print(\"  Small effect (< 0.5)\")\n",
    "elif abs(cohens_d) < 0.8:\n",
    "    print(\"  Medium effect (0.5-0.8)\")\n",
    "else:\n",
    "    print(\"  Large effect (> 0.8)\")\n",
    "    print(\"  ⚠ May indicate stereotyping if larger than real data\")\n",
    "\n",
    "print(f\"\\nNote: Compare this to real survey data Cohen's d\")\n",
    "print(f\"If synthetic d >> real d, this suggests stereotyping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Tests for **stereotyping** by measuring between-group differences:\n",
    "\n",
    "**What is stereotyping in silicon sampling:**\n",
    "- LLMs may exaggerate differences between demographic groups\n",
    "- E.g., making Democrats MORE pro-healthcare than real Democrats\n",
    "- Or Republicans MORE anti-healthcare than real Republicans\n",
    "- Creates artificial polarization\n",
    "\n",
    "**Cohen's d (effect size):**\n",
    "- Standardized measure of group difference\n",
    "- **Formula**: (Mean1 - Mean2) / Pooled SD\n",
    "- **Interpretation**:\n",
    "  - d < 0.5: Small effect\n",
    "  - d = 0.5-0.8: Medium effect\n",
    "  - d > 0.8: Large effect\n",
    "\n",
    "**How to detect stereotyping:**\n",
    "1. Calculate Cohen's d for synthetic data\n",
    "2. Calculate Cohen's d for real data\n",
    "3. Compare: If synthetic d >> real d, stereotyping present\n",
    "\n",
    "**Example:**\n",
    "- Real data: Democrat vs Republican on healthcare, d = 1.2\n",
    "- Synthetic: d = 2.4\n",
    "- **Interpretation**: LLM is doubling the partisan divide\n",
    "\n",
    "**Why stereotyping happens:**\n",
    "- Training data contains exaggerated partisan rhetoric\n",
    "- News articles emphasize differences\n",
    "- Social media polarization in training data\n",
    "- Models learn \"prototypical\" Democrat/Republican\n",
    "\n",
    "**Bisbee et al. (2024) findings:**\n",
    "- Stereotyping worse for:\n",
    "  - Morally charged issues (abortion, guns)\n",
    "  - Identity-salient topics (race, gender)\n",
    "  - Minority subgroups (underrepresented in training)\n",
    "- Better for:\n",
    "  - Non-political topics\n",
    "  - Aggregate estimates (averaging reduces bias)\n",
    "\n",
    "**Solutions:**\n",
    "- Compare effect sizes to real data (essential validation step)\n",
    "- Avoid using for identity-salient questions\n",
    "- Consider weighting/calibrating to match real distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: When Does Silicon Sampling Work? (Bisbee et al. 2024)\n",
    "\n",
    "Based on Bisbee et al. (2024), silicon sampling has clear **boundary conditions**.\n",
    "\n",
    "### When it works:\n",
    "- ✓ High-consensus topics (e.g., basic civic knowledge)\n",
    "- ✓ Non-identity-salient issues\n",
    "- ✓ Aggregate-level estimates\n",
    "- ✓ Larger models (GPT-4 > GPT-3.5)\n",
    "\n",
    "### When it fails:\n",
    "- ✗ Morally charged issues (abortion, immigration)\n",
    "- ✗ Identity-salient topics (racial attitudes, gender policies)\n",
    "- ✗ Minority subgroups (underrepresented in training)\n",
    "- ✗ Individual-level predictions\n",
    "\n",
    "### Appropriate use cases:\n",
    "1. **Question development**: Test survey instruments before fielding\n",
    "2. **Exploratory research**: Generate hypotheses to test with real data\n",
    "3. **Education**: Teach survey methodology\n",
    "4. **Augmentation**: Supplement small real samples (with caution)\n",
    "\n",
    "### Inappropriate use cases:\n",
    "1. ✗ Replacing representative surveys\n",
    "2. ✗ Studying marginalized populations\n",
    "3. ✗ Making substantive claims about \"public opinion\"\n",
    "4. ✗ High-stakes decisions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we learned:**\n",
    "1. ✓ How to construct **demographic personas** following Argyle et al. (2023)\n",
    "2. ✓ How to generate **synthetic survey responses** with LLMs\n",
    "3. ✓ How to measure **algorithmic fidelity** (cosine similarity, KL divergence)\n",
    "4. ✓ How to diagnose **invariance** (within-group diversity)\n",
    "5. ✓ How to diagnose **stereotyping** (exaggerated between-group differences)\n",
    "6. ✓ **Boundary conditions** for when silicon sampling works (Bisbee et al. 2024)\n",
    "\n",
    "**Key insights:**\n",
    "- Silicon sampling can **approximate** population distributions for some questions\n",
    "- But faces serious challenges: **invariance** and **stereotyping**\n",
    "- Works best for **non-controversial, aggregate-level** estimates\n",
    "- Fails for **identity-salient, morally charged** topics\n",
    "- **Validation** against real data is essential\n",
    "\n",
    "**Historical context:**\n",
    "- Before LLMs: ABMs, synthetic populations, MRP, multiple imputation\n",
    "- LLMs add: Flexible generation, natural language, few-shot learning\n",
    "- But: Less principled uncertainty quantification than traditional methods\n",
    "\n",
    "**Validation metrics:**\n",
    "\n",
    "| Metric | What it measures | Target |\n",
    "|--------|------------------|--------|\n",
    "| Cosine similarity | Distribution match | > 0.7 |\n",
    "| KL divergence | Distribution difference | < 0.5 |\n",
    "| Within-group std | Invariance | > 1.0 |\n",
    "| Cohen's d ratio | Stereotyping | ≈ 1.0 |\n",
    "\n",
    "**Best practices:**\n",
    "1. Always validate against real survey data\n",
    "2. Report all three challenges (fidelity, invariance, stereotyping)\n",
    "3. Use for exploration, not substitution\n",
    "4. Be transparent about limitations\n",
    "5. Consider ethical implications\n",
    "\n",
    "**Ethical considerations:**\n",
    "- Risk of reproducing harmful stereotypes\n",
    "- Collapsing diversity within demographic groups\n",
    "- Claiming to represent voices not consulted\n",
    "- Must disclose use of synthetic data\n",
    "\n",
    "**Next steps:**\n",
    "- **Week 8**: Interactive simulations and behavioral experiments with LLMs\n",
    "- **Week 9**: Generative agents and multi-agent systems\n",
    "- **Week 10**: Using LLMs to predict experimental outcomes\n",
    "\n",
    "**Further reading:**\n",
    "- Argyle et al. (2023): \"Out of One, Many: Using Language Models to Simulate Human Samples\"\n",
    "- Bisbee et al. (2024): \"Synthetic Replacements for Human Survey Data? The Perils of Large Language Models\"\n",
    "- Boelaert & Ollion (2025): \"AI-Augmented Surveys: Assessing the Scope and Validity of Silicon Sampling\"\n",
    "- Kozlowski & Evans (2025): \"Machine learning as a model for cultural learning\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Generate your own synthetic sample**: Create 50 personas (uncomment the large-scale generation code) and compare to real ANES/GSS data. Calculate cosine similarity and KL divergence.\n",
    "\n",
    "2. **Test boundary conditions**: Choose a controversial topic (e.g., abortion, immigration) and a non-controversial one (e.g., liking pizza). Compare fidelity, invariance, and stereotyping across both.\n",
    "\n",
    "3. **Model comparison**: Generate responses using both GPT-3.5-turbo and GPT-4. Do larger models show better fidelity and less stereotyping?\n",
    "\n",
    "4. **Temperature experiment**: For the same persona and question, vary temperature from 0.1 to 2.0. How does this affect within-persona variance?\n",
    "\n",
    "5. **Intersectionality**: Test if LLMs capture intersectional effects (e.g., Black women vs white women vs Black men) or just additive demographic effects.\n",
    "\n",
    "6. **Real data validation**: Download SubPOP data (github.com/JosephJeesungSuh/subpop), generate synthetic responses for the same questions, and calculate validation metrics.\n",
    "\n",
    "7. **Ethical analysis**: Write a 1-page reflection on the ethical implications of using silicon sampling to study marginalized groups without their consent.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}