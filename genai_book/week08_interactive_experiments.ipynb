{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs for Synthetic Data II - Behavioral Tests\n",
    "\n",
    "**Learning objectives:**\n",
    "- Use LLMs to generate personalized persuasive messages for human experiments\n",
    "- Design message variants tailored to demographic characteristics\n",
    "- Create experimental materials at scale for behavioral tests\n",
    "- Implement multi-turn conversational scripts\n",
    "- Generate personalized outcome measures (Velez & Liu approach)\n",
    "\n",
    "**How to run this notebook:**\n",
    "- **Google Colab** (recommended): Works for all parts\n",
    "- **OpenAI API key needed**: For generating experimental materials\n",
    "\n",
    "**Key papers:**\n",
    "- **Argyle et al. (2023)**: \"Leveraging AI for Democratic Discourse\"\n",
    "- **Velez & Liu (2024)**: \"Algorithmic Persuasion With LLMs\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: LLMs as Message Generators\n",
    "\n",
    "**The Research Problem:**\n",
    "\n",
    "Traditional persuasion experiments require researchers to manually write multiple message variants:\n",
    "- Generic messages (one-size-fits-all)\n",
    "- Demographic-targeted messages (age, education, location)\n",
    "- Personalized messages (individual-level customization)\n",
    "- Control conditions\n",
    "\n",
    "For even a modest experiment:\n",
    "- 5 demographic groups × 3 message types = 15 unique messages\n",
    "- Multiple topics = even more messages\n",
    "- Conversational experiments = exponentially more content\n",
    "\n",
    "**The LLM Solution:**\n",
    "\n",
    "Use LLMs to **generate** experimental materials at scale:\n",
    "1. Generate message variants automatically\n",
    "2. Tailor messages to demographic characteristics\n",
    "3. Create personalized content for each participant\n",
    "4. Generate conversational scripts\n",
    "5. Create custom outcome measures\n",
    "\n",
    "**IMPORTANT: Testing on Real Humans**\n",
    "\n",
    "This notebook shows how to **generate messages** using LLMs. These messages are then:\n",
    "- Tested on **real human participants** (not LLMs)\n",
    "- Deployed via survey platforms (Qualtrics, MTurk, Prolific)\n",
    "- Measured using standard human survey methods\n",
    "\n",
    "We cannot replicate actual human experiments in this notebook (no real subjects), but we provide:\n",
    "- Code to generate all experimental materials\n",
    "- Examples of message variants\n",
    "- Templates for deploying to human subjects\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q openai pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set API key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Generating Generic Messages\n",
    "\n",
    "**Generic messages**: The same message shown to all participants\n",
    "\n",
    "**Use cases:**\n",
    "- Control condition in experiments\n",
    "- Baseline for comparison with targeted messages\n",
    "- Cost-effective campaigns\n",
    "\n",
    "**Argyle et al. (2023) finding:** Generic messages were just as effective as microtargeted ones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generic_message(topic, position, tone=\"neutral\", model=\"gpt-4o\", temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate generic persuasive message for human participants\n",
    "    \n",
    "    Args:\n",
    "        topic: Policy or issue (e.g., \"universal basic income\")\n",
    "        position: 'support' or 'oppose'\n",
    "        tone: 'neutral', 'emotional', 'factual'\n",
    "        model: Which OpenAI model to use\n",
    "        temperature: Creativity level\n",
    "    \n",
    "    Returns:\n",
    "        str: Persuasive message text\n",
    "    \"\"\"\n",
    "    tone_instructions = {\n",
    "        \"neutral\": \"Use balanced, moderate language\",\n",
    "        \"emotional\": \"Appeal to emotions and values\",\n",
    "        \"factual\": \"Focus on data, statistics, and evidence\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"Write a brief persuasive message (2-3 sentences) that argues people should {position} the following policy:\n",
    "\n",
    "{topic}\n",
    "\n",
    "Requirements:\n",
    "- {tone_instructions.get(tone, tone_instructions['neutral'])}\n",
    "- Be concise and clear\n",
    "- Be respectful and non-manipulative\n",
    "- Appropriate for a general adult audience\n",
    "\n",
    "Return only the message text, no preamble or explanation.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Example: Generate messages for different topics\n",
    "topics = [\n",
    "    \"Increasing government funding for renewable energy research\",\n",
    "    \"Implementing universal basic income\",\n",
    "    \"Expanding public transportation infrastructure\"\n",
    "]\n",
    "\n",
    "print(\"Generic Messages for Human Experiment\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, topic in enumerate(topics, 1):\n",
    "    print(f\"\\nTopic {i}: {topic}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Generate support message\n",
    "    support_msg = generate_generic_message(topic, \"support\", tone=\"factual\")\n",
    "    print(f\"\\nSupport message:\\n\\\"{support_msg}\\\"\")\n",
    "    \n",
    "    # Generate oppose message\n",
    "    oppose_msg = generate_generic_message(topic, \"oppose\", tone=\"factual\")\n",
    "    print(f\"\\nOppose message:\\n\\\"{oppose_msg}\\\"\")\n",
    "    \n",
    "    time.sleep(1)  # Rate limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Generates **generic persuasive messages** for use in human experiments:\n",
    "\n",
    "**Key parameters:**\n",
    "- **Topic**: The policy/issue being tested\n",
    "- **Position**: Support or oppose\n",
    "- **Tone**: Neutral, emotional, or factual framing\n",
    "- **Temperature**: 0.8 allows creative variation while maintaining quality\n",
    "\n",
    "**How to use in real experiments:**\n",
    "1. Generate messages for your experimental conditions\n",
    "2. Review and potentially edit for quality/appropriateness\n",
    "3. Insert into survey platform (Qualtrics, SurveyMonkey, etc.)\n",
    "4. Show to real human participants\n",
    "5. Measure attitude change with standard survey items\n",
    "\n",
    "**Advantages:**\n",
    "- Fast generation of multiple variants\n",
    "- Consistent structure across conditions\n",
    "- Easy to test many topics\n",
    "\n",
    "**Quality control:**\n",
    "- Always review generated messages\n",
    "- Check for factual accuracy\n",
    "- Ensure ethical appropriateness\n",
    "- Test pilot versions on small samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Generating Microtargeted Messages\n",
    "\n",
    "**Microtargeted messages**: Tailored to demographic characteristics\n",
    "\n",
    "**Targeting dimensions:**\n",
    "- Age groups (18-24, 25-34, 35-44, etc.)\n",
    "- Education levels (high school, college, graduate)\n",
    "- Geographic regions\n",
    "- Income brackets\n",
    "- Political affiliation\n",
    "\n",
    "**Research question:** Does personalization increase persuasiveness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_microtargeted_message(topic, position, demographics, model=\"gpt-4o\", temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate demographically-targeted persuasive message\n",
    "    \n",
    "    Args:\n",
    "        topic: Policy or issue\n",
    "        position: 'support' or 'oppose'\n",
    "        demographics: Dict with targeting attributes\n",
    "        model: Which OpenAI model\n",
    "        temperature: Creativity level\n",
    "    \n",
    "    Returns:\n",
    "        str: Targeted message text\n",
    "    \"\"\"\n",
    "    # Build demographic description\n",
    "    demo_desc = []\n",
    "    if 'age_group' in demographics:\n",
    "        demo_desc.append(f\"Age group: {demographics['age_group']}\")\n",
    "    if 'education' in demographics:\n",
    "        demo_desc.append(f\"Education: {demographics['education']}\")\n",
    "    if 'region' in demographics:\n",
    "        demo_desc.append(f\"Region: {demographics['region']}\")\n",
    "    if 'income' in demographics:\n",
    "        demo_desc.append(f\"Income level: {demographics['income']}\")\n",
    "    \n",
    "    demo_string = \"\\n\".join([f\"- {d}\" for d in demo_desc])\n",
    "    \n",
    "    prompt = f\"\"\"Write a brief persuasive message (2-3 sentences) that argues people should {position} this policy:\n",
    "\n",
    "{topic}\n",
    "\n",
    "Target this message to resonate with people who have these characteristics:\n",
    "{demo_string}\n",
    "\n",
    "Requirements:\n",
    "- Use language and examples appropriate for this demographic\n",
    "- Focus on values and concerns likely important to them\n",
    "- Be concise, factual, and respectful\n",
    "- Avoid stereotyping or manipulation\n",
    "\n",
    "Return only the message text, no preamble.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Example: Generate targeted messages for different demographic groups\n",
    "topic = \"Increasing government funding for renewable energy research\"\n",
    "\n",
    "demographic_groups = [\n",
    "    {\n",
    "        \"name\": \"Young Professionals\",\n",
    "        \"age_group\": \"25-34\",\n",
    "        \"education\": \"College degree\",\n",
    "        \"region\": \"Urban areas\",\n",
    "        \"income\": \"Middle to upper-middle class\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Working Class Families\",\n",
    "        \"age_group\": \"35-54\",\n",
    "        \"education\": \"High school or some college\",\n",
    "        \"region\": \"Suburban and rural areas\",\n",
    "        \"income\": \"Lower to middle class\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Retirees\",\n",
    "        \"age_group\": \"65+\",\n",
    "        \"education\": \"Varies\",\n",
    "        \"region\": \"All regions\",\n",
    "        \"income\": \"Fixed income\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Microtargeted Messages for Human Experiment\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTopic: {topic}\\n\")\n",
    "\n",
    "for group in demographic_groups:\n",
    "    print(f\"\\nTarget: {group['name']}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Demographics:\")\n",
    "    print(f\"  Age: {group['age_group']}\")\n",
    "    print(f\"  Education: {group['education']}\")\n",
    "    print(f\"  Region: {group['region']}\")\n",
    "    print(f\"  Income: {group['income']}\")\n",
    "    \n",
    "    message = generate_microtargeted_message(topic, \"support\", group)\n",
    "    print(f\"\\nTargeted message:\\n\\\"{message}\\\"\")\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Generates **demographically-targeted messages** for different participant groups:\n",
    "\n",
    "**Targeting strategy:**\n",
    "- Identifies key demographic attributes\n",
    "- Tailors language, examples, and framing\n",
    "- Focuses on group-relevant concerns\n",
    "\n",
    "**Key finding from Argyle et al. (2023):**\n",
    "- Microtargeting **did NOT** significantly outperform generic messages\n",
    "- Simple approaches may be just as effective\n",
    "- But still useful for testing personalization theories\n",
    "\n",
    "**Experimental design:**\n",
    "1. **Random assignment**: Assign participants to demographic-matched condition\n",
    "2. **Between-subjects**: Each participant sees one message type\n",
    "3. **Pre-post measurement**: Measure attitudes before and after message\n",
    "4. **Comparison**: Test if targeted messages > generic messages\n",
    "\n",
    "**Implementation in real study:**\n",
    "```python\n",
    "# In Qualtrics/survey platform:\n",
    "# 1. Collect demographic info\n",
    "# 2. Use embedded data to select appropriate message\n",
    "# 3. Display message to participant\n",
    "# 4. Measure outcome with Likert scales\n",
    "```\n",
    "\n",
    "**Ethical considerations:**\n",
    "- Avoid stereotyping\n",
    "- Don't exploit vulnerabilities\n",
    "- Transparent about targeting (if required by IRB)\n",
    "- Monitor for unintended harmful effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Batch Message Generation for Experiments\n",
    "\n",
    "For real experiments, we need to generate many message variants:\n",
    "- Multiple topics\n",
    "- Multiple demographic groups\n",
    "- Pro and con versions\n",
    "- Control conditions\n",
    "\n",
    "Let's create a systematic pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experiment_materials(topics, demographic_groups, include_generic=True, include_control=True):\n",
    "    \"\"\"\n",
    "    Generate complete set of experimental materials\n",
    "    \n",
    "    Args:\n",
    "        topics: List of policy topics (strings)\n",
    "        demographic_groups: List of demographic dicts\n",
    "        include_generic: Whether to generate generic messages\n",
    "        include_control: Whether to include control (no message) condition\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: All experimental materials\n",
    "    \"\"\"\n",
    "    materials = []\n",
    "    \n",
    "    for topic in topics:\n",
    "        print(f\"\\nGenerating materials for: {topic}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Control condition\n",
    "        if include_control:\n",
    "            materials.append({\n",
    "                'topic': topic,\n",
    "                'condition': 'control',\n",
    "                'demographic_target': 'all',\n",
    "                'message': '[No message shown - control condition]',\n",
    "                'position': 'none'\n",
    "            })\n",
    "        \n",
    "        # Generic messages\n",
    "        if include_generic:\n",
    "            print(\"  Generating generic messages...\")\n",
    "            for position in ['support', 'oppose']:\n",
    "                message = generate_generic_message(topic, position, tone=\"factual\")\n",
    "                materials.append({\n",
    "                    'topic': topic,\n",
    "                    'condition': 'generic',\n",
    "                    'demographic_target': 'all',\n",
    "                    'message': message,\n",
    "                    'position': position\n",
    "                })\n",
    "                time.sleep(0.5)\n",
    "        \n",
    "        # Microtargeted messages\n",
    "        print(\"  Generating microtargeted messages...\")\n",
    "        for group in demographic_groups:\n",
    "            for position in ['support', 'oppose']:\n",
    "                message = generate_microtargeted_message(topic, position, group)\n",
    "                materials.append({\n",
    "                    'topic': topic,\n",
    "                    'condition': 'microtargeted',\n",
    "                    'demographic_target': group['name'],\n",
    "                    'message': message,\n",
    "                    'position': position,\n",
    "                    **group  # Include demographic details\n",
    "                })\n",
    "                time.sleep(0.5)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✓ Materials generation complete!\")\n",
    "    \n",
    "    return pd.DataFrame(materials)\n",
    "\n",
    "\n",
    "# Example: Generate materials for small experiment\n",
    "experiment_topics = [\n",
    "    \"Increasing minimum wage to $15/hour\",\n",
    "    \"Implementing carbon tax on emissions\"\n",
    "]\n",
    "\n",
    "target_groups = [\n",
    "    {\n",
    "        \"name\": \"Young Adults\",\n",
    "        \"age_group\": \"18-29\",\n",
    "        \"education\": \"Some college or college degree\",\n",
    "        \"region\": \"Urban\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Middle-Aged Workers\",\n",
    "        \"age_group\": \"40-55\",\n",
    "        \"education\": \"High school or some college\",\n",
    "        \"region\": \"Suburban\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Generating Complete Experimental Materials\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "materials_df = generate_experiment_materials(\n",
    "    experiment_topics,\n",
    "    target_groups,\n",
    "    include_generic=True,\n",
    "    include_control=True\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(materials_df)} experimental conditions\")\n",
    "print(\"\\nSample of materials:\")\n",
    "print(materials_df[['topic', 'condition', 'demographic_target', 'position']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Creates a **complete set of experimental materials** ready for deployment:\n",
    "\n",
    "**Output structure:**\n",
    "- Control conditions (no message)\n",
    "- Generic messages (all demographics)\n",
    "- Microtargeted messages (per demographic group)\n",
    "- Both support and oppose positions\n",
    "\n",
    "**Example experiment design:**\n",
    "- 2 topics × (1 control + 2 generic + 4 targeted) = 14 conditions\n",
    "- Each condition assigned to ~50-100 participants\n",
    "- Total sample size: 700-1400 participants\n",
    "\n",
    "**Next steps for real experiment:**\n",
    "1. **Export materials**: Save DataFrame to CSV\n",
    "2. **Review and edit**: Check all messages for quality\n",
    "3. **Upload to survey platform**: Import to Qualtrics/similar\n",
    "4. **Set up randomization**: Assign participants to conditions\n",
    "5. **Deploy and collect data**: Run experiment with real humans\n",
    "6. **Analyze results**: Compare effectiveness across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export materials for use in real experiment\n",
    "output_file = \"experimental_materials.csv\"\n",
    "materials_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Experimental materials exported to: {output_file}\")\n",
    "print(\"\\nTo use in your experiment:\")\n",
    "print(\"1. Review and edit messages as needed\")\n",
    "print(\"2. Import CSV to your survey platform\")\n",
    "print(\"3. Set up random assignment logic\")\n",
    "print(\"4. Add pre/post attitude measurements\")\n",
    "print(\"5. Deploy to real human participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Generating Multi-Turn Conversational Scripts\n",
    "\n",
    "**Argyle et al. (2023)** tested whether multi-turn conversations are more persuasive than one-shot messages.\n",
    "\n",
    "**Research question:** Does elaboration through dialogue increase persuasion?\n",
    "\n",
    "**Implementation challenge:** Can't have live AI conversations in most surveys\n",
    "\n",
    "**Solution:** Generate pre-scripted conversation paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation_script(topic, position, n_turns=3, strategy=\"direct\", model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Generate multi-turn conversation script for human experiment\n",
    "    \n",
    "    Args:\n",
    "        topic: Policy or issue\n",
    "        position: 'support' or 'oppose'\n",
    "        n_turns: Number of exchanges\n",
    "        strategy: 'direct' (persuasive) or 'motivational' (reflective)\n",
    "        model: Which model to use\n",
    "    \n",
    "    Returns:\n",
    "        list: Conversation turns\n",
    "    \"\"\"\n",
    "    if strategy == \"direct\":\n",
    "        approach = \"Use clear, persuasive arguments. Be direct but respectful.\"\n",
    "    else:  # motivational\n",
    "        approach = \"Use motivational interviewing: ask open-ended questions, reflect concerns, explore ambivalence.\"\n",
    "    \n",
    "    prompt = f\"\"\"Create a {n_turns}-turn conversation script for a persuasion experiment.\n",
    "\n",
    "Topic: {topic}\n",
    "Position: {position}\n",
    "Strategy: {approach}\n",
    "\n",
    "Generate {n_turns} messages from a persuader trying to convince someone.\n",
    "Each message should be 2-3 sentences.\n",
    "Build on previous points, don't just repeat.\n",
    "\n",
    "Format as:\n",
    "Turn 1: [message]\n",
    "Turn 2: [message]\n",
    "Turn 3: [message]\n",
    "\n",
    "Return only the turns, no additional text.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    # Parse turns\n",
    "    turns = []\n",
    "    for line in content.split('\\n'):\n",
    "        if line.strip().startswith('Turn'):\n",
    "            # Extract message after \"Turn X:\"\n",
    "            parts = line.split(':', 1)\n",
    "            if len(parts) == 2:\n",
    "                turns.append(parts[1].strip())\n",
    "    \n",
    "    return turns\n",
    "\n",
    "\n",
    "# Example: Generate conversation scripts\n",
    "topic = \"Implementing universal basic income\"\n",
    "\n",
    "print(\"Multi-Turn Conversation Scripts for Human Experiment\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTopic: {topic}\\n\")\n",
    "\n",
    "# Direct persuasion\n",
    "print(\"STRATEGY 1: Direct Persuasion\")\n",
    "print(\"-\" * 70)\n",
    "direct_script = generate_conversation_script(topic, \"support\", n_turns=3, strategy=\"direct\")\n",
    "for i, turn in enumerate(direct_script, 1):\n",
    "    print(f\"\\nTurn {i}:\\n{turn}\")\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Motivational interviewing\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STRATEGY 2: Motivational Interviewing\")\n",
    "print(\"-\" * 70)\n",
    "motivational_script = generate_conversation_script(topic, \"support\", n_turns=3, strategy=\"motivational\")\n",
    "for i, turn in enumerate(motivational_script, 1):\n",
    "    print(f\"\\nTurn {i}:\\n{turn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Generates **pre-scripted conversation sequences** for human experiments:\n",
    "\n",
    "**Two strategies tested:**\n",
    "\n",
    "1. **Direct persuasion**:\n",
    "   - Straightforward arguments\n",
    "   - Facts and logic\n",
    "   - Traditional approach\n",
    "\n",
    "2. **Motivational interviewing**:\n",
    "   - Reflective listening\n",
    "   - Open-ended questions\n",
    "   - Collaborative approach\n",
    "\n",
    "**Implementation in survey:**\n",
    "```\n",
    "Page 1: Show Turn 1 message → Participant reads\n",
    "Page 2: Ask for response (optional) → Show Turn 2\n",
    "Page 3: Show Turn 3 → Measure final attitude\n",
    "```\n",
    "\n",
    "**Argyle et al. (2023) findings:**\n",
    "- Multi-turn conversations DID produce persuasion\n",
    "- BUT: Not significantly more than one-shot messages\n",
    "- Direct vs motivational: No significant difference\n",
    "- **Implication**: Simple may be as effective as complex\n",
    "\n",
    "**Why use multi-turn anyway:**\n",
    "- Tests elaboration theory\n",
    "- More engaging for participants\n",
    "- Mimics real-world conversations\n",
    "- Allows measuring dynamics over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Personalized Outcomes (Velez & Liu Approach)\n",
    "\n",
    "**Velez & Liu (2024)** innovation: Personalize BOTH treatment AND outcome measures\n",
    "\n",
    "**Standard approach:**\n",
    "- Researcher picks topic (e.g., \"climate change\")\n",
    "- All participants respond to same topic\n",
    "\n",
    "**Velez & Liu approach:**\n",
    "- Let EACH participant identify their core issue\n",
    "- Generate personalized persuasive arguments\n",
    "- Create custom attitude measures\n",
    "- Test persuasion on THEIR specific concern\n",
    "\n",
    "**Advantage:** Maximum relevance and engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_personalized_scales(issue_description, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Generate personalized Likert scale items for participant's core issue\n",
    "    \n",
    "    Args:\n",
    "        issue_description: Participant's open-ended description of their concern\n",
    "        model: Which model to use\n",
    "    \n",
    "    Returns:\n",
    "        dict: Scale items and summary\n",
    "    \"\"\"\n",
    "    # Step 1: Summarize the issue\n",
    "    summary_prompt = f\"\"\"Summarize this person's political concern in ONE clear sentence:\n",
    "\n",
    "{issue_description}\n",
    "\n",
    "Return only the summary sentence, no additional text.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    summary = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # Step 2: Generate personalized scale items\n",
    "    scale_prompt = f\"\"\"Create 3 Likert scale items to measure attitude about:\n",
    "\n",
    "{summary}\n",
    "\n",
    "Requirements:\n",
    "- Each item = clear statement (not question)\n",
    "- Measure different aspects: strength, certainty, priority\n",
    "- Use language from their concern\n",
    "- Suitable for 1-7 scale (Strongly Disagree → Strongly Agree)\n",
    "\n",
    "Format:\n",
    "1. [item]\n",
    "2. [item]\n",
    "3. [item]\n",
    "\n",
    "Return only the numbered items.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": scale_prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    scale_items = response.choices[0].message.content.strip()\n",
    "    \n",
    "    return {\n",
    "        'original_description': issue_description,\n",
    "        'summary': summary,\n",
    "        'scale_items': scale_items\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_personalized_arguments(summary, stance, intensity=\"moderate\", model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Generate pro/con arguments about participant's specific issue\n",
    "    \n",
    "    Args:\n",
    "        summary: One-sentence summary of their concern\n",
    "        stance: 'pro' (supports their position) or 'con' (opposes it)\n",
    "        intensity: 'moderate', 'strong', or 'vitriolic'\n",
    "        model: Which model\n",
    "    \n",
    "    Returns:\n",
    "        str: Personalized argument\n",
    "    \"\"\"\n",
    "    tone_map = {\n",
    "        \"moderate\": \"respectful and factual\",\n",
    "        \"strong\": \"strongly worded but still civil\",\n",
    "        \"vitriolic\": \"harsh and uncivil (for research purposes only)\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"Write a {tone_map[intensity]} argument that {'supports' if stance == 'pro' else 'opposes'}:\n",
    "\n",
    "{summary}\n",
    "\n",
    "Make it 2-3 sentences. Return only the argument text.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Example: Velez & Liu personalized pipeline\n",
    "example_responses = [\n",
    "    \"\"\"Healthcare costs are bankrupting families. I believe we need universal \n",
    "    healthcare so that no one has to choose between medical treatment and financial \n",
    "    ruin. The current system is unsustainable and morally wrong.\"\"\",\n",
    "    \n",
    "    \"\"\"Immigration enforcement is too weak. We need stronger border security and \n",
    "    more strict enforcement of immigration laws to protect American workers and \n",
    "    maintain national sovereignty.\"\"\",\n",
    "    \n",
    "    \"\"\"Climate change is the defining crisis of our generation. We must take \n",
    "    immediate aggressive action to transition to renewable energy and reduce \n",
    "    emissions before it's too late.\"\"\"\n",
    "]\n",
    "\n",
    "print(\"Personalized Outcome Materials (Velez & Liu Approach)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, response in enumerate(example_responses, 1):\n",
    "    print(f\"\\n\\nPARTICIPANT {i}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nOriginal response:\\n{response}\")\n",
    "    \n",
    "    # Generate personalized materials\n",
    "    scales = generate_personalized_scales(response)\n",
    "    \n",
    "    print(f\"\\nSummary: {scales['summary']}\")\n",
    "    print(f\"\\nPersonalized scale items:\\n{scales['scale_items']}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Generate pro argument\n",
    "    pro_arg = generate_personalized_arguments(scales['summary'], 'pro', 'moderate')\n",
    "    print(f\"\\nSupporting argument:\\n\\\"{pro_arg}\\\"\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Generate con argument\n",
    "    con_arg = generate_personalized_arguments(scales['summary'], 'con', 'moderate')\n",
    "    print(f\"\\nOpposing argument:\\n\\\"{con_arg}\\\"\")\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements **Velez & Liu's personalized outcome approach**:\n",
    "\n",
    "**Four-step pipeline:**\n",
    "\n",
    "1. **Collect core issue** (from real participant)\n",
    "   - Open-ended question: \"What political issue matters most?\"\n",
    "   - Participant writes in own words\n",
    "\n",
    "2. **Summarize with LLM**\n",
    "   - Extract key concern\n",
    "   - Create standardized format\n",
    "\n",
    "3. **Generate personalized scales**\n",
    "   - Create Likert items about THEIR issue\n",
    "   - Measure strength, certainty, priority\n",
    "   - Use their language\n",
    "\n",
    "4. **Generate personalized arguments**\n",
    "   - Pro: Supports their position\n",
    "   - Con: Challenges their position\n",
    "   - Different intensities available\n",
    "\n",
    "**Implementation in real study:**\n",
    "```\n",
    "Survey Flow:\n",
    "1. Page 1: \"What political issue matters most to you?\" → Collect text\n",
    "2. [Backend]: LLM processes → Generates scales + arguments\n",
    "3. Page 2: Show personalized pre-test scales\n",
    "4. Page 3: Show personalized argument (pro or con)\n",
    "5. Page 4: Show personalized post-test scales\n",
    "6. Measure: Change in personalized attitudes\n",
    "```\n",
    "\n",
    "**Velez & Liu (2024) findings:**\n",
    "- Even with maximum personalization, polarization was RARE\n",
    "- Moderate arguments: No backfire\n",
    "- Strong arguments: Little backfire\n",
    "- Vitriolic arguments: Some attitude defense\n",
    "- **Implication**: Polarization harder to induce than assumed\n",
    "\n",
    "**Advantages of this approach:**\n",
    "- Maximum relevance to each participant\n",
    "- Tests \"easy case\" for polarization\n",
    "- More engaging than generic topics\n",
    "- Captures what people actually care about\n",
    "\n",
    "**Technical challenges:**\n",
    "- Requires API integration with survey platform\n",
    "- Real-time generation during survey\n",
    "- Quality control on generated content\n",
    "- Costs scale with participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Deploying to Real Human Experiments\n",
    "\n",
    "**Workflow summary:**\n",
    "\n",
    "### Option A: Pre-Generated Messages (Simpler)\n",
    "\n",
    "1. **Generate all materials** (using code above)\n",
    "2. **Export to CSV** with condition IDs\n",
    "3. **Import to Qualtrics/SurveyMonkey**\n",
    "4. **Set up randomization**: Randomly assign to conditions\n",
    "5. **Add measurements**: Pre/post attitude scales\n",
    "6. **Deploy to platforms**: MTurk, Prolific, Lucid, etc.\n",
    "7. **Collect responses** from real humans\n",
    "8. **Analyze data**: Compare effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Open-Source Alternatives\n",
    "\n",
    "All message generation can be done with open-source models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ollama (Local)\n",
    "\n",
    "```python\n",
    "from ollama import Client as OllamaClient\n",
    "\n",
    "ollama_client = OllamaClient(host='http://localhost:11434')\n",
    "\n",
    "def generate_message_ollama(topic, position, model=\"llama3.2\"):\n",
    "    prompt = f\"Write a brief persuasive message (2-3 sentences) arguing people should {position} {topic}.\"\n",
    "    \n",
    "    response = ollama_client.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\"temperature\": 0.8}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- Free (local execution)\n",
    "- Private (no data sent to API)\n",
    "- Reproducible (fixed model weights)\n",
    "\n",
    "**Disadvantages:**\n",
    "- Slower (depends on hardware)\n",
    "- Lower quality (smaller models)\n",
    "- Requires local installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Hugging Face (Full Control)\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "def generate_message_hf(topic, position):\n",
    "    prompt = f\"Write a brief persuasive message (2-3 sentences) arguing people should {position} {topic}.\"\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True\n",
    "    ).to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.8,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0][inputs.shape[-1]:], skip_special_tokens=True)\n",
    "```\n",
    "\n",
    "**Best models for message generation:**\n",
    "- Llama 3.2 (8B): Good quality, reasonable speed\n",
    "- Mistral 7B: Fast and capable\n",
    "- Qwen 2.5 (7B): Strong instruction following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What we learned:**\n",
    "\n",
    "1. ✓ How to generate **generic persuasive messages**\n",
    "2. ✓ How to create **microtargeted messages** for demographic groups\n",
    "3. ✓ How to produce **complete experimental materials** at scale\n",
    "4. ✓ How to generate **multi-turn conversation scripts**\n",
    "5. ✓ How to implement **personalized outcomes** (Velez & Liu)\n",
    "6. ✓ How to **deploy materials** to real human experiments\n",
    "\n",
    "**Key insights from research:**\n",
    "\n",
    "- **Argyle et al. (2023)**: Simple approaches work as well as complex\n",
    "  - Generic messages ≈ Microtargeted messages\n",
    "  - One-shot ≈ Multi-turn conversations\n",
    "  - Implication: Start simple!\n",
    "\n",
    "- **Velez & Liu (2024)**: Polarization is hard to produce\n",
    "  - Even with maximum personalization\n",
    "  - Only extreme/vitriolic messages showed effects\n",
    "  - Implication: Backfire may be rarer than assumed\n",
    "\n",
    "**Best practices:**\n",
    "\n",
    "1. **Generate multiple variants**: Test different approaches\n",
    "2. **Always review outputs**: Check quality and ethics\n",
    "3. **Include control groups**: Essential for causal inference\n",
    "4. **Test on real humans**: LLMs generate, humans respond\n",
    "5. **Document everything**: Model versions, prompts, parameters\n",
    "6. **Consider ethics**: IRB approval, informed consent, no harm\n",
    "\n",
    "**When to use LLM message generation:**\n",
    "\n",
    "- ✓ Need many message variants quickly\n",
    "- ✓ Testing personalization hypotheses\n",
    "- ✓ Scaling interventions across topics\n",
    "- ✓ Exploring message design space\n",
    "- ✗ Without human validation/testing\n",
    "- ✗ Without reviewing for quality/ethics\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "- LLM-generated ≠ expert-written (quality varies)\n",
    "- Must be tested on real humans (not LLMs)\n",
    "- Ethical review required (potential manipulation)\n",
    "- Results may not generalize across topics\n",
    "\n",
    "**Next steps:**\n",
    "\n",
    "- Generate materials for your own research questions\n",
    "- Deploy to survey platforms with real participants\n",
    "- Analyze actual human behavioral responses\n",
    "- Compare to manually-written messages\n",
    "- Explore boundary conditions (when does it work?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
