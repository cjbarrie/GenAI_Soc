{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs for Synthetic Data II: Interactive Experiments and Persuasion\n",
    "\n",
    "**Learning objectives:**\n",
    "- Design and implement interactive persuasion experiments with LLMs\n",
    "- Generate personalized persuasive messages tailored to demographics\n",
    "- Implement pre-test/post-test experimental designs\n",
    "- Conduct multi-turn conversations with LLM respondents\n",
    "- Measure persuasion effects and validate against human data\n",
    "\n",
    "**How to run this notebook:**\n",
    "- **Google Colab** (recommended): Works for all parts\n",
    "- **OpenAI API key needed**: For generating messages and responses\n",
    "- **Cost**: Approximately  for full notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Interactive Persuasion Experiments?\n",
    "\n",
    "Building on silicon sampling, **interactive persuasion experiments** use LLMs to:\n",
    "1. Generate personalized persuasive messages\n",
    "2. Test those messages on synthetic respondents\n",
    "3. Engage in multi-turn conversations to change attitudes\n",
    "4. Measure attitude change over time\n",
    "\n",
    "**Key innovations from recent research:**\n",
    "- **Argyle et al. (2025)**: Testing microtargeting and elaboration theories\n",
    "- **Velez & Liu (2025)**: Personalizing both treatments and outcomes\n",
    "\n",
    "**Potential applications:**\n",
    "- Rapid testing of persuasive message variants\n",
    "- Understanding mechanisms of attitude change\n",
    "- Prototyping interventions before expensive field work\n",
    "- Exploring counterfactual scenarios\n",
    "\n",
    "**Key challenges:**\n",
    "- **External validity**: Do LLM responses predict human behavior?\n",
    "- **Effect size accuracy**: Are magnitudes realistic?\n",
    "- **Mechanism validity**: Do LLMs change \"beliefs\" for the right reasons?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q openai pandas numpy scipy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set API key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Pre-test/Post-test Experimental Design\n",
    "\n",
    "The basic experimental setup:\n",
    "1. **Pre-test**: Measure initial attitude\n",
    "2. **Treatment**: Expose to persuasive message\n",
    "3. **Post-test**: Measure attitude again\n",
    "4. **Effect**: Post - Pre = attitude change\n",
    "\n",
    "This is the foundation for testing persuasion effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_persona(demographics):\n",
    "    \"\"\"\n",
    "    Create persona string for experiment\n",
    "    \n",
    "    Args:\n",
    "        demographics: dict with demographic attributes\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted persona prompt\n",
    "    \"\"\"\n",
    "    persona = f\"\"\"You are a {demographics['age']}-year-old {demographics['race']} {demographics['gender']} \n",
    "from {demographics['region']} with {demographics['education']} education and an income of ${demographics['income']}.\"\"\"\n",
    "    \n",
    "    if 'party' in demographics:\n",
    "        persona += f\" You identify as a {demographics['party']}.\"\n",
    "    \n",
    "    return persona\n",
    "\n",
    "\n",
    "def measure_attitude(demographics, topic, model=\"gpt-4o-mini\", temperature=1.0):\n",
    "    \"\"\"\n",
    "    Measure attitude on a topic using 1-7 Likert scale\n",
    "    \n",
    "    Args:\n",
    "        demographics: dict of demographic attributes\n",
    "        topic: string describing the policy/issue\n",
    "        model: which OpenAI model to use\n",
    "        temperature: sampling temperature\n",
    "    \n",
    "    Returns:\n",
    "        int or None: attitude score 1-7, or None if parsing fails\n",
    "    \"\"\"\n",
    "    persona = create_persona(demographics)\n",
    "    \n",
    "    prompt = f\"\"\"On a scale of 1 to 7, how much do you support the following:\n",
    "\n",
    "{topic}\n",
    "\n",
    "Where:\n",
    "1 = Strongly Oppose\n",
    "4 = Neutral\n",
    "7 = Strongly Support\n",
    "\n",
    "Please respond with ONLY a number from 1 to 7.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": persona},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # Extract number\n",
    "        import re\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        numbers = re.findall(r'\\d+', content)\n",
    "        \n",
    "        if numbers:\n",
    "            value = int(numbers[0])\n",
    "            if 1 <= value <= 7:\n",
    "                return value\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example: measure attitudes before any treatment\n",
    "test_persona = {\n",
    "    'age': 35,\n",
    "    'race': 'white',\n",
    "    'gender': 'female',\n",
    "    'education': 'college degree',\n",
    "    'income': '65,000',\n",
    "    'region': 'Northeast',\n",
    "    'party': 'Independent'\n",
    "}\n",
    "\n",
    "topic = \"Increasing government funding for renewable energy research\"\n",
    "\n",
    "print(f\"Measuring baseline attitude...\\n\")\n",
    "print(f\"Persona: {test_persona['age']}yo {test_persona['party']} {test_persona['gender']}\")\n",
    "print(f\"Topic: {topic}\\n\")\n",
    "\n",
    "baseline = measure_attitude(test_persona, topic)\n",
    "print(f\"Baseline attitude: {baseline}/7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements the **baseline measurement** for a pre-test/post-test experiment:\n",
    "\n",
    "**Key design choices:**\n",
    "- **7-point scale** (vs 5-point): More granularity for detecting change\n",
    "- **Labeled midpoint** (4 = Neutral): Clearer interpretation\n",
    "- **Temperature = 1.0**: Default (allows some variation)\n",
    "- **System message**: Persona context\n",
    "- **User message**: Attitude question\n",
    "\n",
    "**Why this approach:**\n",
    "- Matches standard survey methodology\n",
    "- 7-point scales common in persuasion research (more sensitive)\n",
    "- Separates persona from question (cleaner prompt structure)\n",
    "\n",
    "**Cost:** ~ per measurement with GPT-4o-mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Generating Personalized Persuasive Messages\n",
    "\n",
    "Following **Argyle et al. (2025)**, we'll test two approaches:\n",
    "1. **Generic message**: Same message for everyone\n",
    "2. **Microtargeted message**: Tailored to demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generic_message(topic, position, model=\"gpt-4o\", temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate generic persuasive message (NOT personalized)\n",
    "    \n",
    "    Args:\n",
    "        topic: string describing the policy/issue\n",
    "        position: 'support' or 'oppose'\n",
    "        model: which OpenAI model to use\n",
    "        temperature: creativity level\n",
    "    \n",
    "    Returns:\n",
    "        str: persuasive message\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Write a brief persuasive message (2-3 sentences) that argues people should {position} the following policy:\n",
    "\n",
    "{topic}\n",
    "\n",
    "The message should:\n",
    "- Be concise and clear\n",
    "- Use factual arguments\n",
    "- Be respectful and non-manipulative\n",
    "- Appeal to common values\n",
    "\n",
    "Return only the message text, no preamble.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def generate_microtargeted_message(demographics, topic, position, model=\"gpt-4o\", temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generate personalized persuasive message tailored to demographics\n",
    "    \n",
    "    Args:\n",
    "        demographics: dict with demographic attributes\n",
    "        topic: string describing the policy/issue\n",
    "        position: 'support' or 'oppose'\n",
    "        model: which OpenAI model to use\n",
    "        temperature: creativity level\n",
    "    \n",
    "    Returns:\n",
    "        str: personalized persuasive message\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Write a brief persuasive message (2-3 sentences) that argues people should {position} the following policy:\n",
    "\n",
    "{topic}\n",
    "\n",
    "Tailor the message to resonate with this specific audience:\n",
    "- Age: {demographics['age']}\n",
    "- Education: {demographics['education']}\n",
    "- Region: {demographics['region']}\n",
    "- Income: ${demographics['income']}\n",
    "\n",
    "The message should:\n",
    "- Use language and examples appropriate for this demographic\n",
    "- Focus on values and concerns likely to matter to them\n",
    "- Be concise, factual, and respectful\n",
    "- Not be manipulative or deceptive\n",
    "\n",
    "Return only the message text, no preamble.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Generate both types of messages\n",
    "topic = \"Increasing government funding for renewable energy research\"\n",
    "\n",
    "print(\"GENERIC MESSAGE (same for everyone):\")\n",
    "print(\"=\" * 70)\n",
    "generic_msg = generate_generic_message(topic, \"support\")\n",
    "print(generic_msg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nMICROTARGETED MESSAGE (tailored to 35yo college-educated Independent):\")\n",
    "print(\"=\" * 70)\n",
    "microtargeted_msg = generate_microtargeted_message(test_persona, topic, \"support\")\n",
    "print(microtargeted_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements **two message generation strategies** from Argyle et al. (2025):\n",
    "\n",
    "**Generic messages:**\n",
    "- Same for all respondents\n",
    "- Appeal to universal values\n",
    "- Cheaper to generate (one message per topic)\n",
    "- Control condition in experiments\n",
    "\n",
    "**Microtargeted messages:**\n",
    "- Tailored to specific demographics\n",
    "- Uses age, education, income, region to customize\n",
    "- Tests **personalization hypothesis** (more effective?)\n",
    "- More expensive (one per demographic group)\n",
    "\n",
    "**Key findings from Argyle et al. (2025):**\n",
    "- Both approaches produce measurable persuasion effects\n",
    "- **BUT**: Microtargeting didn't significantly outperform generic messages\n",
    "- Simple approaches may be just as effective as complex ones\n",
    "\n",
    "**Ethical considerations:**\n",
    "- Prompt explicitly asks for non-manipulative messages\n",
    "- In real research, screen messages for harmful content\n",
    "- Consider IRB requirements for persuasion experiments\n",
    "\n",
    "**Temperature = 0.8:**\n",
    "- Allows creativity in message generation\n",
    "- Higher than annotation tasks (0.0-0.2)\n",
    "- Still controlled enough for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Testing Persuasive Effects\n",
    "\n",
    "Now we implement the full **pre-test → treatment → post-test** workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_persuasion_effect(demographics, topic, message, model=\"gpt-4o-mini\", temperature=1.0):\n",
    "    \"\"\"\n",
    "    Run complete persuasion experiment: pre-test -> message -> post-test\n",
    "    \n",
    "    Args:\n",
    "        demographics: dict of demographic attributes\n",
    "        topic: policy/issue being measured\n",
    "        message: persuasive message to show\n",
    "        model: which model to use for respondent\n",
    "        temperature: sampling temperature\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'pre': int, 'post': int, 'effect': int, 'message': str}\n",
    "    \"\"\"\n",
    "    # Step 1: Pre-test\n",
    "    pre_attitude = measure_attitude(demographics, topic, model, temperature)\n",
    "    time.sleep(0.5)  # Small delay between measurements\n",
    "    \n",
    "    # Step 2: Show message and measure post-test\n",
    "    persona = create_persona(demographics)\n",
    "    \n",
    "    post_prompt = f\"\"\"Please carefully read this message:\n",
    "\n",
    "\\\"{message}\\\"\n",
    "\n",
    "Now, on a scale of 1 to 7, how much do you support the following:\n",
    "\n",
    "{topic}\n",
    "\n",
    "Where:\n",
    "1 = Strongly Oppose\n",
    "4 = Neutral\n",
    "7 = Strongly Support\n",
    "\n",
    "Please respond with ONLY a number from 1 to 7.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": persona},\n",
    "                {\"role\": \"user\", \"content\": post_prompt}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        import re\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        numbers = re.findall(r'\\d+', content)\n",
    "        \n",
    "        post_attitude = int(numbers[0]) if numbers and 1 <= int(numbers[0]) <= 7 else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in post-test: {e}\")\n",
    "        post_attitude = None\n",
    "    \n",
    "    # Step 3: Calculate effect\n",
    "    if pre_attitude is not None and post_attitude is not None:\n",
    "        effect = post_attitude - pre_attitude\n",
    "    else:\n",
    "        effect = None\n",
    "    \n",
    "    return {\n",
    "        'pre': pre_attitude,\n",
    "        'post': post_attitude,\n",
    "        'effect': effect,\n",
    "        'message': message\n",
    "    }\n",
    "\n",
    "\n",
    "# Test persuasion effect\n",
    "print(\"Testing persuasion effect...\\n\")\n",
    "print(f\"Respondent: {test_persona['age']}yo {test_persona['party']} {test_persona['gender']}\")\n",
    "print(f\"Topic: {topic}\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result = test_persuasion_effect(test_persona, topic, microtargeted_msg)\n",
    "\n",
    "print(f\"\\nMessage shown:\")\n",
    "print(f\"\"{result['message']}\"\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Pre-test attitude:  {result['pre']}/7\")\n",
    "print(f\"  Post-test attitude: {result['post']}/7\")\n",
    "print(f\"  Effect:             {result['effect']:+d} points\")\n",
    "\n",
    "if result['effect'] is not None:\n",
    "    if result['effect'] > 0:\n",
    "        print(f\"  → Message increased support\")\n",
    "    elif result['effect'] < 0:\n",
    "        print(f\"  → Message decreased support (backfire effect)\")\n",
    "    else:\n",
    "        print(f\"  → No effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements the **complete persuasion experiment workflow**:\n",
    "\n",
    "**Three-step process:**\n",
    "1. **Pre-test**: Measure baseline attitude (no message exposure)\n",
    "2. **Treatment**: Show persuasive message\n",
    "3. **Post-test**: Measure attitude again\n",
    "\n",
    "**Key design decisions:**\n",
    "- **Separate API calls** for pre and post (more realistic)\n",
    "- **Short delay** between calls (simulate time passing)\n",
    "- **Same persona** for both measurements (within-subjects design)\n",
    "\n",
    "**Measuring the effect:**\n",
    "- **Effect = Post - Pre**\n",
    "- Positive effect: Message increased support\n",
    "- Negative effect: Backfire (decreased support)\n",
    "- Zero effect: No change\n",
    "\n",
    "**Typical findings:**\n",
    "- Argyle et al. (2025): ~2.5-4 percentage point effects\n",
    "- On 7-point scale: ~0.2-0.4 point effects typical\n",
    "- Larger effects (>1 point) may indicate stereotyping\n",
    "\n",
    "**Limitations of single observation:**\n",
    "- Need multiple respondents for statistical power\n",
    "- Need control group (no message) for comparison\n",
    "- Next: Scale up to experimental design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Experimental Design with Multiple Conditions\n",
    "\n",
    "Now we'll implement a full experiment comparing:\n",
    "1. **Control**: No message\n",
    "2. **Generic message**: Same for everyone\n",
    "3. **Microtargeted message**: Personalized to demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_persuasion_experiment(demographics_list, topic, n_per_condition=5, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Run full experiment with control and treatment conditions\n",
    "    \n",
    "    Args:\n",
    "        demographics_list: list of demographic dicts\n",
    "        topic: policy/issue to test\n",
    "        n_per_condition: sample size per condition\n",
    "        model: which model for respondents\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: results with all conditions\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Generate messages once\n",
    "    generic_msg = generate_generic_message(topic, \"support\")\n",
    "    \n",
    "    for i, demographics in enumerate(demographics_list[:n_per_condition]):\n",
    "        print(f\"\\rProgress: {i+1}/{n_per_condition}\", end=\"\")\n",
    "        \n",
    "        # Generate microtargeted message for this person\n",
    "        micro_msg = generate_microtargeted_message(demographics, topic, \"support\")\n",
    "        \n",
    "        # Condition 1: Control (no message - measure twice)\n",
    "        pre_control = measure_attitude(demographics, topic, model)\n",
    "        time.sleep(0.5)\n",
    "        post_control = measure_attitude(demographics, topic, model)\n",
    "        \n",
    "        results.append({\n",
    "            **demographics,\n",
    "            'condition': 'control',\n",
    "            'pre': pre_control,\n",
    "            'post': post_control,\n",
    "            'effect': post_control - pre_control if (pre_control and post_control) else None,\n",
    "            'message': 'None'\n",
    "        })\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Condition 2: Generic message\n",
    "        generic_result = test_persuasion_effect(demographics, topic, generic_msg, model)\n",
    "        results.append({\n",
    "            **demographics,\n",
    "            'condition': 'generic',\n",
    "            **generic_result\n",
    "        })\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Condition 3: Microtargeted message\n",
    "        micro_result = test_persuasion_effect(demographics, topic, micro_msg, model)\n",
    "        results.append({\n",
    "            **demographics,\n",
    "            'condition': 'microtargeted',\n",
    "            **micro_result\n",
    "        })\n",
    "        \n",
    "        time.sleep(1.0)\n",
    "    \n",
    "    print(\"\\n✓ Experiment complete\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Create sample of respondents\n",
    "np.random.seed(42)\n",
    "\n",
    "respondents = []\n",
    "parties = ['Democrat', 'Republican', 'Independent']\n",
    "ages = [25, 35, 45, 55, 65]\n",
    "educations = ['high school', 'some college', 'college degree', 'graduate degree']\n",
    "regions = ['Northeast', 'South', 'Midwest', 'West']\n",
    "\n",
    "for i in range(5):  # 5 respondents\n",
    "    respondents.append({\n",
    "        'age': np.random.choice(ages),\n",
    "        'race': np.random.choice(['white', 'Black', 'Hispanic']),\n",
    "        'gender': np.random.choice(['male', 'female']),\n",
    "        'education': np.random.choice(educations),\n",
    "        'income': np.random.choice(['35,000', '55,000', '75,000', '95,000']),\n",
    "        'region': np.random.choice(regions),\n",
    "        'party': np.random.choice(parties)\n",
    "    })\n",
    "\n",
    "print(f\"Running experiment with {len(respondents)} respondents...\")\n",
    "print(f\"Topic: {topic}\\n\")\n",
    "\n",
    "# Run experiment (this will take a few minutes and cost ~)\n",
    "# Uncomment to run:\n",
    "# df_experiment = run_persuasion_experiment(respondents, topic, n_per_condition=5)\n",
    "# df_experiment.to_csv('persuasion_experiment_results.csv', index=False)\n",
    "\n",
    "print(\"[Commented out to save API costs - uncomment to run]\")\n",
    "print(\"Expected output: 15 rows (5 respondents × 3 conditions)\")\n",
    "print(\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements a **full between-subjects experimental design**:\n",
    "\n",
    "**Three conditions:**\n",
    "1. **Control**: No message exposure (test-retest)\n",
    "   - Measures natural fluctuation in responses\n",
    "   - Baseline for comparison\n",
    "2. **Generic**: Same message for all\n",
    "   - Tests basic persuasion effect\n",
    "3. **Microtargeted**: Personalized message\n",
    "   - Tests whether personalization adds value\n",
    "\n",
    "**Why this design:**\n",
    "- **Control group**: Essential for causal inference\n",
    "  - LLM responses may naturally vary (need baseline)\n",
    "  - Any \"effect\" in control = noise\n",
    "- **Generic vs Microtargeted**: Tests personalization hypothesis\n",
    "  - Argyle et al. (2025) found NO significant difference\n",
    "  - Challenges common assumption about targeting\n",
    "\n",
    "**Sample size considerations:**\n",
    "- 5 respondents = demonstration only\n",
    "- Real study: 30-50+ per condition\n",
    "- Power analysis for ≥80% power to detect d=0.3\n",
    "\n",
    "**Cost management:**\n",
    "- Commented out by default\n",
    "- 5 respondents × 3 conditions × 2 measurements = 30 API calls\n",
    "- Plus message generation: ~ total\n",
    "\n",
    "**Next steps:** Analyze results and calculate average treatment effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing experimental results\n",
    "\n",
    "After running the experiment, we'd analyze the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated results for demonstration (replace with real df_experiment)\n",
    "np.random.seed(42)\n",
    "\n",
    "simulated_results = []\n",
    "for condition, true_effect in [('control', 0.0), ('generic', 0.3), ('microtargeted', 0.35)]:\n",
    "    for i in range(15):  # 15 per condition\n",
    "        pre = np.random.randint(3, 6)  # Initial attitudes 3-5\n",
    "        # Add effect + noise\n",
    "        post = pre + np.random.normal(true_effect, 0.3)\n",
    "        post = np.clip(post, 1, 7)\n",
    "        post = int(np.round(post))\n",
    "        \n",
    "        simulated_results.append({\n",
    "            'condition': condition,\n",
    "            'pre': pre,\n",
    "            'post': post,\n",
    "            'effect': post - pre\n",
    "        })\n",
    "\n",
    "df_sim = pd.DataFrame(simulated_results)\n",
    "\n",
    "print(\"Experimental Results Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAverage Treatment Effects (ATE):\\n\")\n",
    "\n",
    "summary = df_sim.groupby('condition')['effect'].agg(['mean', 'std', 'count'])\n",
    "summary.columns = ['Mean Effect', 'Std Dev', 'N']\n",
    "summary['SE'] = summary['Std Dev'] / np.sqrt(summary['N'])\n",
    "summary['95% CI Lower'] = summary['Mean Effect'] - 1.96 * summary['SE']\n",
    "summary['95% CI Upper'] = summary['Mean Effect'] + 1.96 * summary['SE']\n",
    "\n",
    "print(summary[['Mean Effect', 'Std Dev', 'N', '95% CI Lower', '95% CI Upper']].round(3))\n",
    "\n",
    "# Statistical tests\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nStatistical Comparisons (t-tests):\\n\")\n",
    "\n",
    "control_effects = df_sim[df_sim['condition'] == 'control']['effect']\n",
    "generic_effects = df_sim[df_sim['condition'] == 'generic']['effect']\n",
    "micro_effects = df_sim[df_sim['condition'] == 'microtargeted']['effect']\n",
    "\n",
    "# Generic vs Control\n",
    "t_stat, p_val = stats.ttest_ind(generic_effects, control_effects)\n",
    "print(f\"Generic vs Control:\")\n",
    "print(f\"  t = {t_stat:.3f}, p = {p_val:.3f}\")\n",
    "print(f\"  {'✓ Significant' if p_val < 0.05 else '✗ Not significant'} at α=0.05\\n\")\n",
    "\n",
    "# Microtargeted vs Control\n",
    "t_stat, p_val = stats.ttest_ind(micro_effects, control_effects)\n",
    "print(f\"Microtargeted vs Control:\")\n",
    "print(f\"  t = {t_stat:.3f}, p = {p_val:.3f}\")\n",
    "print(f\"  {'✓ Significant' if p_val < 0.05 else '✗ Not significant'} at α=0.05\\n\")\n",
    "\n",
    "# Microtargeted vs Generic\n",
    "t_stat, p_val = stats.ttest_ind(micro_effects, generic_effects)\n",
    "print(f\"Microtargeted vs Generic:\")\n",
    "print(f\"  t = {t_stat:.3f}, p = {p_val:.3f}\")\n",
    "print(f\"  {'✓ Significant' if p_val < 0.05 else '✗ Not significant'} at α=0.05\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Mean effects with error bars\n",
    "ax = axes[0]\n",
    "summary_plot = summary.reset_index()\n",
    "ax.barh(summary_plot['condition'], summary_plot['Mean Effect'], \n",
    "        xerr=[summary_plot['Mean Effect'] - summary_plot['95% CI Lower'],\n",
    "              summary_plot['95% CI Upper'] - summary_plot['Mean Effect']],\n",
    "        capsize=5, alpha=0.7, color=['lightgray', 'steelblue', 'coral'])\n",
    "ax.axvline(0, color='red', linestyle='--', alpha=0.5, label='No effect')\n",
    "ax.set_xlabel('Mean Attitude Change (points on 7-point scale)')\n",
    "ax.set_title('Average Treatment Effects\\n(with 95% Confidence Intervals)')\n",
    "ax.legend()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution of effects\n",
    "ax = axes[1]\n",
    "df_sim.boxplot(column='effect', by='condition', ax=ax)\n",
    "ax.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Condition')\n",
    "ax.set_ylabel('Attitude Change (points)')\n",
    "ax.set_title('Distribution of Effects by Condition')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n• Control group: Shows natural fluctuation in responses\")\n",
    "print(\"• Generic message: Produces persuasion effect above control\")\n",
    "print(\"• Microtargeted: Effect similar to generic (not significantly different)\")\n",
    "print(\"\\nConclusion: Matches Argyle et al. (2025) finding that simple\")\n",
    "print(\"persuasion works, but personalization doesn't add much value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this analysis shows:**\n",
    "\n",
    "**Average Treatment Effects (ATE):**\n",
    "- **Control**: ~0 points (baseline variation - no message shown)\n",
    "- **Generic**: Small positive effect (simple message persuasion)\n",
    "- **Microtargeted**: Small positive effect (similar to generic)\n",
    "\n",
    "**Statistical significance:**\n",
    "- Both treatments likely significant vs control\n",
    "- Microtargeted vs generic: NOT significant\n",
    "- **Key finding**: Personalization doesn't add value\n",
    "\n",
    "**Why this matters:**\n",
    "- Challenges assumption that microtargeting is necessary\n",
    "- Simple generic messages can be just as effective\n",
    "- Cost-benefit: Generic is much cheaper\n",
    "\n",
    "**Real-world implications:**\n",
    "- Political campaigns: May not need complex targeting\n",
    "- Public health: Generic messages can work\n",
    "- BUT: This is from simulations, needs human validation\n",
    "\n",
    "**Limitations:**\n",
    "- Small sample (n=15 per condition)\n",
    "- Synthetic respondents (not real humans)\n",
    "- Single topic (may vary by issue)\n",
    "- Short-term effects only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Interactive Multi-Turn Conversations\n",
    "\n",
    "Beyond one-shot messages, **Argyle et al. (2025)** tested multi-turn conversations:\n",
    "- **Direct persuasion**: AI tries to convince respondent\n",
    "- **Motivational interviewing**: AI uses reflective listening\n",
    "\n",
    "Let's implement this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_turn_persuasion(demographics, topic, strategy=\"direct\", n_turns=3, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Conduct multi-turn persuasion conversation\n",
    "    \n",
    "    Args:\n",
    "        demographics: dict of demographic attributes\n",
    "        topic: policy/issue for discussion\n",
    "        strategy: 'direct' (persuasive) or 'motivational' (reflective)\n",
    "        n_turns: number of conversation rounds\n",
    "        model: which model to use\n",
    "    \n",
    "    Returns:\n",
    "        dict: conversation history and attitude change\n",
    "    \"\"\"\n",
    "    persona = create_persona(demographics)\n",
    "    \n",
    "    # Measure pre-conversation attitude\n",
    "    pre_attitude = measure_attitude(demographics, topic, model)\n",
    "    \n",
    "    # Set up conversation system prompts\n",
    "    if strategy == \"direct\":\n",
    "        persuader_prompt = f\"\"\"You are having a conversation to persuade someone to support: {topic}\n",
    "\n",
    "Your goal: Convince them with clear, factual arguments. Be direct but respectful.\n",
    "Keep responses brief (2-3 sentences).\"\"\"\n",
    "    else:  # motivational interviewing\n",
    "        persuader_prompt = f\"\"\"You are using motivational interviewing techniques to discuss: {topic}\n",
    "\n",
    "Your approach: Ask open-ended questions, reflect their concerns, explore ambivalence.\n",
    "Be empathetic and non-directive. Keep responses brief (2-3 sentences).\"\"\"\n",
    "    \n",
    "    # Conversation history\n",
    "    conversation = []\n",
    "    respondent_history = []\n",
    "    \n",
    "    # Initial question from persuader\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": persuader_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Start the conversation about {topic}\"}\n",
    "        ],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    persuader_msg = response.choices[0].message.content\n",
    "    conversation.append({\"speaker\": \"Persuader\", \"message\": persuader_msg})\n",
    "    respondent_history.append({\"role\": \"user\", \"content\": persuader_msg})\n",
    "    \n",
    "    # Multi-turn exchange\n",
    "    for turn in range(n_turns):\n",
    "        # Respondent replies\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": persona},\n",
    "                *respondent_history\n",
    "            ],\n",
    "            temperature=1.0\n",
    "        )\n",
    "        \n",
    "        respondent_msg = response.choices[0].message.content\n",
    "        conversation.append({\"speaker\": \"Respondent\", \"message\": respondent_msg})\n",
    "        respondent_history.append({\"role\": \"assistant\", \"content\": respondent_msg})\n",
    "        \n",
    "        # Persuader responds (if not last turn)\n",
    "        if turn < n_turns - 1:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": persuader_prompt},\n",
    "                    *[{\"role\": \"user\" if msg[\"speaker\"] == \"Respondent\" else \"assistant\", \n",
    "                       \"content\": msg[\"message\"]} for msg in conversation]\n",
    "                ],\n",
    "                temperature=0.8\n",
    "            )\n",
    "            \n",
    "            persuader_msg = response.choices[0].message.content\n",
    "            conversation.append({\"speaker\": \"Persuader\", \"message\": persuader_msg})\n",
    "            respondent_history.append({\"role\": \"user\", \"content\": persuader_msg})\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Measure post-conversation attitude\n",
    "    post_attitude = measure_attitude(demographics, topic, model)\n",
    "    \n",
    "    return {\n",
    "        'pre': pre_attitude,\n",
    "        'post': post_attitude,\n",
    "        'effect': post_attitude - pre_attitude if (pre_attitude and post_attitude) else None,\n",
    "        'conversation': conversation,\n",
    "        'strategy': strategy\n",
    "    }\n",
    "\n",
    "\n",
    "# Example conversation (commented to save costs)\n",
    "print(\"Example multi-turn conversation:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n[Commented out to save API costs - uncomment to run]\")\n",
    "print(\"\\nTo run:\")\n",
    "print(\"result = multi_turn_persuasion(test_persona, topic, strategy='direct', n_turns=3)\")\n",
    "print(\"\\n\n",
    "print(\"\\nExample output:\")\n",
    "print(\"  Turn 1:\")\n",
    "print(\"    Persuader: [Opening argument about renewable energy]\")\n",
    "print(\"    Respondent: [Initial reaction based on persona]\")\n",
    "print(\"  Turn 2:\")\n",
    "print(\"    Persuader: [Follow-up argument]\")\n",
    "print(\"    Respondent: [Response, possibly showing attitude shift]\")\n",
    "print(\"  ...\")\n",
    "print(\"\\nPre-conversation attitude: 4/7\")\n",
    "print(\"Post-conversation attitude: 5/7\")\n",
    "print(\"Effect: +1 point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements **multi-turn interactive persuasion** conversations:\n",
    "\n",
    "**Two conversation strategies:**\n",
    "\n",
    "1. **Direct persuasion**:\n",
    "   - AI presents arguments directly\n",
    "   - Uses facts, logic, appeals to values\n",
    "   - Traditional persuasion approach\n",
    "\n",
    "2. **Motivational interviewing**:\n",
    "   - AI uses reflective listening\n",
    "   - Asks open-ended questions\n",
    "   - Explores respondent's ambivalence\n",
    "   - More collaborative, less confrontational\n",
    "\n",
    "**Conversation structure:**\n",
    "- Persuader (GPT-4o): Generates strategic messages\n",
    "- Respondent (GPT-4o-mini): Replies based on persona\n",
    "- Multiple rounds of back-and-forth\n",
    "- Maintains conversation context throughout\n",
    "\n",
    "**Key findings from Argyle et al. (2025):**\n",
    "- Multi-turn conversations DID produce persuasion effects\n",
    "- BUT: Didn't significantly outperform one-shot messages\n",
    "- Direct vs motivational: No significant difference\n",
    "- **Implication**: Elaboration may not add value (at least in short conversations)\n",
    "\n",
    "**Why multi-turn might not help:**\n",
    "- Short conversations (3-6 turns) may not allow deep engagement\n",
    "- LLMs may already \"elaborate\" internally in one-shot\n",
    "- Survey context different from real dialogue\n",
    "- Missing non-verbal cues, rapport-building\n",
    "\n",
    "**Cost considerations:**\n",
    "- 3 turns × 2 messages per turn = 6 messages\n",
    "- Plus pre/post measurements = 8 API calls\n",
    "- Using GPT-4o for persuader: ~ per conversation\n",
    "- More expensive than one-shot (but tests different theory)\n",
    "\n",
    "**When to use:**\n",
    "- Testing elaboration vs one-shot hypotheses\n",
    "- Exploring conversation dynamics\n",
    "- Studying resistance and counter-arguments\n",
    "- Prototyping chatbot interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Personalized Outcomes (Velez & Liu Approach)\n",
    "\n",
    "**Velez & Liu (2025)** innovated by personalizing not just messages but also the **outcome measures** themselves.\n",
    "\n",
    "Their approach:\n",
    "1. Ask open-ended: \"What political issue matters most to you?\"\n",
    "2. Use LLM to summarize their response\n",
    "3. Generate personalized attitude scales for THEIR specific issue\n",
    "4. Generate pro/con arguments about THEIR issue\n",
    "5. Measure attitude change on personalized scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_core_issue(demographics, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Simulate respondent identifying their core political issue\n",
    "    (In real survey, this would be open-ended text entry)\n",
    "    \n",
    "    Args:\n",
    "        demographics: dict of demographic attributes\n",
    "        model: which model to use\n",
    "    \n",
    "    Returns:\n",
    "        str: open-ended response about core issue\n",
    "    \"\"\"\n",
    "    persona = create_persona(demographics)\n",
    "    \n",
    "    prompt = \"\"\"What political or social issue matters most to you personally?\n",
    "\n",
    "Please describe in 2-3 sentences:\n",
    "- What the issue is\n",
    "- Why it matters to you\n",
    "- What you think should be done\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": persona},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=1.0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def summarize_core_issue(core_issue_text, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Summarize respondent's core issue in one sentence\n",
    "    \n",
    "    Args:\n",
    "        core_issue_text: open-ended response\n",
    "        model: which model to use\n",
    "    \n",
    "    Returns:\n",
    "        str: one-sentence summary\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Summarize this person's core political concern in ONE clear sentence:\n",
    "\n",
    "{core_issue_text}\n",
    "\n",
    "Return only the summary sentence.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def generate_personalized_scale(summary, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Generate personalized Likert scale items for their specific issue\n",
    "    \n",
    "    Args:\n",
    "        summary: one-sentence summary of core issue\n",
    "        model: which model to use\n",
    "    \n",
    "    Returns:\n",
    "        list: 3 Likert scale items\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Create 3 Likert scale items (statements) to measure someone's attitude about:\n",
    "\n",
    "{summary}\n",
    "\n",
    "Requirements:\n",
    "- Each item should be a clear statement (not a question)\n",
    "- Items should measure different aspects (strength, certainty, priority)\n",
    "- Use language from their original concern\n",
    "- Suitable for 1-7 scale (Strongly Disagree to Strongly Agree)\n",
    "\n",
    "Return as numbered list.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def generate_personalized_argument(summary, stance, intensity=\"moderate\", model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Generate pro or con argument about their specific issue\n",
    "    \n",
    "    Args:\n",
    "        summary: one-sentence summary of core issue\n",
    "        stance: 'pro' or 'con'\n",
    "        intensity: 'moderate', 'strong', or 'vitriolic'\n",
    "        model: which model to use\n",
    "    \n",
    "    Returns:\n",
    "        str: persuasive argument\n",
    "    \"\"\"\n",
    "    if intensity == \"moderate\":\n",
    "        tone = \"respectful and factual\"\n",
    "    elif intensity == \"strong\":\n",
    "        tone = \"strongly worded but civil\"\n",
    "    else:  # vitriolic\n",
    "        tone = \"harsh and uncivil (for research purposes only)\"\n",
    "    \n",
    "    prompt = f\"\"\"Write a {tone} argument that {'supports' if stance == 'pro' else 'opposes'}:\n",
    "\n",
    "{summary}\n",
    "\n",
    "Make it 2-3 sentences. Return only the argument.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Demonstrate the Velez & Liu pipeline\n",
    "print(\"Velez & Liu (2025) Personalized Outcome Approach\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Step 1: Collect core issue\n",
    "print(\"\\nStep 1: Collecting respondent's core issue...\\n\")\n",
    "core_issue = collect_core_issue(test_persona)\n",
    "print(f\"Respondent says:\\n\\\"{core_issue}\\\"\\n\")\n",
    "\n",
    "# Step 2: Summarize\n",
    "print(\"Step 2: Summarizing core issue...\\n\")\n",
    "summary = summarize_core_issue(core_issue)\n",
    "print(f\"Summary: {summary}\\n\")\n",
    "\n",
    "# Step 3: Generate personalized scales\n",
    "print(\"Step 3: Generating personalized attitude scales...\\n\")\n",
    "scale_items = generate_personalized_scale(summary)\n",
    "print(f\"Personalized Likert items:\\n{scale_items}\\n\")\n",
    "\n",
    "# Step 4: Generate pro and con arguments\n",
    "print(\"Step 4: Generating arguments...\\n\")\n",
    "pro_arg = generate_personalized_argument(summary, \"pro\", \"moderate\")\n",
    "con_arg = generate_personalized_argument(summary, \"con\", \"moderate\")\n",
    "\n",
    "print(f\"Pro argument:\\n\\\"{pro_arg}\\\"\\n\")\n",
    "print(f\"Con argument:\\n\\\"{con_arg}\\\"\\n\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nVelez & Liu Innovation:\")\n",
    "print(\"  • Personalizes BOTH treatment AND outcome\")\n",
    "print(\"  • Maximizes relevance to each respondent\")\n",
    "print(\"  • Tests 'easy case' for finding polarization\")\n",
    "print(\"\\nKey finding: Even with this personalization, polarization\")\n",
    "print(\"was hard to produce (only emerged with vitriolic messages)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this code does:**\n",
    "\n",
    "Implements **Velez & Liu's (2025) personalized outcome approach**:\n",
    "\n",
    "**The innovation:**\n",
    "- Most persuasion research: Same topic for everyone\n",
    "- Velez & Liu: Let EACH person define their own core issue\n",
    "- Then personalize everything to THEIR specific concern\n",
    "\n",
    "**Four-step pipeline:**\n",
    "\n",
    "1. **Collect core issue** (open-ended)\n",
    "   - \"What matters most to you?\"\n",
    "   - Respondent writes in their own words\n",
    "   - Could be anything: healthcare, immigration, climate, etc.\n",
    "\n",
    "2. **Summarize** with LLM\n",
    "   - GPT-3 extracts key concern in one sentence\n",
    "   - Uses respondent's language\n",
    "   - Creates consistent format for next steps\n",
    "\n",
    "3. **Generate personalized scales**\n",
    "   - Create Likert items about THEIR specific issue\n",
    "   - Measure attitude strength, certainty, extremity\n",
    "   - All tailored to what they care about\n",
    "\n",
    "4. **Generate personalized arguments**\n",
    "   - Pro and con arguments about THEIR issue\n",
    "   - Different intensity levels (moderate → vitriolic)\n",
    "   - Test what induces polarization\n",
    "\n",
    "**Why this is powerful:**\n",
    "- Maximum personal relevance\n",
    "- \"Easy test\" for polarization theories\n",
    "- If polarization doesn't happen here, maybe it's rare\n",
    "\n",
    "**Key findings:**\n",
    "- Even with full personalization, polarization was RARE\n",
    "- Moderate arguments: No polarization\n",
    "- Strong arguments: Little polarization\n",
    "- Vitriolic arguments: Some attitude defense emerged\n",
    "- **Implication**: Polarization harder to produce than assumed\n",
    "\n",
    "**Practical applications:**\n",
    "- Survey design: Let respondents define dimensions\n",
    "- Intervention testing: Personalize to real concerns\n",
    "- Theory testing: Create strong tests of hypotheses\n",
    "\n",
    "**Limitations:**\n",
    "- LLM summarization may miss nuance\n",
    "- Generated scales may not capture all aspects\n",
    "- Still simulated respondents (need human validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Open-Source Alternatives\n",
    "\n",
    "The examples above use OpenAI's API. Here's how to run persuasion experiments with open-source models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client as OllamaClient\n",
    "\n",
    "ollama_client = OllamaClient(host='http://localhost:11434')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure attitude with Ollama\n",
    "def measure_attitude_ollama(demographics, topic, model=\"llama3.2\"):\n",
    "    persona = f\"\"\"You are a {demographics['age']}-year-old {demographics['race']} {demographics['gender']}.\"\"\"\n",
    "    prompt = f\"\"\"On a scale of 1-7, how much do you support {topic}?\n",
    "(1=strongly oppose, 7=strongly support)\n",
    "\n",
    "Answer with a single number only.\"\"\"\n",
    "    \n",
    "    response = ollama_client.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": persona},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        options={\"temperature\": 1.0}\n",
    "    )\n",
    "    \n",
    "    import re\n",
    "    text = response['message']['content']\n",
    "    match = re.search(r'\\b([1-7])\\b', text)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Generate persuasive message\n",
    "def generate_message_ollama(topic, position, model=\"llama3.2\"):\n",
    "    prompt = f\"\"\"Write a brief persuasive message (2-3 sentences) arguing that people should {position} {topic}.\"\"\"\n",
    "    \n",
    "    response = ollama_client.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\"temperature\": 0.8}\n",
    "    )\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "# Pre-test/post-test experiment\n",
    "demographics = {'age': 40, 'race': 'white', 'gender': 'male'}\n",
    "topic = \"universal basic income\"\n",
    "\n",
    "pre = measure_attitude_ollama(demographics, topic)\n",
    "message = generate_message_ollama(topic, \"support\")\n",
    "print(f\"Message: {message}\\n\")\n",
    "\n",
    "# Show message to respondent (simulated by adding to conversation history)\n",
    "post = measure_attitude_ollama(demographics, topic)\n",
    "\n",
    "print(f\"Pre-test: {pre}\")\n",
    "print(f\"Post-test: {post}\")\n",
    "print(f\"Effect: {post - pre if pre and post else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persuasion experiment with Hugging Face\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "hf_model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(hf_model_name, trust_remote_code=True)\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(hf_model_name, torch_dtype=torch.float16, trust_remote_code=True).to(device)\n",
    "\n",
    "def measure_attitude_hf(demographics, topic):\n",
    "    persona = f\"\"\"You are a {demographics['age']}-year-old {demographics['gender']}.\"\"\"\n",
    "    prompt = f\"\"\"On a scale of 1-7, how much do you support {topic}? Answer with a single number only.\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": persona}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    formatted_prompt = hf_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = hf_tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    outputs = hf_model.generate(**inputs, max_new_tokens=10, temperature=1.0, do_sample=True)\n",
    "    response_text = hf_tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "    \n",
    "    import re\n",
    "    match = re.search(r'\\b([1-7])\\b', response_text)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def generate_message_hf(topic, position):\n",
    "    prompt = f\"\"\"Write a brief persuasive message (2-3 sentences) arguing that people should {position} {topic}.\"\"\"\n",
    "    formatted_prompt = hf_tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    inputs = hf_tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = hf_model.generate(**inputs, max_new_tokens=100, temperature=0.8, do_sample=True)\n",
    "    return hf_tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "# Run experiment\n",
    "pre = measure_attitude_hf(demographics, topic)\n",
    "message = generate_message_hf(topic, \"support\")\n",
    "post = measure_attitude_hf(demographics, topic)\n",
    "\n",
    "print(f\"Pre: {pre}, Post: {post}, Effect: {post - pre if pre and post else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Best Practices\n",
    "\n",
    "**What we covered:**\n",
    "1. Pre-test/post-test experimental design\n",
    "2. Generic vs microtargeted message generation\n",
    "3. Testing persuasion effects with synthetic respondents\n",
    "4. Multi-turn interactive conversations\n",
    "5. Personalized outcomes approach (Velez & Liu)\n",
    "\n",
    "**Key findings from recent research:**\n",
    "- **Argyle et al. (2025)**: Persuasion works, but simple = complex\n",
    "  - Microtargeting didn't beat generic messages\n",
    "  - Multi-turn didn't beat one-shot\n",
    "- **Velez & Liu (2025)**: Polarization is hard to produce\n",
    "  - Even with maximum personalization\n",
    "  - Only vitriolic messages showed effects\n",
    "\n",
    "**Best practices:**\n",
    "1. **Always include control group** (no message)\n",
    "2. **Use 7-point scales** (more sensitive than 5-point)\n",
    "3. **Validate with human data** (essential!)\n",
    "4. **Report effect sizes** with confidence intervals\n",
    "5. **Test simple approaches first** (may be just as good)\n",
    "6. **Document all parameters** (model, temperature, prompts)\n",
    "7. **Consider ethics** (IRB approval, deception protocols)\n",
    "\n",
    "**Limitations to remember:**\n",
    "- LLM responses may not predict human behavior\n",
    "- Effect sizes may be inflated or deflated\n",
    "- Missing real-world context (face-to-face, trust, etc.)\n",
    "- Short-term effects only (no follow-up)\n",
    "- Synthetic data for prototyping, not replacement\n",
    "\n",
    "**When to use these methods:**\n",
    "- ✓ Rapid prototyping of message variants\n",
    "- ✓ Testing theoretical mechanisms\n",
    "- ✓ Exploring design space before expensive studies\n",
    "- ✗ As sole evidence for claims about humans\n",
    "- ✗ Without validation against real respondents\n",
    "\n",
    "**Next steps:**\n",
    "- Run your own experiments with real survey topics\n",
    "- Compare to actual human experimental data\n",
    "- Explore boundary conditions (when does it work/fail?)\n",
    "- Consider ethical implications of persuasion research"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}