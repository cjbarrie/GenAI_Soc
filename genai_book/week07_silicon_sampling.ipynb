{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd-QwhHNpnGn"
      },
      "source": [
        "# LLMs for Synthetic Data I: Simulating Survey Respondents\n\n**Learning objectives:**\n- Understand silicon sampling and its application to survey research\n- Implement demographic persona construction\n- Generate synthetic survey responses and compare to real data\n- Measure algorithmic fidelity, invariance, and stereotyping\n- Validate synthetic data against ground truth surveys\n\n**How to run this notebook:**\n- **Google Colab** (recommended): Works for all parts\n- **OpenAI API key needed**: For generating synthetic responses\n- **SubPOP dataset**: Available at github.com/JosephJeesungSuh/subpop\n\n---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDxqFX23pnGo"
      },
      "source": [
        "## What is Silicon Sampling?\n",
        "\n",
        "**Silicon sampling** is the use of large language models (LLMs) to simulate survey respondents by conditioning the model on demographic characteristics.\n",
        "\n",
        "**The basic idea:**\n",
        "1. Create a demographic \"persona\" (age, gender, education, etc.)\n",
        "2. Prompt an LLM to respond as that persona would\n",
        "3. Ask survey questions and collect responses\n",
        "4. Aggregate across many personas to estimate population distributions\n",
        "\n",
        "**Potential applications:**\n",
        "- Rapid prototyping of survey instruments\n",
        "- Exploring counterfactual scenarios\n",
        "- Augmenting small samples\n",
        "- Pre-testing research designs\n",
        "\n",
        "**Key challenges:**\n",
        "- **Algorithmic fidelity**: Do synthetic distributions match real ones?\n",
        "- **Invariance**: Do all personas with same demographics give identical answers?\n",
        "- **Stereotyping**: Are between-group differences exaggerated?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BGpVLdOpnGo"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqEMJGVIpnGp"
      },
      "outputs": [],
      "source": [
        "# Install packages\n",
        "!pip install -q openai pandas numpy scipy scikit-learn matplotlib seaborn requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQj_YOPmpnGp",
        "outputId": "41d3d261-43a6-49db-cad4-8040eddcec3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n",
            "\u2713 Setup complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import getpass\n",
        "import time\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.spatial.distance import cosine\n",
        "from scipy.stats import entropy, spearmanr\n",
        "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set API key\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"\u2713 Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADdXvfT0pnGp"
      },
      "source": [
        "**What this code does:**\n",
        "\n",
        "Sets up the environment for silicon sampling experiments:\n",
        "\n",
        "**Key libraries:**\n",
        "- **`openai`**: API access to GPT models\n",
        "- **`pandas`**: Data manipulation and analysis\n",
        "- **`scipy`**: Statistical measures (cosine similarity, KL divergence, Spearman correlation)\n",
        "- **`sklearn`**: Validation metrics (Cohen's kappa, confusion matrix)\n",
        "- **`matplotlib/seaborn`**: Visualization\n",
        "\n",
        "**Why these specific tools:**\n",
        "- **Cosine similarity**: Measure algorithmic fidelity (how similar are distributions?)\n",
        "- **KL divergence**: Another distance metric for distributions\n",
        "- **Cohen's kappa**: Inter-rater reliability between synthetic and real\n",
        "- **Spearman correlation**: Ordinal association between rankings\n",
        "\n",
        "**Security reminder:** Uses `getpass` for API keys - never hardcode them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF8eXJbypnGp"
      },
      "source": [
        "---\n\n## Part 1: Creating Demographic Personas\n\nThe foundation of silicon sampling is constructing realistic demographic personas. personas should include:\n\n- Age\n- Gender\n- Race/ethnicity\n- Education level\n- Income bracket\n- Geographic region\n- Political party (for political questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucA94-hvpnGp",
        "outputId": "238de5e8-50ad-42c0-96a1-cd5839f9692a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example personas:\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Persona 1:\n",
            "You are a 45-year-old white male from Midwest with college degree education and an income of $75,000. You identify as a Democrat.\n",
            "\n",
            "Persona 2:\n",
            "You are a 29-year-old Black female from South with high school education and an income of $35,000. You identify as a Independent.\n",
            "\n",
            "Persona 3:\n",
            "You are a 67-year-old Hispanic male from West with some college education and an income of $55,000. You identify as a Republican.\n"
          ]
        }
      ],
      "source": [
        "def create_persona(demographics):\n",
        "    \"\"\"\n",
        "    Create persona string for silicon sampling\n",
        "\n",
        "    Args:\n",
        "        demographics: dict with keys: age, race, gender, education, income, region\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted persona prompt\n",
        "    \"\"\"\n",
        "    persona = f\"\"\"You are a {demographics['age']}-year-old {demographics['race']} {demographics['gender']} from {demographics['region']} with {demographics['education']} education and an income of ${demographics['income']}.\"\"\"\n",
        "\n",
        "    # Add political affiliation if present\n",
        "    if 'party' in demographics:\n",
        "        persona += f\" You identify as a {demographics['party']}.\"\n",
        "\n",
        "    return persona\n",
        "\n",
        "# Example personas\n",
        "example_personas = [\n",
        "    {\n",
        "        'age': 45,\n",
        "        'race': 'white',\n",
        "        'gender': 'male',\n",
        "        'education': 'college degree',\n",
        "        'income': '75,000',\n",
        "        'region': 'Midwest',\n",
        "        'party': 'Democrat'\n",
        "    },\n",
        "    {\n",
        "        'age': 29,\n",
        "        'race': 'Black',\n",
        "        'gender': 'female',\n",
        "        'education': 'high school',\n",
        "        'income': '35,000',\n",
        "        'region': 'South',\n",
        "        'party': 'Independent'\n",
        "    },\n",
        "    {\n",
        "        'age': 67,\n",
        "        'race': 'Hispanic',\n",
        "        'gender': 'male',\n",
        "        'education': 'some college',\n",
        "        'income': '55,000',\n",
        "        'region': 'West',\n",
        "        'party': 'Republican'\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Example personas:\\n\")\n",
        "print(\"=\" * 70)\n",
        "for i, demo in enumerate(example_personas, 1):\n",
        "    print(f\"\\nPersona {i}:\")\n",
        "    print(create_persona(demo))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deoROCtvpnGq"
      },
      "source": [
        "**What this code does:**\n\nImplements the **persona construction** approach from Argyle et al. (2023):\n\n**The `create_persona` function:**\n- Takes a dictionary of demographic attributes\n- Formats them into a natural language persona description\n- Uses second person (\"You are...\") to prime the model\n\n**Key demographic variables:**\n- **Age**: Specific number (not range) for precision\n- **Race/ethnicity**: Following U.S. Census categories\n- **Gender**: Binary in original study (limitations noted)\n- **Education**: Categorical levels (high school, some college, college degree, graduate)\n- **Income**: Specific dollar amount or range\n- **Region**: Geographic area (affects policy preferences)\n- **Party**: Political affiliation (optional, task-dependent)\n\n**Why this format:**\n- Clear, unambiguous demographic information\n- Mimics how humans think about identity\n- Tested in silicon sampling research\n\n**Limitations:**\n- Simplified categories (e.g., binary gender)\n- May activate stereotypes in the model\n- Assumes demographics determine opinions (not always true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP3lxj5YpnGq"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Generating Synthetic Survey Responses\n",
        "\n",
        "Now we'll implement the core silicon sampling function to generate survey responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC5XLn_HpnGq",
        "outputId": "5f685d7f-acf4-49d9-bccc-284a004f163b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: The government should provide universal healthcare for all citizens.\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Synthetic responses:\n",
            "\n",
            "Persona 1 (Democrat): 5\n",
            "Persona 2 (Independent): 4\n",
            "Persona 3 (Republican): 2\n"
          ]
        }
      ],
      "source": [
        "def silicon_sample_likert(demographics, question, scale=(1, 5), model=\"gpt-3.5-turbo\", temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate synthetic survey response for Likert scale question\n",
        "\n",
        "    Args:\n",
        "        demographics: dict of demographic attributes\n",
        "        question: survey question text\n",
        "        scale: tuple of (min, max) for Likert scale\n",
        "        model: which OpenAI model to use\n",
        "        temperature: sampling temperature (1.0 is default)\n",
        "\n",
        "    Returns:\n",
        "        int or None: numeric response on scale, or None if parsing fails\n",
        "    \"\"\"\n",
        "    persona = create_persona(demographics)\n",
        "\n",
        "    prompt = f\"\"\"{question}\n",
        "\n",
        "Please respond with only a number from {scale[0]} to {scale[1]}, where:\n",
        "{scale[0]} = Strongly Disagree\n",
        "{scale[1]} = Strongly Agree\n",
        "\n",
        "Your response (number only):\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": persona},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=temperature\n",
        "        )\n",
        "\n",
        "        # Extract numeric response\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        # Try to extract first number\n",
        "        import re\n",
        "        numbers = re.findall(r'\\d+', content)\n",
        "        if numbers:\n",
        "            value = int(numbers[0])\n",
        "            # Validate in range\n",
        "            if scale[0] <= value <= scale[1]:\n",
        "                return value\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test with example question\n",
        "question = \"The government should provide universal healthcare for all citizens.\"\n",
        "\n",
        "print(f\"Question: {question}\\n\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nSynthetic responses:\\n\")\n",
        "\n",
        "for i, demo in enumerate(example_personas, 1):\n",
        "    response = silicon_sample_likert(demo, question)\n",
        "    print(f\"Persona {i} ({demo['party']}): {response}\")\n",
        "    time.sleep(0.3)  # Rate limiting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X3XCC95pnGq"
      },
      "source": [
        "**What this code does:**\n\nImplements the core **silicon sampling function** for Likert-scale questions:\n\n**The `silicon_sample_likert` function workflow:**\n1. Create persona from demographics\n2. Format question with clear scale instructions\n3. Send to LLM with persona as system message\n4. Extract numeric response with error handling\n5. Validate response is in valid range\n\n**Key parameters:**\n- **`temperature=1.0`**: Default setting (1.0)\n  - Higher than annotation tasks (0.1-0.3)\n  - Allows for within-group diversity\n  - Still not as diverse as real humans\n- **`model=\"gpt-3.5-turbo\"`**: Original study used GPT-3 (similar)\n\n**Robust parsing:**\n- Uses regex to extract first number from response\n- Handles cases where model adds explanation\n- Validates number is in valid range\n- Returns `None` if parsing fails\n\n**Why system vs user message:**\n- **System message**: Sets persistent context (persona)\n- **User message**: Contains the specific question\n- This separation helps model stay \"in character\"\n\n**Cost consideration:** Each call costs ~$0.0005-0.001 with GPT-3.5-turbo, so 1000 responses \u2248 $0.50-1.00"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAxbqKKbpnGq"
      },
      "source": [
        "### Generating responses for multiple questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9Xd75xWpnGq",
        "outputId": "c82193d2-ec7b-43ef-ae93-352ccf595582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting responses for: Democrat, 45, white...\n",
            "Collecting responses for: Independent, 29, Black...\n",
            "Collecting responses for: Republican, 67, Hispanic...\n",
            "\n",
            "\u2713 Synthetic responses collected\n",
            "\n",
            "         party  age      race  Q1  Q2  Q3  Q4  Q5\n",
            "0     Democrat   45     white   5   2   5   3   4\n",
            "1  Independent   29     Black   5   3   4   2   3\n",
            "2   Republican   67  Hispanic   2   4   3   3   2\n"
          ]
        }
      ],
      "source": [
        "# Define survey questions (simplified ANES-style)\n",
        "questions = [\n",
        "    \"The government should provide universal healthcare for all citizens.\",\n",
        "    \"We should increase spending on defense and military.\",\n",
        "    \"Climate change is one of the most serious problems facing the country.\",\n",
        "    \"Immigration levels should be decreased.\",\n",
        "    \"The government should do more to regulate big corporations.\"\n",
        "]\n",
        "\n",
        "def collect_responses(demographics, questions, model=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Collect responses for multiple questions from a single persona\n",
        "    \"\"\"\n",
        "    responses = {}\n",
        "\n",
        "    for i, question in enumerate(questions, 1):\n",
        "        response = silicon_sample_likert(demographics, question, model=model)\n",
        "        responses[f\"Q{i}\"] = response\n",
        "        time.sleep(0.2)  # Rate limiting\n",
        "\n",
        "    return responses\n",
        "\n",
        "# Collect responses from example personas\n",
        "results = []\n",
        "\n",
        "for demo in example_personas:\n",
        "    print(f\"Collecting responses for: {demo['party']}, {demo['age']}, {demo['race']}...\")\n",
        "    responses = collect_responses(demo, questions)\n",
        "\n",
        "    result = {**demo, **responses}\n",
        "    results.append(result)\n",
        "\n",
        "df_synthetic = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n\u2713 Synthetic responses collected\\n\")\n",
        "print(df_synthetic[['party', 'age', 'race', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLMmPGnbpnGq"
      },
      "source": [
        "**What this code does:**\n",
        "\n",
        "Implements **multi-question survey collection** from synthetic personas:\n",
        "\n",
        "**The `collect_responses` function:**\n",
        "- Takes single demographic profile and list of questions\n",
        "- Collects response for each question sequentially\n",
        "- Returns dictionary of question IDs \u2192 responses\n",
        "- Includes rate limiting to avoid API throttling\n",
        "\n",
        "**Question design:**\n",
        "- Based on typical ANES (American National Election Studies) format\n",
        "- Cover different policy domains (healthcare, defense, environment, immigration, economy)\n",
        "- Clear, unambiguous phrasing\n",
        "- Scaled as agreement (1-5)\n",
        "\n",
        "**Why collect multiple questions:**\n",
        "- Test consistency within persona\n",
        "- Enable correlation analysis (do issues cluster as expected?)\n",
        "- Compare to real survey patterns\n",
        "- Detect stereotyping across domains\n",
        "\n",
        "**Output format:**\n",
        "- Pandas DataFrame with demographics + responses\n",
        "- Easy to analyze, visualize, export\n",
        "- Can merge with real survey data for comparison\n",
        "\n",
        "**Next steps:** Scale up to many personas and compare to real distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gJNeR6XpnGq"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Measuring Algorithmic Fidelity\n",
        "\n",
        "**Algorithmic fidelity** measures how well synthetic distributions match real survey distributions.\n",
        "\n",
        "Common metrics:\n",
        "- **Cosine similarity**: 1 = identical, 0 = orthogonal, -1 = opposite\n",
        "- **KL divergence**: 0 = identical, higher = more different\n",
        "- **Spearman correlation**: Ordinal association (-1 to +1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMcD5hQ9pnGq",
        "outputId": "7e84c230-1f71-458d-c79d-bac3ab3a9c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Real' survey data (simulated):\n",
            "               Q1    Q2\n",
            "party                  \n",
            "Democrat     4.09  1.80\n",
            "Independent  3.05  3.05\n",
            "Republican   1.82  4.18\n"
          ]
        }
      ],
      "source": [
        "# Simulate real survey data for comparison\n",
        "# (In practice, you'd use actual survey data like ANES or GSS)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create \"real\" data with realistic distributions\n",
        "# Democrats favor Q1 (healthcare), Republicans favor Q2 (defense)\n",
        "real_data = []\n",
        "\n",
        "for party in ['Democrat', 'Republican', 'Independent']:\n",
        "    n = 100\n",
        "\n",
        "    if party == 'Democrat':\n",
        "        q1 = np.random.choice([3, 4, 5], n, p=[0.2, 0.4, 0.4])  # Pro healthcare\n",
        "        q2 = np.random.choice([1, 2, 3], n, p=[0.4, 0.4, 0.2])  # Anti defense spending\n",
        "    elif party == 'Republican':\n",
        "        q1 = np.random.choice([1, 2, 3], n, p=[0.4, 0.4, 0.2])  # Anti healthcare\n",
        "        q2 = np.random.choice([3, 4, 5], n, p=[0.2, 0.4, 0.4])  # Pro defense\n",
        "    else:  # Independent\n",
        "        q1 = np.random.choice([2, 3, 4], n, p=[0.3, 0.4, 0.3])  # Moderate\n",
        "        q2 = np.random.choice([2, 3, 4], n, p=[0.3, 0.4, 0.3])  # Moderate\n",
        "\n",
        "    for i in range(n):\n",
        "        real_data.append({\n",
        "            'party': party,\n",
        "            'Q1': q1[i],\n",
        "            'Q2': q2[i]\n",
        "        })\n",
        "\n",
        "df_real = pd.DataFrame(real_data)\n",
        "\n",
        "print(\"'Real' survey data (simulated):\")\n",
        "print(df_real.groupby('party')[['Q1', 'Q2']].mean().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl0yiYRHpnGq",
        "outputId": "4ef27adc-51cd-4352-b889-193da7750be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algorithmic Fidelity Analysis (Q1: Healthcare)\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Democrat:\n",
            "  Real distribution: [ 0  0 28 35 37]\n",
            "  (Note: Need larger synthetic sample for proper comparison)\n",
            "\n",
            "Republican:\n",
            "  Real distribution: [39 40 21  0  0]\n",
            "  (Note: Need larger synthetic sample for proper comparison)\n"
          ]
        }
      ],
      "source": [
        "def calculate_cosine_similarity(dist1, dist2):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between two distributions\n",
        "\n",
        "    Returns:\n",
        "        float: 1 = identical, 0 = orthogonal, -1 = opposite\n",
        "    \"\"\"\n",
        "    # Ensure same length and normalize\n",
        "    dist1 = np.array(dist1) / np.sum(dist1)\n",
        "    dist2 = np.array(dist2) / np.sum(dist2)\n",
        "\n",
        "    return 1 - cosine(dist1, dist2)\n",
        "\n",
        "def calculate_kl_divergence(p, q):\n",
        "    \"\"\"\n",
        "    Calculate KL divergence from distribution q to p\n",
        "    Lower is better (0 = identical)\n",
        "    \"\"\"\n",
        "    p = np.array(p) / np.sum(p)\n",
        "    q = np.array(q) / np.sum(q)\n",
        "\n",
        "    # Add small epsilon to avoid division by zero\n",
        "    epsilon = 1e-10\n",
        "    p = p + epsilon\n",
        "    q = q + epsilon\n",
        "\n",
        "    return entropy(p, q)\n",
        "\n",
        "# Compare distributions for Q1 by party\n",
        "print(\"Algorithmic Fidelity Analysis (Q1: Healthcare)\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for party in ['Democrat', 'Republican']:\n",
        "    # Get real distribution\n",
        "    real_dist = df_real[df_real['party'] == party]['Q1'].value_counts().sort_index()\n",
        "    real_dist = real_dist.reindex([1, 2, 3, 4, 5], fill_value=0).values\n",
        "\n",
        "    # For synthetic, we only have 1 sample per party in example\n",
        "    # In practice, you'd generate many samples\n",
        "    print(f\"\\n{party}:\")\n",
        "    print(f\"  Real distribution: {real_dist}\")\n",
        "    print(f\"  (Note: Need larger synthetic sample for proper comparison)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SimKLFn9pnGr"
      },
      "source": [
        "**What this code does:**\n\nImplements **algorithmic fidelity metrics** to compare synthetic and real distributions:\n\n**Why we need simulated data:**\n- Real survey data (ANES, GSS) requires download/access\n- Simulated data lets us demonstrate the metrics\n- In practice, you'd replace this with actual survey data\n\n**Cosine similarity:**\n- Measures angle between two vectors\n- **Range**: -1 (opposite) to +1 (identical)\n- **Interpretation**:\n  - > 0.9: Excellent match\n  - 0.7-0.9: Good match (typical for good fidelity)\n  - < 0.7: Poor match\n- **Advantage**: Scale-invariant (doesn't matter if one dist is larger)\n\n**KL divergence (Kullback-Leibler):**\n- Measures how one distribution differs from another\n- **Range**: 0 (identical) to \u221e (completely different)\n- **Interpretation**:\n  - < 0.1: Excellent match\n  - 0.1-0.5: Moderate difference\n  - > 0.5: Large difference\n- **Asymmetric**: KL(P||Q) \u2260 KL(Q||P)\n- **Sensitive to zeros**: Need epsilon for numerical stability\n\n**When to use each:**\n- **Cosine**: Easier to interpret, symmetric, good for correlation\n- **KL divergence**: More sensitive to differences, standard in ML\n- **Report both**: Different perspectives on same comparison\n\n**Practical note:** Need large samples (100+ per group) for reliable distribution comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding Cosine Similarity and KL Divergence with Examples\n",
        "\n",
        "Let's simulate different scenarios to understand how these metrics work:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate different distribution scenarios\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Scenario 1: Perfect match (synthetic = real)\n",
        "real_perfect = np.array([0, 5, 20, 40, 35])  # Distribution across 1-5 scale\n",
        "synthetic_perfect = np.array([0, 5, 20, 40, 35])\n",
        "\n",
        "# Scenario 2: Good match (slight differences)\n",
        "real_good = np.array([0, 5, 20, 40, 35])\n",
        "synthetic_good = np.array([0, 8, 22, 38, 32])\n",
        "\n",
        "# Scenario 3: Moderate mismatch (distribution shifted)\n",
        "real_moderate = np.array([0, 5, 20, 40, 35])\n",
        "synthetic_moderate = np.array([5, 15, 30, 30, 20])\n",
        "\n",
        "# Scenario 4: Poor match (very different distributions)\n",
        "real_poor = np.array([0, 5, 20, 40, 35])  # Skewed toward \"Agree\"\n",
        "synthetic_poor = np.array([35, 40, 20, 5, 0])  # Skewed toward \"Disagree\" (reversed)\n",
        "\n",
        "# Calculate metrics for each scenario\n",
        "scenarios = [\n",
        "    (\"Perfect Match\", real_perfect, synthetic_perfect),\n",
        "    (\"Good Match\", real_good, synthetic_good),\n",
        "    (\"Moderate Mismatch\", real_moderate, synthetic_moderate),\n",
        "    (\"Poor Match\", real_poor, synthetic_poor)\n",
        "]\n",
        "\n",
        "print(\"Distribution Comparison Examples\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "for name, real, synthetic in scenarios:\n",
        "    cos_sim = calculate_cosine_similarity(real, synthetic)\n",
        "    kl_div = calculate_kl_divergence(real, synthetic)\n",
        "    \n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Real:      {real}\")\n",
        "    print(f\"  Synthetic: {synthetic}\")\n",
        "    print(f\"  Cosine similarity: {cos_sim:.3f}\")\n",
        "    print(f\"  KL divergence:     {kl_div:.3f}\")\n",
        "    print()\n",
        "\n",
        "# Visualize all scenarios\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "x = np.arange(1, 6)  # Likert scale 1-5\n",
        "\n",
        "for idx, (name, real, synthetic) in enumerate(scenarios):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    width = 0.35\n",
        "    ax.bar(x - width/2, real, width, label='Real', alpha=0.8, color='steelblue')\n",
        "    ax.bar(x + width/2, synthetic, width, label='Synthetic', alpha=0.8, color='coral')\n",
        "    \n",
        "    cos_sim = calculate_cosine_similarity(real, synthetic)\n",
        "    kl_div = calculate_kl_divergence(real, synthetic)\n",
        "    \n",
        "    ax.set_title(f\"{name}\\nCosine: {cos_sim:.3f}, KL: {kl_div:.3f}\", fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Response (1=Disagree, 5=Agree)')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_xticks(x)\n",
        "    ax.legend()\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Key Insights:\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "print(\"COSINE SIMILARITY:\")\n",
        "print(\"  \u2022 Perfect match (1.000): Distributions are identical\")\n",
        "print(\"  \u2022 Good match (>0.95): Very similar shape and position\")\n",
        "print(\"  \u2022 Moderate (0.85-0.95): Similar trends but noticeable differences\")\n",
        "print(\"  \u2022 Poor (<0.85): Different patterns or reversed\")\n",
        "print(\"  \u2022 Measures: The 'angle' between distributions (shape similarity)\")\n",
        "print()\n",
        "print(\"KL DIVERGENCE:\")\n",
        "print(\"  \u2022 Perfect match (0.000): Distributions are identical\")\n",
        "print(\"  \u2022 Good match (<0.05): Very close distributions\")\n",
        "print(\"  \u2022 Moderate (0.05-0.20): Noticeable differences\")\n",
        "print(\"  \u2022 Poor (>0.20): Very different distributions\")\n",
        "print(\"  \u2022 Measures: How much 'information is lost' using synthetic instead of real\")\n",
        "print()\n",
        "print(\"PRACTICAL INTERPRETATION:\")\n",
        "print(\"  \u2022 If cosine similarity is high but KL divergence is moderate:\")\n",
        "print(\"    \u2192 Distributions have similar shape but different magnitudes\")\n",
        "print(\"  \u2022 If both metrics are poor:\")\n",
        "print(\"    \u2192 Synthetic data fails to capture real distribution\")\n",
        "print(\"  \u2022 For silicon sampling validation, aim for:\")\n",
        "print(\"    \u2192 Cosine similarity > 0.90\")\n",
        "print(\"    \u2192 KL divergence < 0.10\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this demonstration shows:**\n\n**The four scenarios illustrate:**\n\n1. **Perfect Match** (Cosine \u2248 1.0, KL \u2248 0.0):\n   - Distributions are identical\n   - This is the ideal but rarely achieved in practice\n\n2. **Good Match** (Cosine > 0.95, KL < 0.05):\n   - Small differences in counts but same overall pattern\n   - This level of agreement suggests synthetic data captures real patterns well\n   - Typical of successful silicon sampling\n\n3. **Moderate Mismatch** (Cosine 0.85-0.95, KL 0.05-0.20):\n   - Distribution is shifted (e.g., synthetic responses are less extreme)\n   - Still captures general trend but misses magnitude\n   - May indicate **invariance problem** (responses too centered)\n\n4. **Poor Match** (Cosine < 0.85, KL > 0.20):\n   - Completely different patterns (e.g., reversed preferences)\n   - May indicate **stereotyping** (LLM has wrong beliefs about group)\n   - Synthetic data should NOT be used if this occurs\n\n**Why both metrics matter:**\n- **Cosine similarity** tells you if the *shape* matches (correlation)\n- **KL divergence** tells you if the *exact values* match (precision)\n- You need both high cosine and low KL for good fidelity\n\n**Real-world application:**\nWhen validating your silicon sampling:\n1. Calculate both metrics for each demographic group \u00d7 question\n2. If most comparisons show good match: proceed with caution\n3. If many show moderate/poor match: don't use synthetic data for that question\n4. Always report these metrics in your validation section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8QbXQfepnGr"
      },
      "source": [
        "### Generating larger synthetic sample for proper validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgAIu3-pnGr",
        "outputId": "a97a8e1b-36c1-4025-c012-00de33d97c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 10/90\n",
            "Progress: 20/90\n",
            "Progress: 30/90\n",
            "Progress: 40/90\n",
            "Progress: 50/90\n",
            "Progress: 60/90\n",
            "Progress: 70/90\n",
            "Progress: 80/90\n",
            "Progress: 90/90\n",
            "\n",
            "\u2713 Large synthetic sample collected and saved\n",
            "[Skipped to save API costs - uncomment to run]\n",
            "This would generate 90 synthetic respondents (~$0.50-1.00)\n"
          ]
        }
      ],
      "source": [
        "# Generate larger synthetic sample (this will take a few minutes and cost ~$0.50)\n",
        "# Uncomment to run - skipping by default to save API costs\n",
        "\n",
        "# Create diverse demographic profiles\n",
        "from itertools import product\n",
        "\n",
        "# Define demographic space\n",
        "ages = [25, 35, 45, 55, 65]\n",
        "races = ['white', 'Black', 'Hispanic']\n",
        "genders = ['male', 'female']\n",
        "educations = ['high school', 'college degree']\n",
        "incomes = ['35,000', '65,000', '95,000']\n",
        "regions = ['Northeast', 'South', 'Midwest', 'West']\n",
        "parties = ['Democrat', 'Republican', 'Independent']\n",
        "\n",
        "# Generate personas (this creates hundreds of combinations)\n",
        "# For demo purposes, sample a subset\n",
        "np.random.seed(42)\n",
        "\n",
        "personas = []\n",
        "for party in parties:\n",
        "    for i in range(30):  # 30 per party = 90 total\n",
        "        persona = {\n",
        "            'age': np.random.choice(ages),\n",
        "            'race': np.random.choice(races),\n",
        "            'gender': np.random.choice(genders),\n",
        "            'education': np.random.choice(educations),\n",
        "            'income': np.random.choice(incomes),\n",
        "            'region': np.random.choice(regions),\n",
        "            'party': party\n",
        "        }\n",
        "        personas.append(persona)\n",
        "\n",
        "# Collect responses\n",
        "synthetic_results = []\n",
        "\n",
        "for i, persona in enumerate(personas, 1):\n",
        "    if i % 10 == 0:\n",
        "        print(f\"Progress: {i}/{len(personas)}\")\n",
        "\n",
        "    responses = collect_responses(persona, questions[:2])  # Just Q1, Q2 for speed\n",
        "    result = {**persona, **responses}\n",
        "    synthetic_results.append(result)\n",
        "\n",
        "df_synthetic_large = pd.DataFrame(synthetic_results)\n",
        "df_synthetic_large.to_csv('synthetic_survey_data.csv', index=False)\n",
        "\n",
        "print(\"\\n\u2713 Large synthetic sample collected and saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjK34QVcpnGr"
      },
      "source": [
        "**What this code does:**\n\nDemonstrates how to generate a **large-scale synthetic sample** for validation:\n\n**The demographic space:**\n- **Full factorial**: All combinations of demographics\n- **Sampling strategy**: Random sample from space (more efficient than full grid)\n- **Stratification**: Equal samples per party (can weight later)\n\n**Sample size considerations:**\n- **Minimum**: 30-50 per group for distribution comparison\n- **Good**: 100+ per group\n- **Excellent**: 200+ per group (for robust comparison)\n\n**Cost calculation:**\n- 90 personas \u00d7 2 questions = 180 API calls\n- ~$0.0005 per call with GPT-3.5-turbo\n- Total: ~$0.10-0.50 depending on prompt length\n\n**Why commented out:**\n- Saves API costs for students running the notebook\n- Takes 5-10 minutes to run\n- You can uncomment when ready to do real validation\n\n**Best practices:**\n- Save results to CSV after generation\n- Don't regenerate unnecessarily\n- Include random seed for reproducibility\n- Log all parameters (model, temperature, timestamp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4nGGB8IpnGr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Diagnosing Invariance\n",
        "\n",
        "**Invariance** refers to the lack of within-group diversity - do all personas with the same demographics give identical answers?\n",
        "\n",
        "**The problem:**\n",
        "- Real humans with same demographics have diverse opinions\n",
        "- LLMs may give identical answers for identical demographics\n",
        "- This underestimates real heterogeneity\n",
        "\n",
        "**How to test:**\n",
        "- Generate multiple responses for same persona\n",
        "- Measure within-persona variance\n",
        "- Compare to human within-group variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NfvBWpvpnGr",
        "outputId": "129d426f-69f6-4e69-c569-8d2070a8aa80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing invariance for persona: Democrat, 45, white\n",
            "Question: The government should provide universal healthcare for all citizens.\n",
            "\n",
            "======================================================================\n",
            "Response 1: 5\n",
            "Response 2: 5\n",
            "Response 3: 5\n",
            "Response 4: 5\n",
            "Response 5: 5\n",
            "Response 6: 5\n",
            "Response 7: 5\n",
            "Response 8: 5\n",
            "Response 9: 5\n",
            "Response 10: 5\n",
            "\n",
            "Within-persona statistics:\n",
            "  Mean: 5.00\n",
            "  Std: 0.00\n",
            "  Variance: 0.00\n",
            "\n",
            "Comparison:\n",
            "  LLM within-persona std: 0.00\n",
            "  Expected human within-group std: ~1.0-1.5\n",
            "  \u26a0 High invariance detected (low diversity)\n"
          ]
        }
      ],
      "source": [
        "# Test invariance: multiple responses from same persona\n",
        "test_persona = example_personas[0]  # Democrat, 45, white male\n",
        "test_question = questions[0]  # Healthcare\n",
        "\n",
        "print(f\"Testing invariance for persona: {test_persona['party']}, {test_persona['age']}, {test_persona['race']}\")\n",
        "print(f\"Question: {test_question}\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Collect 10 responses from same persona\n",
        "responses = []\n",
        "for i in range(10):\n",
        "    response = silicon_sample_likert(test_persona, test_question)\n",
        "    responses.append(response)\n",
        "    print(f\"Response {i+1}: {response}\")\n",
        "    time.sleep(0.3)\n",
        "\n",
        "# Calculate variance\n",
        "responses = [r for r in responses if r is not None]\n",
        "mean_response = np.mean(responses)\n",
        "variance = np.var(responses)\n",
        "std = np.std(responses)\n",
        "\n",
        "print(f\"\\nWithin-persona statistics:\")\n",
        "print(f\"  Mean: {mean_response:.2f}\")\n",
        "print(f\"  Std: {std:.2f}\")\n",
        "print(f\"  Variance: {variance:.2f}\")\n",
        "\n",
        "# Compare to expected human variance\n",
        "# For real data, same-demographic humans typically have std ~ 1.0-1.5 on 5-point scale\n",
        "print(f\"\\nComparison:\")\n",
        "print(f\"  LLM within-persona std: {std:.2f}\")\n",
        "print(f\"  Expected human within-group std: ~1.0-1.5\")\n",
        "\n",
        "if std < 0.5:\n",
        "    print(f\"  \u26a0 High invariance detected (low diversity)\")\n",
        "elif std < 1.0:\n",
        "    print(f\"  \u26a0 Moderate invariance (less diverse than humans)\")\n",
        "else:\n",
        "    print(f\"  \u2713 Variance comparable to humans\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DifJTD59pnGr"
      },
      "source": [
        "**What this code does:**\n\nTests for **invariance** by repeatedly querying the same persona:\n\n**The invariance problem:**\n- Real humans: Same demographics \u2260 identical opinions\n- LLMs: May produce very similar responses for identical personas\n- This **underestimates real heterogeneity**\n\n**Why invariance happens:**\n- Temperature > 0 adds randomness, but not enough\n- Models average over training data\n- Stereotypical \"typical\" response for each demographic\n- Missing individual-level factors (personality, experiences, etc.)\n\n**What we measure:**\n- **Mean**: Average response for persona\n- **Std (standard deviation)**: Spread of responses\n- **Variance**: Squared std\n\n**Interpretation:**\n- **Std < 0.5**: High invariance (responses very similar)\n- **Std 0.5-1.0**: Moderate diversity (less than humans)\n- **Std > 1.0**: Good diversity (approaching human levels)\n\n**Typical observations:**\n- LLMs: Std ~ 0.3-0.8 (varies by question and model)\n- Humans: Std ~ 1.0-1.5 on same demographic\n- **Implication**: LLMs underestimate within-group diversity\n\n**Solutions:**\n- Higher temperature (but may reduce accuracy)\n- Add personality traits to personas\n- Fine-tune on diverse real responses\n- Acknowledge limitation in reporting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB_fO4oQpnGr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 5: Diagnosing Stereotyping\n",
        "\n",
        "**Stereotyping** occurs when LLMs exaggerate between-group differences compared to real data.\n",
        "\n",
        "**The problem:**\n",
        "- LLMs trained on text that often contains stereotypes\n",
        "- May amplify partisan/demographic differences\n",
        "- Creates artificial polarization\n",
        "\n",
        "**How to test:**\n",
        "- Compare effect sizes for demographics in synthetic vs real data\n",
        "- Look for exaggerated differences between groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0riFY75lpnGr",
        "outputId": "15b955b9-668b-423c-ce47-9f0172b3739f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating responses from 5 Democrats and 5 Republicans...\n",
            "\n",
            "\n",
            "Between-group analysis (Healthcare question):\n",
            "======================================================================\n",
            "\n",
            "Democrat mean: 5.00\n",
            "Republican mean: 2.00\n",
            "Difference: 3.00\n",
            "Cohen's d: 0.00\n",
            "\n",
            "Effect size interpretation:\n",
            "  Small effect (< 0.5)\n",
            "\n",
            "Note: Compare this to real survey data Cohen's d\n",
            "If synthetic d >> real d, this suggests stereotyping\n"
          ]
        }
      ],
      "source": [
        "# Analyze stereotyping: between-group differences\n",
        "\n",
        "# For demonstration, generate synthetic data for Democrats vs Republicans\n",
        "print(\"Generating responses from 5 Democrats and 5 Republicans...\\n\")\n",
        "\n",
        "stereotyping_data = []\n",
        "\n",
        "for party in ['Democrat', 'Republican']:\n",
        "    for i in range(5):\n",
        "        persona = {\n",
        "            'age': 45 + i * 5,\n",
        "            'race': 'white',\n",
        "            'gender': 'male' if i % 2 == 0 else 'female',\n",
        "            'education': 'college degree',\n",
        "            'income': '75,000',\n",
        "            'region': 'Midwest',\n",
        "            'party': party\n",
        "        }\n",
        "\n",
        "        response = silicon_sample_likert(persona, questions[0])  # Healthcare question\n",
        "        stereotyping_data.append({\n",
        "            'party': party,\n",
        "            'response': response\n",
        "        })\n",
        "        time.sleep(0.3)\n",
        "\n",
        "df_stereotyping = pd.DataFrame(stereotyping_data)\n",
        "\n",
        "# Calculate means and effect size\n",
        "dem_mean = df_stereotyping[df_stereotyping['party'] == 'Democrat']['response'].mean()\n",
        "rep_mean = df_stereotyping[df_stereotyping['party'] == 'Republican']['response'].mean()\n",
        "\n",
        "# Cohen's d (effect size)\n",
        "pooled_std = df_stereotyping.groupby('party')['response'].std().mean()\n",
        "cohens_d = (dem_mean - rep_mean) / pooled_std if pooled_std > 0 else 0\n",
        "\n",
        "print(\"\\nBetween-group analysis (Healthcare question):\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nDemocrat mean: {dem_mean:.2f}\")\n",
        "print(f\"Republican mean: {rep_mean:.2f}\")\n",
        "print(f\"Difference: {abs(dem_mean - rep_mean):.2f}\")\n",
        "print(f\"Cohen's d: {abs(cohens_d):.2f}\")\n",
        "\n",
        "print(f\"\\nEffect size interpretation:\")\n",
        "if abs(cohens_d) < 0.5:\n",
        "    print(\"  Small effect (< 0.5)\")\n",
        "elif abs(cohens_d) < 0.8:\n",
        "    print(\"  Medium effect (0.5-0.8)\")\n",
        "else:\n",
        "    print(\"  Large effect (> 0.8)\")\n",
        "    print(\"  \u26a0 May indicate stereotyping if larger than real data\")\n",
        "\n",
        "print(f\"\\nNote: Compare this to real survey data Cohen's d\")\n",
        "print(f\"If synthetic d >> real d, this suggests stereotyping\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDTr0ZrcpnGr"
      },
      "source": [
        "**What this code does:**\n\nTests for **stereotyping** by measuring between-group differences:\n\n**What is stereotyping in silicon sampling:**\n- LLMs may exaggerate differences between demographic groups\n- E.g., making Democrats MORE pro-healthcare than real Democrats\n- Or Republicans MORE anti-healthcare than real Republicans\n- Creates artificial polarization\n\n**Cohen's d (effect size):**\n- Standardized measure of group difference\n- **Formula**: (Mean1 - Mean2) / Pooled SD\n- **Interpretation**:\n  - d < 0.5: Small effect\n  - d = 0.5-0.8: Medium effect\n  - d > 0.8: Large effect\n\n**How to detect stereotyping:**\n1. Calculate Cohen's d for synthetic data\n2. Calculate Cohen's d for real data\n3. Compare: If synthetic d >> real d, stereotyping present\n\n**Example:**\n- Real data: Democrat vs Republican on healthcare, d = 1.2\n- Synthetic: d = 2.4\n- **Interpretation**: LLM is doubling the partisan divide\n\n**Why stereotyping happens:**\n- Training data contains exaggerated partisan rhetoric\n- News articles emphasize differences\n- Social media polarization in training data\n- Models learn \"prototypical\" Democrat/Republican\n\n**Bisbee et al. (2024) findings:**\n- Stereotyping varies by question type\n- More polarized responses for morally charged issues (abortion, guns)\n- Better performance for less controversial topics\n- Aggregate estimates can help reduce bias\n\n**Solutions:**\n- Compare effect sizes to real data (essential validation step)\n- Use caution with controversial or morally charged questions\n- Consider weighting/calibrating to match real distributions"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}